{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview \u00b6 About ANNarchy \u00b6 ANNarchy (Artificial Neural Networks architect) is a neural simulator designed for distributed rate-coded or spiking neural networks. The core of the library is written in C++ and distributed using openMP, CUDA and MPI. It provides an interface in Python for the definition of the networks. It is released under the GNU GPL v2 or later . Source code: http://bitbucket.org/annarchy/annarchy Documentation: http://annarchy.readthedocs.io Forum: https://groups.google.com/forum/#!forum/annarchy Bug reports: https://bitbucket.org/annarchy/annarchy/issues Citation If you use ANNarchy for your research, we would appreciate if you cite the following paper: Vitay J, Dinkelbach H\u00dc and Hamker FH (2015). ANNarchy: a code generation approach to neural simulations on parallel hardware. Frontiers in Neuroinformatics 9:19. http://dx.doi.org/10.3389/fninf.2015.00019 Dependencies \u00b6 ANNarchy can be used on any GNU/Linux system, as well as MacOS X. Python >= 3.7 Numpy >= 1.20.0 Scipy >= 1.6.0 Installation \u00b6 To install the latest stable release of ANNarchy, pip is recommended: pip install ANNarchy To install the latest developement release of ANNarchy, install it from source: git clone http://bitbucket.org/annarchy/annarchy.git cd annarchy/ python setup.py install","title":"Overview"},{"location":"#overview","text":"","title":"Overview"},{"location":"#about-annarchy","text":"ANNarchy (Artificial Neural Networks architect) is a neural simulator designed for distributed rate-coded or spiking neural networks. The core of the library is written in C++ and distributed using openMP, CUDA and MPI. It provides an interface in Python for the definition of the networks. It is released under the GNU GPL v2 or later . Source code: http://bitbucket.org/annarchy/annarchy Documentation: http://annarchy.readthedocs.io Forum: https://groups.google.com/forum/#!forum/annarchy Bug reports: https://bitbucket.org/annarchy/annarchy/issues Citation If you use ANNarchy for your research, we would appreciate if you cite the following paper: Vitay J, Dinkelbach H\u00dc and Hamker FH (2015). ANNarchy: a code generation approach to neural simulations on parallel hardware. Frontiers in Neuroinformatics 9:19. http://dx.doi.org/10.3389/fninf.2015.00019","title":"About ANNarchy"},{"location":"#dependencies","text":"ANNarchy can be used on any GNU/Linux system, as well as MacOS X. Python >= 3.7 Numpy >= 1.20.0 Scipy >= 1.6.0","title":"Dependencies"},{"location":"#installation","text":"To install the latest stable release of ANNarchy, pip is recommended: pip install ANNarchy To install the latest developement release of ANNarchy, install it from source: git clone http://bitbucket.org/annarchy/annarchy.git cd annarchy/ python setup.py install","title":"Installation"},{"location":"api/network/","text":"Network \u00b6 Network class containing the complete neural model. Attributes: Name Type Description dt float simulation time step in ms. __init__ ( self , dt = 1.0 , verbose = 1 , logfile = None ) special \u00b6 Constructor of the Network class. The discretization time contant dt is determined at the network-level and should stay constant during the whole simulation. The verbose level specifies which logging messages will be shown: 0 : only errors and exceptions are printed. 1 : errors, exceptions and warnings are displayed (default). 2 : additional information is also displayed (parsing, etc). 3 : debug information is also displayed (which method is entered, variable values, etc...) When logfile is specified, the logging messages will be saved in that file instead of stdout. Parameters: Name Type Description Default dt float simulation step size in ms. 1.0 verbose int logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 1 logfile str file to save the logs. stdout if left empty. None Source code in ANNarchy_future/api/Network.py def __init__ ( self , dt : float = 1.0 , verbose : int = 1 , logfile : str = None ): \"\"\"Constructor of the `Network` class. The discretization time contant `dt` is determined at the network-level and should stay constant during the whole simulation. The `verbose` level specifies which logging messages will be shown: * 0 : only errors and exceptions are printed. * 1 : errors, exceptions and warnings are displayed (default). * 2 : additional information is also displayed (parsing, etc). * 3 : debug information is also displayed (which method is entered, variable values, etc...) When `logfile` is specified, the logging messages will be saved in that file instead of stdout. Args: dt: simulation step size in ms. verbose: logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 logfile: file to save the logs. stdout if left empty. \"\"\" self . dt = dt # Logging module: https://docs.python.org/3/howto/logging.html if logfile is not None : logging . basicConfig ( filename = logfile , level = verbosity_levels [ verbose ]) else : logging . basicConfig ( level = verbosity_levels [ verbose ]) self . logger = logging . getLogger ( __name__ ) self . logger . info ( \"Creating new network with dt=\" + str ( self . dt )) # List of populations self . _populations = [] # List of used neuron self . _neuron_types = {} add ( self , shape , neuron , name = None ) \u00b6 Adds a population to the network. Parameters: Name Type Description Default shape tuple shape of the population as a single integer or tuple. required neuron Neuron Neuron instance. required name str optional name. None Returns: Type Description Population A population instance. Source code in ANNarchy_future/api/Network.py def add ( self , shape : tuple , neuron : Neuron , name : str = None ) -> Population : \"\"\"Adds a population to the network. Args: shape: shape of the population as a single integer or tuple. neuron: Neuron instance. name: optional name. Returns: A population instance. \"\"\" if isinstance ( shape , int ): shape = ( shape ,) # Create the population self . logger . info ( \"Adding Population(\" + str ( shape ) + \", \" + type ( neuron ) . __name__ + \", \" + str ( name ) + \").\" ) pop = Population ( shape , neuron , name ) id_pop = len ( self . _populations ) pop . _register ( self , id_pop ) # Have the population analyse its attributes self . logger . debug ( \"Analysing the population.\" ) pop . _analyse () # Store the neuron if not done already if not pop . neuron_class in self . _neuron_types . keys (): self . _neuron_types [ pop . neuron_class ] = pop . parser # Store the population self . _populations . append ( pop ) self . logger . info ( \"Population created.\" ) return pop compile ( self , backend = 'single' ) \u00b6 Compiles and instantiates the network. Parameters: Name Type Description Default backend str choose between 'single' , 'openmp' , 'cuda' or 'mpi' . 'single' Source code in ANNarchy_future/api/Network.py def compile ( self , backend : str = 'single' ): \"\"\"Compiles and instantiates the network. Args: backend: choose between `'single'`, `'openmp'`, `'cuda'` or `'mpi'`. \"\"\" self . _backend = backend # Gather all parsed information description = self . _gather_generated_code () # Create compiler compiler = Compiler ( description , backend = backend ) # Sanity check compiler . sanity_check () # Code generation self . _simulation_core = compiler . compile () # Instantiate the network self . _instantiate ()","title":"Network"},{"location":"api/network/#network","text":"Network class containing the complete neural model. Attributes: Name Type Description dt float simulation time step in ms.","title":"Network"},{"location":"api/network/#ANNarchy_future.api.Network.Network.__init__","text":"Constructor of the Network class. The discretization time contant dt is determined at the network-level and should stay constant during the whole simulation. The verbose level specifies which logging messages will be shown: 0 : only errors and exceptions are printed. 1 : errors, exceptions and warnings are displayed (default). 2 : additional information is also displayed (parsing, etc). 3 : debug information is also displayed (which method is entered, variable values, etc...) When logfile is specified, the logging messages will be saved in that file instead of stdout. Parameters: Name Type Description Default dt float simulation step size in ms. 1.0 verbose int logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 1 logfile str file to save the logs. stdout if left empty. None Source code in ANNarchy_future/api/Network.py def __init__ ( self , dt : float = 1.0 , verbose : int = 1 , logfile : str = None ): \"\"\"Constructor of the `Network` class. The discretization time contant `dt` is determined at the network-level and should stay constant during the whole simulation. The `verbose` level specifies which logging messages will be shown: * 0 : only errors and exceptions are printed. * 1 : errors, exceptions and warnings are displayed (default). * 2 : additional information is also displayed (parsing, etc). * 3 : debug information is also displayed (which method is entered, variable values, etc...) When `logfile` is specified, the logging messages will be saved in that file instead of stdout. Args: dt: simulation step size in ms. verbose: logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 logfile: file to save the logs. stdout if left empty. \"\"\" self . dt = dt # Logging module: https://docs.python.org/3/howto/logging.html if logfile is not None : logging . basicConfig ( filename = logfile , level = verbosity_levels [ verbose ]) else : logging . basicConfig ( level = verbosity_levels [ verbose ]) self . logger = logging . getLogger ( __name__ ) self . logger . info ( \"Creating new network with dt=\" + str ( self . dt )) # List of populations self . _populations = [] # List of used neuron self . _neuron_types = {}","title":"__init__()"},{"location":"api/network/#ANNarchy_future.api.Network.Network.add","text":"Adds a population to the network. Parameters: Name Type Description Default shape tuple shape of the population as a single integer or tuple. required neuron Neuron Neuron instance. required name str optional name. None Returns: Type Description Population A population instance. Source code in ANNarchy_future/api/Network.py def add ( self , shape : tuple , neuron : Neuron , name : str = None ) -> Population : \"\"\"Adds a population to the network. Args: shape: shape of the population as a single integer or tuple. neuron: Neuron instance. name: optional name. Returns: A population instance. \"\"\" if isinstance ( shape , int ): shape = ( shape ,) # Create the population self . logger . info ( \"Adding Population(\" + str ( shape ) + \", \" + type ( neuron ) . __name__ + \", \" + str ( name ) + \").\" ) pop = Population ( shape , neuron , name ) id_pop = len ( self . _populations ) pop . _register ( self , id_pop ) # Have the population analyse its attributes self . logger . debug ( \"Analysing the population.\" ) pop . _analyse () # Store the neuron if not done already if not pop . neuron_class in self . _neuron_types . keys (): self . _neuron_types [ pop . neuron_class ] = pop . parser # Store the population self . _populations . append ( pop ) self . logger . info ( \"Population created.\" ) return pop","title":"add()"},{"location":"api/network/#ANNarchy_future.api.Network.Network.compile","text":"Compiles and instantiates the network. Parameters: Name Type Description Default backend str choose between 'single' , 'openmp' , 'cuda' or 'mpi' . 'single' Source code in ANNarchy_future/api/Network.py def compile ( self , backend : str = 'single' ): \"\"\"Compiles and instantiates the network. Args: backend: choose between `'single'`, `'openmp'`, `'cuda'` or `'mpi'`. \"\"\" self . _backend = backend # Gather all parsed information description = self . _gather_generated_code () # Create compiler compiler = Compiler ( description , backend = backend ) # Sanity check compiler . sanity_check () # Code generation self . _simulation_core = compiler . compile () # Instantiate the network self . _instantiate ()","title":"compile()"},{"location":"api/neuron/","text":"Neuron \u00b6 Abstract class defining single neurons. TODO Array ( self , init = 0.0 , dtype =< class ' numpy . float32 '>) \u00b6 Defines an Array for the neuron. Arrays can take a different value for each neuron in the population. If a single value is needed, use Value to save some memory. Parameters: Name Type Description Default value initial value. required dtype numpy type of the value (e.g. np.int, np.float) <class 'numpy.float32'> Returns: Type Description Array Value instance. Source code in ANNarchy_future/api/Neuron.py def Array ( self , init : float = 0.0 , dtype = np . float32 ) -> Array : \"\"\"Defines an Array for the neuron. Arrays can take a different value for each neuron in the population. If a single value is needed, use `Value` to save some memory. Args: value: initial value. dtype: numpy type of the value (e.g. np.int, np.float) Returns: `Value` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = Array ( init , dtype ) self . _data . append ( val ) return val Equations ( self , method = 'euler' ) \u00b6 Returns an Equations context. with self . Equations () as n : n . dr_dt = ( n . ge - n . r ) / n . tau When opening the context as n , the variable has all attributes (values and arrays) of the neuron as symbols, which can be combined in Sympy equations. Parameters: Name Type Description Default method str numerical method (euler, midpoint, exponential, rk4, event-driven) 'euler' Source code in ANNarchy_future/api/Neuron.py def Equations ( self , method : str = 'euler' ): \"\"\"Returns an Equations context. ```python with self.Equations() as n: n.dr_dt = (n.ge - n.r)/n.tau ``` When opening the context as `n`, the variable has all attributes (values and arrays) of the neuron as symbols, which can be combined in Sympy equations. Args: method: numerical method (euler, midpoint, exponential, rk4, event-driven) \"\"\" eq = Equations ( neuron = self , method = method ) self . _current_eq = eq return eq Value ( self , value , dtype =< class ' numpy . float32 '>) \u00b6 Defines a Value for the neuron. Values are defined only once for the whole population. If each neuron should have different values, use an Array instead. Parameters: Name Type Description Default value float initial value. required dtype numpy type of the value (e.g. np.int, np.float) <class 'numpy.float32'> Returns: Type Description Value Value instance. Source code in ANNarchy_future/api/Neuron.py def Value ( self , value : float , dtype = np . float32 ) -> Value : \"\"\"Defines a Value for the neuron. Values are defined only once for the whole population. If each neuron should have different values, use an `Array` instead. Args: value: initial value. dtype: numpy type of the value (e.g. np.int, np.float) Returns: `Value` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = Value ( value , dtype ) self . _data . append ( val ) return val","title":"Neuron"},{"location":"api/neuron/#neuron","text":"Abstract class defining single neurons. TODO","title":"Neuron"},{"location":"api/neuron/#ANNarchy_future.api.Neuron.Neuron.Array","text":"Defines an Array for the neuron. Arrays can take a different value for each neuron in the population. If a single value is needed, use Value to save some memory. Parameters: Name Type Description Default value initial value. required dtype numpy type of the value (e.g. np.int, np.float) <class 'numpy.float32'> Returns: Type Description Array Value instance. Source code in ANNarchy_future/api/Neuron.py def Array ( self , init : float = 0.0 , dtype = np . float32 ) -> Array : \"\"\"Defines an Array for the neuron. Arrays can take a different value for each neuron in the population. If a single value is needed, use `Value` to save some memory. Args: value: initial value. dtype: numpy type of the value (e.g. np.int, np.float) Returns: `Value` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = Array ( init , dtype ) self . _data . append ( val ) return val","title":"Array()"},{"location":"api/neuron/#ANNarchy_future.api.Neuron.Neuron.Equations","text":"Returns an Equations context. with self . Equations () as n : n . dr_dt = ( n . ge - n . r ) / n . tau When opening the context as n , the variable has all attributes (values and arrays) of the neuron as symbols, which can be combined in Sympy equations. Parameters: Name Type Description Default method str numerical method (euler, midpoint, exponential, rk4, event-driven) 'euler' Source code in ANNarchy_future/api/Neuron.py def Equations ( self , method : str = 'euler' ): \"\"\"Returns an Equations context. ```python with self.Equations() as n: n.dr_dt = (n.ge - n.r)/n.tau ``` When opening the context as `n`, the variable has all attributes (values and arrays) of the neuron as symbols, which can be combined in Sympy equations. Args: method: numerical method (euler, midpoint, exponential, rk4, event-driven) \"\"\" eq = Equations ( neuron = self , method = method ) self . _current_eq = eq return eq","title":"Equations()"},{"location":"api/neuron/#ANNarchy_future.api.Neuron.Neuron.Value","text":"Defines a Value for the neuron. Values are defined only once for the whole population. If each neuron should have different values, use an Array instead. Parameters: Name Type Description Default value float initial value. required dtype numpy type of the value (e.g. np.int, np.float) <class 'numpy.float32'> Returns: Type Description Value Value instance. Source code in ANNarchy_future/api/Neuron.py def Value ( self , value : float , dtype = np . float32 ) -> Value : \"\"\"Defines a Value for the neuron. Values are defined only once for the whole population. If each neuron should have different values, use an `Array` instead. Args: value: initial value. dtype: numpy type of the value (e.g. np.int, np.float) Returns: `Value` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = Value ( value , dtype ) self . _data . append ( val ) return val","title":"Value()"},{"location":"api/population/","text":"Population \u00b6 Population \u00b6 Population of neurons. Populations should not be created explicitly, but returned by Network.add() : net = Network () pop = net . add ( 10 , LIF ()) Attributes: Name Type Description shape tuple shape of the population. size int number of neurons. name str unique name of the population. neuron_class name of the Neuron class Additionaly, all values and arrays of the neuron type are accessible as attributes: class Leaky ( Neuron ): def __init__ ( self ): self . tau = self . Value ( 20. ) self . r = self . Array ( 0.0 ) net = Network () pop = net . add ( 10 , Leaky ()) print ( pop . tau ) # 20. print ( pop . r ) # [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] is_spiking ( self ) \u00b6 Returns True if the neuron type is spiking. Source code in ANNarchy_future/api/Population.py def is_spiking ( self ) -> bool : \"Returns True if the neuron type is spiking.\" return self . _neuron_type . is_spiking ()","title":"Population"},{"location":"api/population/#population","text":"","title":"Population"},{"location":"api/population/#ANNarchy_future.api.Population.Population","text":"Population of neurons. Populations should not be created explicitly, but returned by Network.add() : net = Network () pop = net . add ( 10 , LIF ()) Attributes: Name Type Description shape tuple shape of the population. size int number of neurons. name str unique name of the population. neuron_class name of the Neuron class Additionaly, all values and arrays of the neuron type are accessible as attributes: class Leaky ( Neuron ): def __init__ ( self ): self . tau = self . Value ( 20. ) self . r = self . Array ( 0.0 ) net = Network () pop = net . add ( 10 , Leaky ()) print ( pop . tau ) # 20. print ( pop . r ) # [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]","title":"Population"},{"location":"api/population/#ANNarchy_future.api.Population.Population.is_spiking","text":"Returns True if the neuron type is spiking. Source code in ANNarchy_future/api/Population.py def is_spiking ( self ) -> bool : \"Returns True if the neuron type is spiking.\" return self . _neuron_type . is_spiking ()","title":"is_spiking()"},{"location":"contributing/parser/","text":"Parser \u00b6 Equations \u00b6 Context to define equations. It should be primarily used inside a Neuron or Synapse class, but can also be used in a standalone mode by providing a list of attributes: with Equations ( symbols = [ 'tau' , 'v' , 'r' ]) as n : n . dv_dt = ( n . cast ( 1.0 ) - n . v ) / n . tau n . r = sp . tanh ( n . v ) print ( n ) __init__ ( self , symbols = None , method = 'euler' , neuron = None , synapse = None ) special \u00b6 Creates the Equations context. Parameters: Name Type Description Default symbols list list of attributes when in standalone mode. None method str numerical method (euler, midpoint, exponential, rk4, event-driven) 'euler' neuron Neuron instance (passed by the population). None synapse Synapse instance (passed by the projection). None Source code in ANNarchy_future/parser/Equations.py def __init__ ( self , symbols : list = None , method : str = 'euler' , neuron = None , synapse = None ): \"\"\"Creates the Equations context. Args: symbols: list of attributes when in standalone mode. method: numerical method (euler, midpoint, exponential, rk4, event-driven) neuron: Neuron instance (passed by the population). synapse: Synapse instance (passed by the projection). \"\"\" # Logger self . logger = logging . getLogger ( __name__ ) self . logger . info ( \"Equations() created.\" ) # Objects self . neuron = neuron self . synapse = synapse # Numerical method self . method = method # Built-in symbols self . symbols = { 't' : sp . Symbol ( \"t\" ), 'dt' : sp . Symbol ( \"dt\" ), 'spike' : sp . Symbol ( \"spike\" ), } # Standalone mode if self . neuron is None and self . synapse is None : self . _custom_symbols = symbols self . logger . info ( \"Custom symbols: \" + str ( symbols )) # List of tuples (name, Equation) self . equations = [] # Start recording assignments self . _started = False cast ( self , val ) \u00b6 Cast floating point numbers to symbols in order to avoid numerical errors. Parameters: Name Type Description Default val float required Source code in ANNarchy_future/parser/Equations.py def cast ( self , val : float ) -> sp . Symbol : \"\"\"Cast floating point numbers to symbols in order to avoid numerical errors. Args: val (float): \"\"\" return sp . Symbol ( str ( float ( val ))) ite ( self , cond , then , els ) \u00b6 If-then-else ternary operator. Equivalent to: def ite ( cond , then , els ): if cond : return then else : return els Args: cond: condition. then: returned value when cond is true. else: returned value when cond is false. Source code in ANNarchy_future/parser/Equations.py def ite ( self , cond , then , els ): \"\"\"If-then-else ternary operator. Equivalent to: ```python def ite(cond, then, els): if cond: return then else: return els ``` Args: cond: condition. then: returned value when cond is true. else: returned value when cond is false. \"\"\" return sp . Piecewise (( then , cond ), ( els , True )) NeuronParser \u00b6 Neuron parser. Attributes: Name Type Description neuron Neuron Neuron class name str name of the Neuron class attributes list list of attributes (values and arrays) values list list of values arrays list list of arrays update_equations list update equations. spike_condition Condition spike condition. reset_equations list reset equations. __init__ ( self , neuron ) special \u00b6 Initializes the parser. Sets: self.neuron self.name Source code in ANNarchy_future/parser/NeuronParser.py def __init__ ( self , neuron : Neuron ): \"\"\"Initializes the parser. Sets: * `self.neuron` * `self.name` \"\"\" self . neuron = neuron self . _spiking = False self . name = self . neuron . __class__ . __name__ # Logging self . logger = logging . getLogger ( __name__ ) self . logger . debug ( \"Neuron parser created.\" ) # Attributes self . attributes = [] self . values = [] self . arrays = [] # Equations to retrieve self . update_equations = None self . spike_condition = None self . reset_equations = None analyse_equations ( self ) \u00b6 Analyses the neuron equations. Calls update(), spike() and reset() to retrieve the Equations objects. Sets: self.update_equations self.spike_condition self.reset_equations Source code in ANNarchy_future/parser/NeuronParser.py def analyse_equations ( self ): \"\"\"Analyses the neuron equations. Calls update(), spike() and reset() to retrieve the `Equations` objects. Sets: * `self.update_equations` * `self.spike_condition` * `self.reset_equations` \"\"\" # List of methods callables = [ f for f in dir ( self . neuron ) if callable ( getattr ( self . neuron , f ))] if not 'update' in callables : self . logger . error ( \"The Neuron class must implement update(self)\" ) sys . exit ( 1 ) # Analyse update() self . logger . info ( \"Calling Neuron.update().\" ) try : self . neuron . update () except Exception : self . logger . exception ( \"Unable to analyse update()\" ) sys . exit ( 1 ) self . update_equations = self . process_equations ( self . neuron . _current_eq ) # For spiking neurons only if 'spike' in callables : self . logger . info ( \"Neuron has a spike() method.\" ) self . _spiking = True self . logger . info ( \"Calling Neuron.spike().\" ) # Analyse spike() try : self . neuron . spike () except Exception : self . logger . exception ( \"Unable to analyse spike()\" ) sys . exit ( 1 ) self . spike_condition = self . process_condition ( self . neuron . _current_eq ) # Analyse reset() self . logger . info ( \"Calling Neuron.reset().\" ) try : self . neuron . reset () except Exception : self . logger . exception ( \"Unable to analyse reset()\" ) sys . exit ( 1 ) self . reset_equations = self . process_equations ( self . neuron . _current_eq ) extract_variables ( self ) \u00b6 Iterates over neuron.__dict__ and extracts all Value() and Array() instances. Sets: self._spiking self.attributes self.values self.arrays Source code in ANNarchy_future/parser/NeuronParser.py def extract_variables ( self ): \"\"\"Iterates over `neuron.__dict__` and extracts all `Value()` and `Array()` instances. Sets: * `self._spiking` * `self.attributes` * `self.values` * `self.arrays` \"\"\" # List attributes current_attributes = list ( self . neuron . __dict__ . keys ()) for attr in current_attributes : if isinstance ( getattr ( self . neuron , attr ), ( Value , )): self . values . append ( attr ) self . attributes . append ( attr ) if isinstance ( getattr ( self . neuron , attr ), ( Array , )): self . arrays . append ( attr ) self . attributes . append ( attr ) # Get lists of values and arrays self . logger . info ( \"Attributes: \" + str ( self . attributes )) self . logger . info ( \"Values: \" + str ( self . values )) self . logger . info ( \"Arrays: \" + str ( self . arrays )) # Set the attributes to the neuron self . neuron . attributes = self . attributes self . neuron . _values_list = self . values self . neuron . _arrays_list = self . arrays is_spiking ( self ) \u00b6 Returns True if the Neuron class is spiking. Source code in ANNarchy_future/parser/NeuronParser.py def is_spiking ( self ) -> bool : \"Returns True if the Neuron class is spiking.\" return self . _spiking process_equations ( self , equations ) \u00b6 Checks all declared equations and applies a numerical method if necessary. Parameters: Name Type Description Default equations tuple (name, equation) required Returns: Type Description list a list of blocks, which are lists of equations of three types: assignments, ODEs and conditions. Source code in ANNarchy_future/parser/NeuronParser.py def process_equations ( self , equations ) -> list : \"\"\"Checks all declared equations and applies a numerical method if necessary. Args: equations: tuple (name, equation) Returns: a list of blocks, which are lists of equations of three types: assignments, ODEs and conditions. \"\"\" blocks = [] _current_assignment_block = None _current_ODE_block = None # Iterate over the equations to group them into blocks for name , eq in equations . equations : # ODE block if name . startswith ( \"d\" ) and name . endswith ( '_dt' ): if _current_assignment_block is not None : blocks . append ( _current_assignment_block ) _current_assignment_block = None if _current_ODE_block is None : _current_ODE_block = ODEBlock ( self , equations . method ) _current_ODE_block . add ( name [ 1 : - 3 ], eq ) # Assignment block else : if _current_ODE_block is not None : blocks . append ( _current_ODE_block ) _current_ODE_block = None if _current_assignment_block is None : _current_assignment_block = AssignmentBlock ( self ) _current_assignment_block . add ( name , eq ) # Append the last block if _current_assignment_block is not None : blocks . append ( _current_assignment_block ) if _current_ODE_block is not None : blocks . append ( _current_ODE_block ) for block in blocks : block . parse () return blocks","title":"Parser"},{"location":"contributing/parser/#parser","text":"","title":"Parser"},{"location":"contributing/parser/#ANNarchy_future.parser.Equations.Equations","text":"Context to define equations. It should be primarily used inside a Neuron or Synapse class, but can also be used in a standalone mode by providing a list of attributes: with Equations ( symbols = [ 'tau' , 'v' , 'r' ]) as n : n . dv_dt = ( n . cast ( 1.0 ) - n . v ) / n . tau n . r = sp . tanh ( n . v ) print ( n )","title":"Equations"},{"location":"contributing/parser/#ANNarchy_future.parser.Equations.Equations.__init__","text":"Creates the Equations context. Parameters: Name Type Description Default symbols list list of attributes when in standalone mode. None method str numerical method (euler, midpoint, exponential, rk4, event-driven) 'euler' neuron Neuron instance (passed by the population). None synapse Synapse instance (passed by the projection). None Source code in ANNarchy_future/parser/Equations.py def __init__ ( self , symbols : list = None , method : str = 'euler' , neuron = None , synapse = None ): \"\"\"Creates the Equations context. Args: symbols: list of attributes when in standalone mode. method: numerical method (euler, midpoint, exponential, rk4, event-driven) neuron: Neuron instance (passed by the population). synapse: Synapse instance (passed by the projection). \"\"\" # Logger self . logger = logging . getLogger ( __name__ ) self . logger . info ( \"Equations() created.\" ) # Objects self . neuron = neuron self . synapse = synapse # Numerical method self . method = method # Built-in symbols self . symbols = { 't' : sp . Symbol ( \"t\" ), 'dt' : sp . Symbol ( \"dt\" ), 'spike' : sp . Symbol ( \"spike\" ), } # Standalone mode if self . neuron is None and self . synapse is None : self . _custom_symbols = symbols self . logger . info ( \"Custom symbols: \" + str ( symbols )) # List of tuples (name, Equation) self . equations = [] # Start recording assignments self . _started = False","title":"__init__()"},{"location":"contributing/parser/#ANNarchy_future.parser.Equations.Equations.cast","text":"Cast floating point numbers to symbols in order to avoid numerical errors. Parameters: Name Type Description Default val float required Source code in ANNarchy_future/parser/Equations.py def cast ( self , val : float ) -> sp . Symbol : \"\"\"Cast floating point numbers to symbols in order to avoid numerical errors. Args: val (float): \"\"\" return sp . Symbol ( str ( float ( val )))","title":"cast()"},{"location":"contributing/parser/#ANNarchy_future.parser.Equations.Equations.ite","text":"If-then-else ternary operator. Equivalent to: def ite ( cond , then , els ): if cond : return then else : return els Args: cond: condition. then: returned value when cond is true. else: returned value when cond is false. Source code in ANNarchy_future/parser/Equations.py def ite ( self , cond , then , els ): \"\"\"If-then-else ternary operator. Equivalent to: ```python def ite(cond, then, els): if cond: return then else: return els ``` Args: cond: condition. then: returned value when cond is true. else: returned value when cond is false. \"\"\" return sp . Piecewise (( then , cond ), ( els , True ))","title":"ite()"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser","text":"Neuron parser. Attributes: Name Type Description neuron Neuron Neuron class name str name of the Neuron class attributes list list of attributes (values and arrays) values list list of values arrays list list of arrays update_equations list update equations. spike_condition Condition spike condition. reset_equations list reset equations.","title":"NeuronParser"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.__init__","text":"Initializes the parser. Sets: self.neuron self.name Source code in ANNarchy_future/parser/NeuronParser.py def __init__ ( self , neuron : Neuron ): \"\"\"Initializes the parser. Sets: * `self.neuron` * `self.name` \"\"\" self . neuron = neuron self . _spiking = False self . name = self . neuron . __class__ . __name__ # Logging self . logger = logging . getLogger ( __name__ ) self . logger . debug ( \"Neuron parser created.\" ) # Attributes self . attributes = [] self . values = [] self . arrays = [] # Equations to retrieve self . update_equations = None self . spike_condition = None self . reset_equations = None","title":"__init__()"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.analyse_equations","text":"Analyses the neuron equations. Calls update(), spike() and reset() to retrieve the Equations objects. Sets: self.update_equations self.spike_condition self.reset_equations Source code in ANNarchy_future/parser/NeuronParser.py def analyse_equations ( self ): \"\"\"Analyses the neuron equations. Calls update(), spike() and reset() to retrieve the `Equations` objects. Sets: * `self.update_equations` * `self.spike_condition` * `self.reset_equations` \"\"\" # List of methods callables = [ f for f in dir ( self . neuron ) if callable ( getattr ( self . neuron , f ))] if not 'update' in callables : self . logger . error ( \"The Neuron class must implement update(self)\" ) sys . exit ( 1 ) # Analyse update() self . logger . info ( \"Calling Neuron.update().\" ) try : self . neuron . update () except Exception : self . logger . exception ( \"Unable to analyse update()\" ) sys . exit ( 1 ) self . update_equations = self . process_equations ( self . neuron . _current_eq ) # For spiking neurons only if 'spike' in callables : self . logger . info ( \"Neuron has a spike() method.\" ) self . _spiking = True self . logger . info ( \"Calling Neuron.spike().\" ) # Analyse spike() try : self . neuron . spike () except Exception : self . logger . exception ( \"Unable to analyse spike()\" ) sys . exit ( 1 ) self . spike_condition = self . process_condition ( self . neuron . _current_eq ) # Analyse reset() self . logger . info ( \"Calling Neuron.reset().\" ) try : self . neuron . reset () except Exception : self . logger . exception ( \"Unable to analyse reset()\" ) sys . exit ( 1 ) self . reset_equations = self . process_equations ( self . neuron . _current_eq )","title":"analyse_equations()"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.extract_variables","text":"Iterates over neuron.__dict__ and extracts all Value() and Array() instances. Sets: self._spiking self.attributes self.values self.arrays Source code in ANNarchy_future/parser/NeuronParser.py def extract_variables ( self ): \"\"\"Iterates over `neuron.__dict__` and extracts all `Value()` and `Array()` instances. Sets: * `self._spiking` * `self.attributes` * `self.values` * `self.arrays` \"\"\" # List attributes current_attributes = list ( self . neuron . __dict__ . keys ()) for attr in current_attributes : if isinstance ( getattr ( self . neuron , attr ), ( Value , )): self . values . append ( attr ) self . attributes . append ( attr ) if isinstance ( getattr ( self . neuron , attr ), ( Array , )): self . arrays . append ( attr ) self . attributes . append ( attr ) # Get lists of values and arrays self . logger . info ( \"Attributes: \" + str ( self . attributes )) self . logger . info ( \"Values: \" + str ( self . values )) self . logger . info ( \"Arrays: \" + str ( self . arrays )) # Set the attributes to the neuron self . neuron . attributes = self . attributes self . neuron . _values_list = self . values self . neuron . _arrays_list = self . arrays","title":"extract_variables()"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.is_spiking","text":"Returns True if the Neuron class is spiking. Source code in ANNarchy_future/parser/NeuronParser.py def is_spiking ( self ) -> bool : \"Returns True if the Neuron class is spiking.\" return self . _spiking","title":"is_spiking()"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.process_equations","text":"Checks all declared equations and applies a numerical method if necessary. Parameters: Name Type Description Default equations tuple (name, equation) required Returns: Type Description list a list of blocks, which are lists of equations of three types: assignments, ODEs and conditions. Source code in ANNarchy_future/parser/NeuronParser.py def process_equations ( self , equations ) -> list : \"\"\"Checks all declared equations and applies a numerical method if necessary. Args: equations: tuple (name, equation) Returns: a list of blocks, which are lists of equations of three types: assignments, ODEs and conditions. \"\"\" blocks = [] _current_assignment_block = None _current_ODE_block = None # Iterate over the equations to group them into blocks for name , eq in equations . equations : # ODE block if name . startswith ( \"d\" ) and name . endswith ( '_dt' ): if _current_assignment_block is not None : blocks . append ( _current_assignment_block ) _current_assignment_block = None if _current_ODE_block is None : _current_ODE_block = ODEBlock ( self , equations . method ) _current_ODE_block . add ( name [ 1 : - 3 ], eq ) # Assignment block else : if _current_ODE_block is not None : blocks . append ( _current_ODE_block ) _current_ODE_block = None if _current_assignment_block is None : _current_assignment_block = AssignmentBlock ( self ) _current_assignment_block . add ( name , eq ) # Append the last block if _current_assignment_block is not None : blocks . append ( _current_assignment_block ) if _current_ODE_block is not None : blocks . append ( _current_ODE_block ) for block in blocks : block . parse () return blocks","title":"process_equations()"},{"location":"contributing/structure/","text":"Overview \u00b6 Contributing \u00b6 Some words on how to contribute on github. Style \u00b6 Attributes and methods must be typed according to PEP 484: def method ( a : int , b : float = 1.0 ) -> str : \"\"\"Dummy method. Args: a: first parameter. b: second parameter. Returns: a string. \"\"\" c : float = pow ( b , a ) return str ( c ) To facilitate documentation with mkdocstrings , all comments and docstrings must follow the Google style: https://google.github.io/styleguide/pyguide.html Example: https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html Pylint should never have to complain ;) Unit tests \u00b6 Find a strategy for consistent unit testing. Overview of ANNarchy's structure \u00b6 Overview of the architecture: api parser generator","title":"Overview"},{"location":"contributing/structure/#overview","text":"","title":"Overview"},{"location":"contributing/structure/#contributing","text":"Some words on how to contribute on github.","title":"Contributing"},{"location":"contributing/structure/#style","text":"Attributes and methods must be typed according to PEP 484: def method ( a : int , b : float = 1.0 ) -> str : \"\"\"Dummy method. Args: a: first parameter. b: second parameter. Returns: a string. \"\"\" c : float = pow ( b , a ) return str ( c ) To facilitate documentation with mkdocstrings , all comments and docstrings must follow the Google style: https://google.github.io/styleguide/pyguide.html Example: https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html Pylint should never have to complain ;)","title":"Style"},{"location":"contributing/structure/#unit-tests","text":"Find a strategy for consistent unit testing.","title":"Unit tests"},{"location":"contributing/structure/#overview-of-annarchys-structure","text":"Overview of the architecture: api parser generator","title":"Overview of ANNarchy's structure"},{"location":"manual/neuron/","text":"Neuron \u00b6 class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Value ( params [ 'tau' ]) self . V_th = self . Value ( params [ 'V_th' ]) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0","title":"Neuron"},{"location":"manual/neuron/#neuron","text":"class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Value ( params [ 'tau' ]) self . V_th = self . Value ( params [ 'V_th' ]) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0","title":"Neuron"},{"location":"manual/structure/","text":"Structure \u00b6 Networks \u00b6 Everything is inside a Network object to avoid global variables and allow for parallel simulations easily. Populations are created with net.add() , projections with net.connect() . net = Network () pop = net . add ( 100 , Izhikevich ()) proj = net . connect ( pop , pop . ge ) proj . dense ( w = 1.0 ) net . compile () net . simulate ( 1000. ) net . save ( \"data.h5\" ) Networks can be inherited for a better parameterization and to allow finer control of the operations: class BG ( Network ): def __init__ ( self , N ): self . N = N super ( self , BG ) . __init__ ( dt = 1.0 ) def build ( self ): self . striatum = self . add ( N , MSN ()) self . gpi = self . add ( N / 10 , GPI ()) self . gpe = self . add ( N / 10 , GPE ()) self . thal = self . add ( N , Thal ()) self . str_gpi = self . connect ( striatum , gpi . gi , Covariance ) self . str_gpi . dense ( w = 1.0 ) def step ( self ): # Transmission for proj in self . projections (): proj . transmit () # Update neural equations for pop in self . populations (): pop . update () # Update synaptic equations for proj in self . projections () proj . update () Neurons \u00b6 Neurons have to be defined as classes. This allows to pass them default parameter values in the constructor and simplify instantiation of populations: pop1 = net . add ( 100 , Izhikevich ( a = 0.02 )) pop2 = net . add ( 100 , Izhikevich ( a = 0.2 )) There is no explicit distinction between parameters and variables anymore, but between Values and Arrays : Values take a single value for the whole population. Arrays take one value per neuron. An attribute is a variable if it is modified in update() , otherwise it is a parameter... Rate-coded neurons only need to define update() : class RateCoded ( ann . Neuron ): \"\"\" Simple rate-coded neuron. \"\"\" def __init__ ( self , tau ): self . tau = self . Value ( tau ) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) self . r = self . Array ( init = 0.0 ) def update ( self ): # n will contain all variables of the model as sympy symbols, # plus some operations (ite = if/then/else) with self . Equations () as n : # One can declare intermediary variables # that won't be allocated in memory! shunting = n . ite ( n . ge > 1 , n . ge , 0 ) # ODEs use the dX_dt trick n . dv_dt = ( n . ge + shunting + sp . exp ( n . v ** 2 ) - n . v ) / n . tau # Sympy functions can be used directly n . r = sp . tanh ( n . v ) Spiking neuron declares additionally spike() and reset() : class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Value ( params [ 'tau' ]) self . V_th = self . Value ( params [ 'V_th' ]) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0 The Equations() context provides sympy symbols for each value/array of the neuron, plus some specific ones ( t , dt , spike for spike emission, etc). Derivatives are symbolically set as dX_dt . All sympy operations (math C99 ) can be used. Areas \u00b6 We introduce back the notion of Area / node / subnetwork, grouping several populations and their internal connections together: cortical columns reusable ensembles (BG, Hipp) hybrid networks (rate-coded -> spiking, with a specific projection interface) multi-scale networks, using DTI data for long-range connections between reservoirs class BG ( ANNarchy . Area ): def __init__ ( self ): \"Mostly creating the populations and projections.\" self . striatum = self . add ( 1000 , MSN ()) self . gpi = self . add ( 100 , GPI ()) self . gpe = self . add ( 100 , GPE ()) self . thal = self . add ( 100 , Thal ()) self . str_gpi = self . connect ( striatum , gpi . gi , Covariance ) self . str_gpi . dense ( w = 1.0 ) super ( self , BG ) . __init__ () net = Network () cortex = net . add ( 10000 , Cx ()) bg = net . add ( BG ()) cx_bg = net . connect ( cortex , bg . striatum . ge , Corticostriatal ) cx_bg . dense ( w = Normal ( 0.0 , 1.0 ))","title":"Structure"},{"location":"manual/structure/#structure","text":"","title":"Structure"},{"location":"manual/structure/#networks","text":"Everything is inside a Network object to avoid global variables and allow for parallel simulations easily. Populations are created with net.add() , projections with net.connect() . net = Network () pop = net . add ( 100 , Izhikevich ()) proj = net . connect ( pop , pop . ge ) proj . dense ( w = 1.0 ) net . compile () net . simulate ( 1000. ) net . save ( \"data.h5\" ) Networks can be inherited for a better parameterization and to allow finer control of the operations: class BG ( Network ): def __init__ ( self , N ): self . N = N super ( self , BG ) . __init__ ( dt = 1.0 ) def build ( self ): self . striatum = self . add ( N , MSN ()) self . gpi = self . add ( N / 10 , GPI ()) self . gpe = self . add ( N / 10 , GPE ()) self . thal = self . add ( N , Thal ()) self . str_gpi = self . connect ( striatum , gpi . gi , Covariance ) self . str_gpi . dense ( w = 1.0 ) def step ( self ): # Transmission for proj in self . projections (): proj . transmit () # Update neural equations for pop in self . populations (): pop . update () # Update synaptic equations for proj in self . projections () proj . update ()","title":"Networks"},{"location":"manual/structure/#neurons","text":"Neurons have to be defined as classes. This allows to pass them default parameter values in the constructor and simplify instantiation of populations: pop1 = net . add ( 100 , Izhikevich ( a = 0.02 )) pop2 = net . add ( 100 , Izhikevich ( a = 0.2 )) There is no explicit distinction between parameters and variables anymore, but between Values and Arrays : Values take a single value for the whole population. Arrays take one value per neuron. An attribute is a variable if it is modified in update() , otherwise it is a parameter... Rate-coded neurons only need to define update() : class RateCoded ( ann . Neuron ): \"\"\" Simple rate-coded neuron. \"\"\" def __init__ ( self , tau ): self . tau = self . Value ( tau ) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) self . r = self . Array ( init = 0.0 ) def update ( self ): # n will contain all variables of the model as sympy symbols, # plus some operations (ite = if/then/else) with self . Equations () as n : # One can declare intermediary variables # that won't be allocated in memory! shunting = n . ite ( n . ge > 1 , n . ge , 0 ) # ODEs use the dX_dt trick n . dv_dt = ( n . ge + shunting + sp . exp ( n . v ** 2 ) - n . v ) / n . tau # Sympy functions can be used directly n . r = sp . tanh ( n . v ) Spiking neuron declares additionally spike() and reset() : class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Value ( params [ 'tau' ]) self . V_th = self . Value ( params [ 'V_th' ]) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0 The Equations() context provides sympy symbols for each value/array of the neuron, plus some specific ones ( t , dt , spike for spike emission, etc). Derivatives are symbolically set as dX_dt . All sympy operations (math C99 ) can be used.","title":"Neurons"},{"location":"manual/structure/#areas","text":"We introduce back the notion of Area / node / subnetwork, grouping several populations and their internal connections together: cortical columns reusable ensembles (BG, Hipp) hybrid networks (rate-coded -> spiking, with a specific projection interface) multi-scale networks, using DTI data for long-range connections between reservoirs class BG ( ANNarchy . Area ): def __init__ ( self ): \"Mostly creating the populations and projections.\" self . striatum = self . add ( 1000 , MSN ()) self . gpi = self . add ( 100 , GPI ()) self . gpe = self . add ( 100 , GPE ()) self . thal = self . add ( 100 , Thal ()) self . str_gpi = self . connect ( striatum , gpi . gi , Covariance ) self . str_gpi . dense ( w = 1.0 ) super ( self , BG ) . __init__ () net = Network () cortex = net . add ( 10000 , Cx ()) bg = net . add ( BG ()) cx_bg = net . connect ( cortex , bg . striatum . ge , Corticostriatal ) cx_bg . dense ( w = Normal ( 0.0 , 1.0 ))","title":"Areas"}]}