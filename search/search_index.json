{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview \u00b6 About ANNarchy \u00b6 ANNarchy (Artificial Neural Networks architect) is a neural simulator designed for distributed rate-coded or spiking neural networks. The core of the library is written in C++ and distributed using openMP, CUDA and MPI. It provides an interface in Python for the definition of the networks. It is released under the GNU GPL v2 or later . Source code: http://bitbucket.org/annarchy/annarchy Documentation: http://annarchy.readthedocs.io Forum: https://groups.google.com/forum/#!forum/annarchy Bug reports: https://bitbucket.org/annarchy/annarchy/issues Citation If you use ANNarchy for your research, we would appreciate if you cite the following paper: Vitay J, Dinkelbach H\u00dc and Hamker FH (2015). ANNarchy: a code generation approach to neural simulations on parallel hardware. Frontiers in Neuroinformatics 9:19. http://dx.doi.org/10.3389/fninf.2015.00019 Dependencies \u00b6 ANNarchy can be used on any GNU/Linux system, as well as MacOS X. Installation \u00b6 To install the latest stable release of ANNarchy, pip is recommended: pip install ANNarchy To install the latest developement release of ANNarchy, install it from source: git clone http://bitbucket.org/annarchy/annarchy.git cd annarchy/ python setup.py install","title":"Overview"},{"location":"#overview","text":"","title":"Overview"},{"location":"#about-annarchy","text":"ANNarchy (Artificial Neural Networks architect) is a neural simulator designed for distributed rate-coded or spiking neural networks. The core of the library is written in C++ and distributed using openMP, CUDA and MPI. It provides an interface in Python for the definition of the networks. It is released under the GNU GPL v2 or later . Source code: http://bitbucket.org/annarchy/annarchy Documentation: http://annarchy.readthedocs.io Forum: https://groups.google.com/forum/#!forum/annarchy Bug reports: https://bitbucket.org/annarchy/annarchy/issues Citation If you use ANNarchy for your research, we would appreciate if you cite the following paper: Vitay J, Dinkelbach H\u00dc and Hamker FH (2015). ANNarchy: a code generation approach to neural simulations on parallel hardware. Frontiers in Neuroinformatics 9:19. http://dx.doi.org/10.3389/fninf.2015.00019","title":"About ANNarchy"},{"location":"#dependencies","text":"ANNarchy can be used on any GNU/Linux system, as well as MacOS X.","title":"Dependencies"},{"location":"#installation","text":"To install the latest stable release of ANNarchy, pip is recommended: pip install ANNarchy To install the latest developement release of ANNarchy, install it from source: git clone http://bitbucket.org/annarchy/annarchy.git cd annarchy/ python setup.py install","title":"Installation"},{"location":"api/network/","text":"Network \u00b6 Network class containing the complete neural model. Attributes: Name Type Description dt float simulation time step in ms. __init__ ( self , dt = 1.0 , verbose = 1 , logfile = None ) special \u00b6 Constructor of the Network class. The discretization time contant dt is determined at the network-level and should stay constant during the whole simulation. The verbose level specifies which logging messages will be shown: 0 : only errors and exceptions are printed. 1 : errors, exceptions and warnings are displayed (default). 2 : additional information is also displayed (parsing, etc). 3 : debug information is also displayed (which method is entered, variable values, etc...) When logfile is specified, the logging messages will be saved in that file instead of stdout. Parameters: Name Type Description Default dt float simulation step size in ms. 1.0 verbose int logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 1 logfile str file to save the logs. stdout if left empty. None Source code in ANNarchy_future/api/Network.py def __init__ ( self , dt : float = 1.0 , verbose : int = 1 , logfile : str = None ): \"\"\"Constructor of the `Network` class. The discretization time contant `dt` is determined at the network-level and should stay constant during the whole simulation. The `verbose` level specifies which logging messages will be shown: * 0 : only errors and exceptions are printed. * 1 : errors, exceptions and warnings are displayed (default). * 2 : additional information is also displayed (parsing, etc). * 3 : debug information is also displayed (which method is entered, variable values, etc...) When `logfile` is specified, the logging messages will be saved in that file instead of stdout. Args: dt: simulation step size in ms. verbose: logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 logfile: file to save the logs. stdout if left empty. \"\"\" self . dt = dt # Logging module: https://docs.python.org/3/howto/logging.html if logfile is not None : logging . basicConfig ( filename = logfile , level = verbosity_levels [ verbose ]) else : logging . basicConfig ( level = verbosity_levels [ verbose ]) self . logger = logging . getLogger ( __name__ ) self . logger . info ( \"Creating new network with dt=\" + str ( self . dt )) # List of populations self . _populations = [] add ( self , shape , neuron , name = None ) \u00b6 Adds a population to the network. Parameters: Name Type Description Default shape tuple shape of the population as a single integer or tuple. required neuron Neuron Neuron instance. required name str optional name. None Returns: Type Description Population A population instance. Source code in ANNarchy_future/api/Network.py def add ( self , shape : tuple , neuron : Neuron , name : str = None ) -> Population : \"\"\"Adds a population to the network. Args: shape: shape of the population as a single integer or tuple. neuron: Neuron instance. name: optional name. Returns: A population instance. \"\"\" if isinstance ( shape , int ): shape = ( shape ,) # Create the population self . logger . info ( \"Adding Population(\" + str ( shape ) + \", \" + type ( neuron ) . __name__ + \", \" + str ( name ) + \").\" ) pop = Population ( shape , neuron , name ) id_pop = len ( self . _populations ) pop . _register ( self , id_pop ) # Have the population analyse its attributes self . logger . debug ( \"Analysing the population.\" ) pop . _analyse () # Store the population self . _populations . append ( pop ) self . logger . info ( \"Population created.\" ) return pop compile ( self , backend = 'single' ) \u00b6 Compiles and instantiates the network. Parameters: Name Type Description Default backend str choose between 'single' , 'openmp' , 'cuda' or 'mpi' . 'single' Source code in ANNarchy_future/api/Network.py def compile ( self , backend : str = 'single' ): \"\"\" Compiles and instantiates the network. Args: backend: choose between `'single'`, `'openmp'`, `'cuda'` or `'mpi'`. \"\"\" self . _backend = backend # Gather all parsed information description = {} compiler = Compiler ( description , backend = backend ) # Sanity check ? compiler . sanity_check () # Code generation self . _simulation_core = compiler . compile () # Instantiate the network self . _instantiate () self . _obj_ids = self . _simulation_core . _instantiate ()","title":"Network"},{"location":"api/network/#network","text":"Network class containing the complete neural model. Attributes: Name Type Description dt float simulation time step in ms.","title":"Network"},{"location":"api/network/#ANNarchy_future.api.Network.Network.__init__","text":"Constructor of the Network class. The discretization time contant dt is determined at the network-level and should stay constant during the whole simulation. The verbose level specifies which logging messages will be shown: 0 : only errors and exceptions are printed. 1 : errors, exceptions and warnings are displayed (default). 2 : additional information is also displayed (parsing, etc). 3 : debug information is also displayed (which method is entered, variable values, etc...) When logfile is specified, the logging messages will be saved in that file instead of stdout. Parameters: Name Type Description Default dt float simulation step size in ms. 1.0 verbose int logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 1 logfile str file to save the logs. stdout if left empty. None Source code in ANNarchy_future/api/Network.py def __init__ ( self , dt : float = 1.0 , verbose : int = 1 , logfile : str = None ): \"\"\"Constructor of the `Network` class. The discretization time contant `dt` is determined at the network-level and should stay constant during the whole simulation. The `verbose` level specifies which logging messages will be shown: * 0 : only errors and exceptions are printed. * 1 : errors, exceptions and warnings are displayed (default). * 2 : additional information is also displayed (parsing, etc). * 3 : debug information is also displayed (which method is entered, variable values, etc...) When `logfile` is specified, the logging messages will be saved in that file instead of stdout. Args: dt: simulation step size in ms. verbose: logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 logfile: file to save the logs. stdout if left empty. \"\"\" self . dt = dt # Logging module: https://docs.python.org/3/howto/logging.html if logfile is not None : logging . basicConfig ( filename = logfile , level = verbosity_levels [ verbose ]) else : logging . basicConfig ( level = verbosity_levels [ verbose ]) self . logger = logging . getLogger ( __name__ ) self . logger . info ( \"Creating new network with dt=\" + str ( self . dt )) # List of populations self . _populations = []","title":"__init__()"},{"location":"api/network/#ANNarchy_future.api.Network.Network.add","text":"Adds a population to the network. Parameters: Name Type Description Default shape tuple shape of the population as a single integer or tuple. required neuron Neuron Neuron instance. required name str optional name. None Returns: Type Description Population A population instance. Source code in ANNarchy_future/api/Network.py def add ( self , shape : tuple , neuron : Neuron , name : str = None ) -> Population : \"\"\"Adds a population to the network. Args: shape: shape of the population as a single integer or tuple. neuron: Neuron instance. name: optional name. Returns: A population instance. \"\"\" if isinstance ( shape , int ): shape = ( shape ,) # Create the population self . logger . info ( \"Adding Population(\" + str ( shape ) + \", \" + type ( neuron ) . __name__ + \", \" + str ( name ) + \").\" ) pop = Population ( shape , neuron , name ) id_pop = len ( self . _populations ) pop . _register ( self , id_pop ) # Have the population analyse its attributes self . logger . debug ( \"Analysing the population.\" ) pop . _analyse () # Store the population self . _populations . append ( pop ) self . logger . info ( \"Population created.\" ) return pop","title":"add()"},{"location":"api/network/#ANNarchy_future.api.Network.Network.compile","text":"Compiles and instantiates the network. Parameters: Name Type Description Default backend str choose between 'single' , 'openmp' , 'cuda' or 'mpi' . 'single' Source code in ANNarchy_future/api/Network.py def compile ( self , backend : str = 'single' ): \"\"\" Compiles and instantiates the network. Args: backend: choose between `'single'`, `'openmp'`, `'cuda'` or `'mpi'`. \"\"\" self . _backend = backend # Gather all parsed information description = {} compiler = Compiler ( description , backend = backend ) # Sanity check ? compiler . sanity_check () # Code generation self . _simulation_core = compiler . compile () # Instantiate the network self . _instantiate () self . _obj_ids = self . _simulation_core . _instantiate ()","title":"compile()"},{"location":"api/neuron/","text":"Neuron \u00b6 Abstract class defining single neurons. TODO Array ( self , init = 0.0 , dtype =< class ' numpy . float32 '>) \u00b6 Defines an Array for the neuron. Arrays can take a different value for each neuron in the population. If a single value is needed, use Value to save some memory. Parameters: Name Type Description Default value initial value. required dtype numpy type of the value (e.g. np.int, np.float) <class 'numpy.float32'> Returns: Type Description Array Value instance. Source code in ANNarchy_future/api/Neuron.py def Array ( self , init : float = 0.0 , dtype = np . float32 ) -> Array : \"\"\"Defines an Array for the neuron. Arrays can take a different value for each neuron in the population. If a single value is needed, use `Value` to save some memory. Args: value: initial value. dtype: numpy type of the value (e.g. np.int, np.float) Returns: `Value` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = Array ( init , dtype ) self . _data . append ( val ) return val Equations ( self ) \u00b6 Returns an Equations context. with self . Equations () as n : n . dr_dt = ( n . ge - n . r ) / n . tau When opening the context as n , the variable has all attributes (values and arrays) of the neuron as symbols, which can be combined in Sympy equations. Source code in ANNarchy_future/api/Neuron.py def Equations ( self ): \"\"\"Returns an Equations context. ```python with self.Equations() as n: n.dr_dt = (n.ge - n.r)/n.tau ``` When opening the context as `n`, the variable has all attributes (values and arrays) of the neuron as symbols, which can be combined in Sympy equations. \"\"\" eq = Equations ( neuron = self ) self . _current_eq = eq return eq Value ( self , value , dtype =< class ' numpy . float32 '>) \u00b6 Defines a Value for the neuron. Values are defined only once for the whole population. If each neuron should have different values, use an Array instead. Parameters: Name Type Description Default value float initial value. required dtype numpy type of the value (e.g. np.int, np.float) <class 'numpy.float32'> Returns: Type Description Value Value instance. Source code in ANNarchy_future/api/Neuron.py def Value ( self , value : float , dtype = np . float32 ) -> Value : \"\"\"Defines a Value for the neuron. Values are defined only once for the whole population. If each neuron should have different values, use an `Array` instead. Args: value: initial value. dtype: numpy type of the value (e.g. np.int, np.float) Returns: `Value` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = Value ( value , dtype ) self . _data . append ( val ) return val","title":"Neuron"},{"location":"api/neuron/#neuron","text":"Abstract class defining single neurons. TODO","title":"Neuron"},{"location":"api/neuron/#ANNarchy_future.api.Neuron.Neuron.Array","text":"Defines an Array for the neuron. Arrays can take a different value for each neuron in the population. If a single value is needed, use Value to save some memory. Parameters: Name Type Description Default value initial value. required dtype numpy type of the value (e.g. np.int, np.float) <class 'numpy.float32'> Returns: Type Description Array Value instance. Source code in ANNarchy_future/api/Neuron.py def Array ( self , init : float = 0.0 , dtype = np . float32 ) -> Array : \"\"\"Defines an Array for the neuron. Arrays can take a different value for each neuron in the population. If a single value is needed, use `Value` to save some memory. Args: value: initial value. dtype: numpy type of the value (e.g. np.int, np.float) Returns: `Value` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = Array ( init , dtype ) self . _data . append ( val ) return val","title":"Array()"},{"location":"api/neuron/#ANNarchy_future.api.Neuron.Neuron.Equations","text":"Returns an Equations context. with self . Equations () as n : n . dr_dt = ( n . ge - n . r ) / n . tau When opening the context as n , the variable has all attributes (values and arrays) of the neuron as symbols, which can be combined in Sympy equations. Source code in ANNarchy_future/api/Neuron.py def Equations ( self ): \"\"\"Returns an Equations context. ```python with self.Equations() as n: n.dr_dt = (n.ge - n.r)/n.tau ``` When opening the context as `n`, the variable has all attributes (values and arrays) of the neuron as symbols, which can be combined in Sympy equations. \"\"\" eq = Equations ( neuron = self ) self . _current_eq = eq return eq","title":"Equations()"},{"location":"api/neuron/#ANNarchy_future.api.Neuron.Neuron.Value","text":"Defines a Value for the neuron. Values are defined only once for the whole population. If each neuron should have different values, use an Array instead. Parameters: Name Type Description Default value float initial value. required dtype numpy type of the value (e.g. np.int, np.float) <class 'numpy.float32'> Returns: Type Description Value Value instance. Source code in ANNarchy_future/api/Neuron.py def Value ( self , value : float , dtype = np . float32 ) -> Value : \"\"\"Defines a Value for the neuron. Values are defined only once for the whole population. If each neuron should have different values, use an `Array` instead. Args: value: initial value. dtype: numpy type of the value (e.g. np.int, np.float) Returns: `Value` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = Value ( value , dtype ) self . _data . append ( val ) return val","title":"Value()"},{"location":"api/population/","text":"Population \u00b6 Population \u00b6 Population of neurons. Populations should not be created explicitly, but returned by Network.add() : net = Network () pop = net . add ( 10 , LIF ()) Attributes: Name Type Description shape tuple shape of the population. size int number of neurons. name str unique name of the population. neuron_class name of the Neuron class Additionaly, all values and arrays of the neuron type are accessible as attributes: class Leaky ( Neuron ): def __init__ ( self ): self . tau = self . Value ( 20. ) self . r = self . Array ( 0.0 ) net = Network () pop = net . add ( 10 , Leaky ()) print ( pop . tau ) # 20. print ( pop . r ) # [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] is_spiking ( self ) \u00b6 Returns True if the neuron type is spiking. Source code in ANNarchy_future/api/Population.py def is_spiking ( self ) -> bool : \"Returns True if the neuron type is spiking.\" return self . _neuron_type . is_spiking ()","title":"Population"},{"location":"api/population/#population","text":"","title":"Population"},{"location":"api/population/#ANNarchy_future.api.Population.Population","text":"Population of neurons. Populations should not be created explicitly, but returned by Network.add() : net = Network () pop = net . add ( 10 , LIF ()) Attributes: Name Type Description shape tuple shape of the population. size int number of neurons. name str unique name of the population. neuron_class name of the Neuron class Additionaly, all values and arrays of the neuron type are accessible as attributes: class Leaky ( Neuron ): def __init__ ( self ): self . tau = self . Value ( 20. ) self . r = self . Array ( 0.0 ) net = Network () pop = net . add ( 10 , Leaky ()) print ( pop . tau ) # 20. print ( pop . r ) # [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]","title":"Population"},{"location":"api/population/#ANNarchy_future.api.Population.Population.is_spiking","text":"Returns True if the neuron type is spiking. Source code in ANNarchy_future/api/Population.py def is_spiking ( self ) -> bool : \"Returns True if the neuron type is spiking.\" return self . _neuron_type . is_spiking ()","title":"is_spiking()"},{"location":"contributing/parser/","text":"Parser \u00b6 Equations \u00b6 Context to define equations. It should be primarily used inside a Neuron or Synapse class, but can also be used in a standalone mode by providing a list of attributes: with Equations ( symbols = [ 'tau' , 'v' , 'r' ]) as n : n . dv_dt = ( n . cast ( 1.0 ) - n . v ) / n . tau n . r = sp . tanh ( n . v ) print ( n ) __init__ ( self , symbols = None , neuron = None , synapse = None ) special \u00b6 Creates the Equations context. Parameters: Name Type Description Default symbols list list of attributes when in standalone mode. None neuron Neuron instance (passed by the population). None synapse Synapse instance (passed by the projection). None Source code in ANNarchy_future/parser/Equations.py def __init__ ( self , symbols : list = None , neuron = None , synapse = None ): \"\"\"Creates the Equations context. Args: symbols: list of attributes when in standalone mode. neuron: Neuron instance (passed by the population). synapse: Synapse instance (passed by the projection). \"\"\" self . logger = logging . getLogger ( __name__ ) self . logger . info ( \"Equations() created.\" ) self . neuron = neuron self . synapse = synapse self . symbols = { 't' : sp . Symbol ( \"t\" ), 'dt' : sp . Symbol ( \"dt\" ), 'spike' : sp . Symbol ( \"spike\" ), } if self . neuron is None and self . synapse is None : self . _custom_symbols = symbols self . logger . info ( \"Custom symbols: \" + str ( symbols )) self . equations = [] self . _started = False cast ( self , val ) \u00b6 Cast floating point numbers to symbols in order to avoid numerical errors. Parameters: Name Type Description Default val float required Source code in ANNarchy_future/parser/Equations.py def cast ( self , val : float ) -> sp . Symbol : \"\"\"Cast floating point numbers to symbols in order to avoid numerical errors. Args: val (float): \"\"\" return sp . Symbol ( str ( float ( val ))) ite ( self , cond , then , els ) \u00b6 If-then-else ternary condition. Equivalent to: def ite ( cond , then , els ): if cond : return then else : return els Args: cond: condition. then: returned value when cond is true. else: returned value when cond is false. Source code in ANNarchy_future/parser/Equations.py def ite ( self , cond , then , els ): \"\"\"If-then-else ternary condition. Equivalent to: ```python def ite(cond, then, els): if cond: return then else: return els ``` Args: cond: condition. then: returned value when cond is true. else: returned value when cond is false. \"\"\" return sp . Piecewise (( then , cond ), ( els , True )) NeuronParser \u00b6 Neuron parser. Attributes: Name Type Description neuron Neuron Neuron class name str name of the Neuron class attributes list list of attributes (values and arrays) values list list of values arrays list list of arrays update_equations list update equations. spike_condition list spike condition. reset_equations list reset equations. __init__ ( self , neuron ) special \u00b6 Initializes the parser. Sets: self.neuron self.name Source code in ANNarchy_future/parser/NeuronParser.py def __init__ ( self , neuron : Neuron ): \"\"\"Initializes the parser. Sets: * `self.neuron` * `self.name` \"\"\" self . neuron = neuron self . _spiking = False self . name = self . neuron . __class__ . __name__ # Logging self . logger = logging . getLogger ( __name__ ) self . logger . debug ( \"Neuron parser created.\" ) # Attributes self . attributes = [] self . values = [] self . arrays = [] # Equations to retrieve self . update_equations = None self . spike_condition = None self . reset_equations = None analyse_equations ( self ) \u00b6 Analyses the neuron equations. Calls update(), spike() and reset() to retrieve the Equations objects. Sets: self.update_equations self.spike_condition self.reset_equations Source code in ANNarchy_future/parser/NeuronParser.py def analyse_equations ( self ): \"\"\"Analyses the neuron equations. Calls update(), spike() and reset() to retrieve the `Equations` objects. Sets: * `self.update_equations` * `self.spike_condition` * `self.reset_equations` \"\"\" # List of methods callables = [ f for f in dir ( self . neuron ) if callable ( getattr ( self . neuron , f ))] if not 'update' in callables : self . logger . error ( \"The Neuron class must implement update(self)\" ) sys . exit ( 1 ) # Analyse update() self . logger . info ( \"Calling Neuron.update().\" ) try : self . neuron . update () except Exception : self . logger . exception ( \"Unable to analyse update()\" ) sys . exit ( 1 ) self . update_equations = self . neuron . _current_eq # For spiking neurons only if 'spike' in callables : self . logger . info ( \"Neuron has a spike() method.\" ) self . _spiking = True self . logger . info ( \"Calling Neuron.spike().\" ) # Analyse spike() try : self . neuron . spike () except Exception : self . logger . exception ( \"Unable to analyse spike()\" ) sys . exit ( 1 ) self . spike_condition = self . neuron . _current_eq # Analyse reset() self . logger . info ( \"Calling Neuron.reset().\" ) try : self . neuron . reset () except Exception : self . logger . exception ( \"Unable to analyse reset()\" ) sys . exit ( 1 ) self . reset_equations = self . neuron . _current_eq extract_variables ( self ) \u00b6 Iterates over neuron.__dict__ and extracts all Value() and Array() instances. Sets: self._spiking self.attributes self.values self.arrays Source code in ANNarchy_future/parser/NeuronParser.py def extract_variables ( self ): \"\"\"Iterates over `neuron.__dict__` and extracts all `Value()` and `Array()` instances. Sets: * `self._spiking` * `self.attributes` * `self.values` * `self.arrays` \"\"\" # List attributes current_attributes = list ( self . neuron . __dict__ . keys ()) for attr in current_attributes : if isinstance ( getattr ( self . neuron , attr ), ( Value , )): self . values . append ( attr ) self . attributes . append ( attr ) if isinstance ( getattr ( self . neuron , attr ), ( Array , )): self . arrays . append ( attr ) self . attributes . append ( attr ) # Get lists of values and arrays self . logger . info ( \"Attributes: \" + str ( self . attributes )) self . logger . info ( \"Values: \" + str ( self . values )) self . logger . info ( \"Arrays: \" + str ( self . arrays )) # Set the attributes to the neuron self . neuron . attributes = self . attributes self . neuron . _values_list = self . values self . neuron . _arrays_list = self . arrays is_spiking ( self ) \u00b6 Returns True if the Neuron class is spiking. Source code in ANNarchy_future/parser/NeuronParser.py def is_spiking ( self ): \"Returns True if the Neuron class is spiking.\" return self . _spiking","title":"Parser"},{"location":"contributing/parser/#parser","text":"","title":"Parser"},{"location":"contributing/parser/#ANNarchy_future.parser.Equations.Equations","text":"Context to define equations. It should be primarily used inside a Neuron or Synapse class, but can also be used in a standalone mode by providing a list of attributes: with Equations ( symbols = [ 'tau' , 'v' , 'r' ]) as n : n . dv_dt = ( n . cast ( 1.0 ) - n . v ) / n . tau n . r = sp . tanh ( n . v ) print ( n )","title":"Equations"},{"location":"contributing/parser/#ANNarchy_future.parser.Equations.Equations.__init__","text":"Creates the Equations context. Parameters: Name Type Description Default symbols list list of attributes when in standalone mode. None neuron Neuron instance (passed by the population). None synapse Synapse instance (passed by the projection). None Source code in ANNarchy_future/parser/Equations.py def __init__ ( self , symbols : list = None , neuron = None , synapse = None ): \"\"\"Creates the Equations context. Args: symbols: list of attributes when in standalone mode. neuron: Neuron instance (passed by the population). synapse: Synapse instance (passed by the projection). \"\"\" self . logger = logging . getLogger ( __name__ ) self . logger . info ( \"Equations() created.\" ) self . neuron = neuron self . synapse = synapse self . symbols = { 't' : sp . Symbol ( \"t\" ), 'dt' : sp . Symbol ( \"dt\" ), 'spike' : sp . Symbol ( \"spike\" ), } if self . neuron is None and self . synapse is None : self . _custom_symbols = symbols self . logger . info ( \"Custom symbols: \" + str ( symbols )) self . equations = [] self . _started = False","title":"__init__()"},{"location":"contributing/parser/#ANNarchy_future.parser.Equations.Equations.cast","text":"Cast floating point numbers to symbols in order to avoid numerical errors. Parameters: Name Type Description Default val float required Source code in ANNarchy_future/parser/Equations.py def cast ( self , val : float ) -> sp . Symbol : \"\"\"Cast floating point numbers to symbols in order to avoid numerical errors. Args: val (float): \"\"\" return sp . Symbol ( str ( float ( val )))","title":"cast()"},{"location":"contributing/parser/#ANNarchy_future.parser.Equations.Equations.ite","text":"If-then-else ternary condition. Equivalent to: def ite ( cond , then , els ): if cond : return then else : return els Args: cond: condition. then: returned value when cond is true. else: returned value when cond is false. Source code in ANNarchy_future/parser/Equations.py def ite ( self , cond , then , els ): \"\"\"If-then-else ternary condition. Equivalent to: ```python def ite(cond, then, els): if cond: return then else: return els ``` Args: cond: condition. then: returned value when cond is true. else: returned value when cond is false. \"\"\" return sp . Piecewise (( then , cond ), ( els , True ))","title":"ite()"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser","text":"Neuron parser. Attributes: Name Type Description neuron Neuron Neuron class name str name of the Neuron class attributes list list of attributes (values and arrays) values list list of values arrays list list of arrays update_equations list update equations. spike_condition list spike condition. reset_equations list reset equations.","title":"NeuronParser"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.__init__","text":"Initializes the parser. Sets: self.neuron self.name Source code in ANNarchy_future/parser/NeuronParser.py def __init__ ( self , neuron : Neuron ): \"\"\"Initializes the parser. Sets: * `self.neuron` * `self.name` \"\"\" self . neuron = neuron self . _spiking = False self . name = self . neuron . __class__ . __name__ # Logging self . logger = logging . getLogger ( __name__ ) self . logger . debug ( \"Neuron parser created.\" ) # Attributes self . attributes = [] self . values = [] self . arrays = [] # Equations to retrieve self . update_equations = None self . spike_condition = None self . reset_equations = None","title":"__init__()"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.analyse_equations","text":"Analyses the neuron equations. Calls update(), spike() and reset() to retrieve the Equations objects. Sets: self.update_equations self.spike_condition self.reset_equations Source code in ANNarchy_future/parser/NeuronParser.py def analyse_equations ( self ): \"\"\"Analyses the neuron equations. Calls update(), spike() and reset() to retrieve the `Equations` objects. Sets: * `self.update_equations` * `self.spike_condition` * `self.reset_equations` \"\"\" # List of methods callables = [ f for f in dir ( self . neuron ) if callable ( getattr ( self . neuron , f ))] if not 'update' in callables : self . logger . error ( \"The Neuron class must implement update(self)\" ) sys . exit ( 1 ) # Analyse update() self . logger . info ( \"Calling Neuron.update().\" ) try : self . neuron . update () except Exception : self . logger . exception ( \"Unable to analyse update()\" ) sys . exit ( 1 ) self . update_equations = self . neuron . _current_eq # For spiking neurons only if 'spike' in callables : self . logger . info ( \"Neuron has a spike() method.\" ) self . _spiking = True self . logger . info ( \"Calling Neuron.spike().\" ) # Analyse spike() try : self . neuron . spike () except Exception : self . logger . exception ( \"Unable to analyse spike()\" ) sys . exit ( 1 ) self . spike_condition = self . neuron . _current_eq # Analyse reset() self . logger . info ( \"Calling Neuron.reset().\" ) try : self . neuron . reset () except Exception : self . logger . exception ( \"Unable to analyse reset()\" ) sys . exit ( 1 ) self . reset_equations = self . neuron . _current_eq","title":"analyse_equations()"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.extract_variables","text":"Iterates over neuron.__dict__ and extracts all Value() and Array() instances. Sets: self._spiking self.attributes self.values self.arrays Source code in ANNarchy_future/parser/NeuronParser.py def extract_variables ( self ): \"\"\"Iterates over `neuron.__dict__` and extracts all `Value()` and `Array()` instances. Sets: * `self._spiking` * `self.attributes` * `self.values` * `self.arrays` \"\"\" # List attributes current_attributes = list ( self . neuron . __dict__ . keys ()) for attr in current_attributes : if isinstance ( getattr ( self . neuron , attr ), ( Value , )): self . values . append ( attr ) self . attributes . append ( attr ) if isinstance ( getattr ( self . neuron , attr ), ( Array , )): self . arrays . append ( attr ) self . attributes . append ( attr ) # Get lists of values and arrays self . logger . info ( \"Attributes: \" + str ( self . attributes )) self . logger . info ( \"Values: \" + str ( self . values )) self . logger . info ( \"Arrays: \" + str ( self . arrays )) # Set the attributes to the neuron self . neuron . attributes = self . attributes self . neuron . _values_list = self . values self . neuron . _arrays_list = self . arrays","title":"extract_variables()"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.is_spiking","text":"Returns True if the Neuron class is spiking. Source code in ANNarchy_future/parser/NeuronParser.py def is_spiking ( self ): \"Returns True if the Neuron class is spiking.\" return self . _spiking","title":"is_spiking()"},{"location":"contributing/structure/","text":"Structure \u00b6","title":"Structure"},{"location":"contributing/structure/#structure","text":"","title":"Structure"},{"location":"manual/neuron/","text":"Neuron \u00b6 class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Value ( params [ 'tau' ]) self . V_th = self . Value ( params [ 'V_th' ]) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0","title":"Neuron"},{"location":"manual/neuron/#neuron","text":"class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Value ( params [ 'tau' ]) self . V_th = self . Value ( params [ 'V_th' ]) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0","title":"Neuron"},{"location":"manual/structure/","text":"Structure \u00b6 Networks \u00b6 Everything is inside a Network object to avoid global variables and allow for parallel simulations easily. Populations are created with net.add() , projections with net.connect() . net = Network () pop = net . add ( 100 , Izhikevich ()) proj = net . connect ( pop , pop . ge ) proj . dense ( w = 1.0 ) net . compile () net . simulate ( 1000. ) net . save ( \"data.h5\" ) Neurons \u00b6 Neurons have to be defined as classes. This allows to pass them default parameter values in the constructor and simplify instantiation of populations: pop1 = net . add ( 100 , Izhikevich ( a = 0.02 )) pop2 = net . add ( 100 , Izhikevich ( a = 0.2 )) There is no explicit distinction between parameters and variables anymore, but between Values and Arrays : Values take a single value for the whole population. Arrays take one value per neuron. An attribute is a variable if it is modified in update() , otherwise it is a parameter... Rate-coded neurons only need to define update() : class RateCoded ( ann . Neuron ): \"\"\" Simple rate-coded neuron. \"\"\" def __init__ ( self , tau ): self . tau = self . Value ( tau ) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) self . r = self . Array ( init = 0.0 ) def update ( self ): # n will contain all variables of the model as sympy symbols, # plus some operations (ite = if/then/else) with self . Equations () as n : # One can declare intermediary variables # that won't be allocated in memory! shunting = n . ite ( n . ge > 1 , n . ge , 0 ) # ODEs use the dX_dt trick n . dv_dt = ( n . ge + shunting + sp . exp ( n . v ** 2 ) - n . v ) / n . tau # Sympy functions can be used directly n . r = sp . tanh ( n . v ) Spiking neuron declares additionally spike() and reset() : class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Value ( params [ 'tau' ]) self . V_th = self . Value ( params [ 'V_th' ]) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0 The Equations() context provides sympy symbols for each value/array of the neuron, plus some specific ones ( t , dt , spike for spike emission, etc). Derivatives are symbolically set as dX_dt . All sympy operations (math C99 ) can be used. Areas \u00b6 We introduce back the notion of Area / node / subnetwork, grouping several populations and their internal connections together: cortical columns reusable ensembles (BG, Hipp) hybrid networks (rate-coded -> spiking, with a specific projection interface) multi-scale networks, using DTI data for long-range connections between reservoirs class BG ( ANNarchy . Area ): def __init__ ( self ): \"Mostly creating the populations and projections.\" self . striatum = self . add ( 1000 , MSN ()) self . gpi = self . add ( 100 , GPI ()) self . gpe = self . add ( 100 , GPE ()) self . thal = self . add ( 100 , Thal ()) self . str_gpi = self . connect ( striatum , gpi . gi , Covariance ) self . str_gpi . dense ( w = 1.0 ) super ( self , BG ) . __init__ () net = Network () cortex = net . add ( 10000 , Cx ()) bg = net . add ( BG ()) cx_bg = net . connect ( cortex , bg . striatum . ge , Corticostriatal ) cx_bg . dense ( w = Normal ( 0.0 , 1.0 ))","title":"Structure"},{"location":"manual/structure/#structure","text":"","title":"Structure"},{"location":"manual/structure/#networks","text":"Everything is inside a Network object to avoid global variables and allow for parallel simulations easily. Populations are created with net.add() , projections with net.connect() . net = Network () pop = net . add ( 100 , Izhikevich ()) proj = net . connect ( pop , pop . ge ) proj . dense ( w = 1.0 ) net . compile () net . simulate ( 1000. ) net . save ( \"data.h5\" )","title":"Networks"},{"location":"manual/structure/#neurons","text":"Neurons have to be defined as classes. This allows to pass them default parameter values in the constructor and simplify instantiation of populations: pop1 = net . add ( 100 , Izhikevich ( a = 0.02 )) pop2 = net . add ( 100 , Izhikevich ( a = 0.2 )) There is no explicit distinction between parameters and variables anymore, but between Values and Arrays : Values take a single value for the whole population. Arrays take one value per neuron. An attribute is a variable if it is modified in update() , otherwise it is a parameter... Rate-coded neurons only need to define update() : class RateCoded ( ann . Neuron ): \"\"\" Simple rate-coded neuron. \"\"\" def __init__ ( self , tau ): self . tau = self . Value ( tau ) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) self . r = self . Array ( init = 0.0 ) def update ( self ): # n will contain all variables of the model as sympy symbols, # plus some operations (ite = if/then/else) with self . Equations () as n : # One can declare intermediary variables # that won't be allocated in memory! shunting = n . ite ( n . ge > 1 , n . ge , 0 ) # ODEs use the dX_dt trick n . dv_dt = ( n . ge + shunting + sp . exp ( n . v ** 2 ) - n . v ) / n . tau # Sympy functions can be used directly n . r = sp . tanh ( n . v ) Spiking neuron declares additionally spike() and reset() : class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Value ( params [ 'tau' ]) self . V_th = self . Value ( params [ 'V_th' ]) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0 The Equations() context provides sympy symbols for each value/array of the neuron, plus some specific ones ( t , dt , spike for spike emission, etc). Derivatives are symbolically set as dX_dt . All sympy operations (math C99 ) can be used.","title":"Neurons"},{"location":"manual/structure/#areas","text":"We introduce back the notion of Area / node / subnetwork, grouping several populations and their internal connections together: cortical columns reusable ensembles (BG, Hipp) hybrid networks (rate-coded -> spiking, with a specific projection interface) multi-scale networks, using DTI data for long-range connections between reservoirs class BG ( ANNarchy . Area ): def __init__ ( self ): \"Mostly creating the populations and projections.\" self . striatum = self . add ( 1000 , MSN ()) self . gpi = self . add ( 100 , GPI ()) self . gpe = self . add ( 100 , GPE ()) self . thal = self . add ( 100 , Thal ()) self . str_gpi = self . connect ( striatum , gpi . gi , Covariance ) self . str_gpi . dense ( w = 1.0 ) super ( self , BG ) . __init__ () net = Network () cortex = net . add ( 10000 , Cx ()) bg = net . add ( BG ()) cx_bg = net . connect ( cortex , bg . striatum . ge , Corticostriatal ) cx_bg . dense ( w = Normal ( 0.0 , 1.0 ))","title":"Areas"}]}