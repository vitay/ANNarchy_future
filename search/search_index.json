{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ANNarchy \u00b6 This is a mockup, do not use. About ANNarchy \u00b6 ANNarchy (Artificial Neural Networks architect) is a neural simulator designed for distributed rate-coded or spiking neural networks. The core of the library is written in C++ and distributed using openMP, CUDA and MPI. It provides an interface in Python for the definition of the networks. It is released under the MIT license . Source code: http://bitbucket.org/annarchy/annarchy Documentation: http://annarchy.readthedocs.io Forum: https://groups.google.com/forum/#!forum/annarchy Bug reports: https://bitbucket.org/annarchy/annarchy/issues Citation If you use ANNarchy for your research, we would appreciate if you cite the following paper: Vitay J, Dinkelbach H\u00dc and Hamker FH (2015). ANNarchy: a code generation approach to neural simulations on parallel hardware. Frontiers in Neuroinformatics 9:19. http://dx.doi.org/10.3389/fninf.2015.00019 Installation \u00b6 To install the latest stable release of ANNarchy, pip is recommended: pip install ANNarchy To install the latest developement release of ANNarchy, install it from source: git clone http://bitbucket.org/annarchy/annarchy.git cd annarchy/ python setup.py install","title":"ANNarchy"},{"location":"#annarchy","text":"This is a mockup, do not use.","title":"ANNarchy"},{"location":"#about-annarchy","text":"ANNarchy (Artificial Neural Networks architect) is a neural simulator designed for distributed rate-coded or spiking neural networks. The core of the library is written in C++ and distributed using openMP, CUDA and MPI. It provides an interface in Python for the definition of the networks. It is released under the MIT license . Source code: http://bitbucket.org/annarchy/annarchy Documentation: http://annarchy.readthedocs.io Forum: https://groups.google.com/forum/#!forum/annarchy Bug reports: https://bitbucket.org/annarchy/annarchy/issues Citation If you use ANNarchy for your research, we would appreciate if you cite the following paper: Vitay J, Dinkelbach H\u00dc and Hamker FH (2015). ANNarchy: a code generation approach to neural simulations on parallel hardware. Frontiers in Neuroinformatics 9:19. http://dx.doi.org/10.3389/fninf.2015.00019","title":"About ANNarchy"},{"location":"#installation","text":"To install the latest stable release of ANNarchy, pip is recommended: pip install ANNarchy To install the latest developement release of ANNarchy, install it from source: git clone http://bitbucket.org/annarchy/annarchy.git cd annarchy/ python setup.py install","title":"Installation"},{"location":"CHANGELOG/","text":"Changelog \u00b6 5.0.0 (18.03.21) \u00b6 Initial release.","title":"Changelog"},{"location":"CHANGELOG/#changelog","text":"","title":"Changelog"},{"location":"CHANGELOG/#500-180321","text":"Initial release.","title":"5.0.0 (18.03.21)"},{"location":"License/","text":"License \u00b6 Copyright 2021- Julien Vitay, Helge \u00dclo Dinkelbach, Fred H. Hamker Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"License/#license","text":"Copyright 2021- Julien Vitay, Helge \u00dclo Dinkelbach, Fred H. Hamker Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"api/equations/","text":"Equations \u00b6 Context to define equations. It should be primarily used inside a Neuron or Synapse class, but can also be used in a standalone mode by providing a list of attributes: with Equations ( symbols = [ 'tau' , 'v' , 'r' ]) as n : n . dv_dt = ( n . cast ( 0.04 ) - n . v ) / n . tau n . r = sp . tanh ( n . v ) print ( n ) __init__ ( self , symbols = None , method = 'euler' , neuron = None , synapse = None ) special \u00b6 Creates the Equations context. Parameters: Name Type Description Default symbols list list of attributes when in standalone mode. None method str numerical method (euler, midpoint, exponential, rk4, event-driven) 'euler' neuron Neuron instance (passed by the population). None synapse Synapse instance (passed by the projection). None Source code in ANNarchy_future/parser/Equations.py def __init__ ( self , symbols : list = None , method : str = 'euler' , neuron = None , synapse = None ): \"\"\"Creates the Equations context. Args: symbols: list of attributes when in standalone mode. method: numerical method (euler, midpoint, exponential, rk4, event-driven) neuron: Neuron instance (passed by the population). synapse: Synapse instance (passed by the projection). \"\"\" # Logger self . _logger = logging . getLogger ( __name__ ) self . _logger . debug ( \"Equations() created.\" ) # Objects self . _neuron = neuron self . _synapse = synapse # Numerical method self . method = method # Built-in symbols self . symbols = parser . symbols_dict . copy () # Standalone mode if self . _neuron is None and self . _synapse is None : self . _custom_symbols = symbols self . _logger . info ( \"Custom symbols: \" + str ( symbols )) # List of tuples (name, Equation) self . equations = [] # Start recording assignments self . _started = False cast ( self , val ) \u00b6 Cast floating point numbers to symbols in order to avoid numerical errors. Parameters: Name Type Description Default val float required Source code in ANNarchy_future/parser/Equations.py def cast ( self , val : float ) -> sp . Symbol : \"\"\"Cast floating point numbers to symbols in order to avoid numerical errors. Args: val (float): \"\"\" return sp . Symbol ( str ( float ( val ))) clip ( self , val , min , max = None ) \u00b6 Sets the lower and upper bounds of a variable. Equivalent to: def clip ( val , min , max ): if val < min : return min elif val > max : return max else : return val Args: val: variable. min: lower bound. max: upper bound. Source code in ANNarchy_future/parser/Equations.py def clip ( self , val : sp . Symbol , min : sp . Symbol , max : sp . Symbol = None ): \"\"\"Sets the lower and upper bounds of a variable. Equivalent to: ```python def clip(val, min, max): if val < min: return min elif val > max: return max else: return val ``` Args: val: variable. min: lower bound. max: upper bound. \"\"\" if min is None and max is None : # Do nothing return val elif min is not None and max is None : # Lower bound return sp . Piecewise (( min , val < min ), ( val , True )) elif min is None and max is not None : # Upper bound return sp . Piecewise (( max , val > max ), ( val , True )) else : # Two-sided clip return sp . Piecewise (( min , val < min ), ( max , val > max ), ( val , True )) ite ( self , cond , then , els ) \u00b6 If-then-else ternary operator. Equivalent to: def ite ( cond , then , els ): if cond : return then else : return els Args: cond: condition. then: returned value when cond is true. else: returned value when cond is false. Source code in ANNarchy_future/parser/Equations.py def ite ( self , cond , then , els ): \"\"\"If-then-else ternary operator. Equivalent to: ```python def ite(cond, then, els): if cond: return then else: return els ``` Args: cond: condition. then: returned value when cond is true. else: returned value when cond is false. \"\"\" return sp . Piecewise (( then , cond ), ( els , True ))","title":"Equations"},{"location":"api/equations/#equations","text":"Context to define equations. It should be primarily used inside a Neuron or Synapse class, but can also be used in a standalone mode by providing a list of attributes: with Equations ( symbols = [ 'tau' , 'v' , 'r' ]) as n : n . dv_dt = ( n . cast ( 0.04 ) - n . v ) / n . tau n . r = sp . tanh ( n . v ) print ( n )","title":"Equations"},{"location":"api/equations/#ANNarchy_future.parser.Equations.Equations.__init__","text":"Creates the Equations context. Parameters: Name Type Description Default symbols list list of attributes when in standalone mode. None method str numerical method (euler, midpoint, exponential, rk4, event-driven) 'euler' neuron Neuron instance (passed by the population). None synapse Synapse instance (passed by the projection). None Source code in ANNarchy_future/parser/Equations.py def __init__ ( self , symbols : list = None , method : str = 'euler' , neuron = None , synapse = None ): \"\"\"Creates the Equations context. Args: symbols: list of attributes when in standalone mode. method: numerical method (euler, midpoint, exponential, rk4, event-driven) neuron: Neuron instance (passed by the population). synapse: Synapse instance (passed by the projection). \"\"\" # Logger self . _logger = logging . getLogger ( __name__ ) self . _logger . debug ( \"Equations() created.\" ) # Objects self . _neuron = neuron self . _synapse = synapse # Numerical method self . method = method # Built-in symbols self . symbols = parser . symbols_dict . copy () # Standalone mode if self . _neuron is None and self . _synapse is None : self . _custom_symbols = symbols self . _logger . info ( \"Custom symbols: \" + str ( symbols )) # List of tuples (name, Equation) self . equations = [] # Start recording assignments self . _started = False","title":"__init__()"},{"location":"api/equations/#ANNarchy_future.parser.Equations.Equations.cast","text":"Cast floating point numbers to symbols in order to avoid numerical errors. Parameters: Name Type Description Default val float required Source code in ANNarchy_future/parser/Equations.py def cast ( self , val : float ) -> sp . Symbol : \"\"\"Cast floating point numbers to symbols in order to avoid numerical errors. Args: val (float): \"\"\" return sp . Symbol ( str ( float ( val )))","title":"cast()"},{"location":"api/equations/#ANNarchy_future.parser.Equations.Equations.clip","text":"Sets the lower and upper bounds of a variable. Equivalent to: def clip ( val , min , max ): if val < min : return min elif val > max : return max else : return val Args: val: variable. min: lower bound. max: upper bound. Source code in ANNarchy_future/parser/Equations.py def clip ( self , val : sp . Symbol , min : sp . Symbol , max : sp . Symbol = None ): \"\"\"Sets the lower and upper bounds of a variable. Equivalent to: ```python def clip(val, min, max): if val < min: return min elif val > max: return max else: return val ``` Args: val: variable. min: lower bound. max: upper bound. \"\"\" if min is None and max is None : # Do nothing return val elif min is not None and max is None : # Lower bound return sp . Piecewise (( min , val < min ), ( val , True )) elif min is None and max is not None : # Upper bound return sp . Piecewise (( max , val > max ), ( val , True )) else : # Two-sided clip return sp . Piecewise (( min , val < min ), ( max , val > max ), ( val , True ))","title":"clip()"},{"location":"api/equations/#ANNarchy_future.parser.Equations.Equations.ite","text":"If-then-else ternary operator. Equivalent to: def ite ( cond , then , els ): if cond : return then else : return els Args: cond: condition. then: returned value when cond is true. else: returned value when cond is false. Source code in ANNarchy_future/parser/Equations.py def ite ( self , cond , then , els ): \"\"\"If-then-else ternary operator. Equivalent to: ```python def ite(cond, then, els): if cond: return then else: return els ``` Args: cond: condition. then: returned value when cond is true. else: returned value when cond is false. \"\"\" return sp . Piecewise (( then , cond ), ( els , True ))","title":"ite()"},{"location":"api/network/","text":"Network \u00b6 Network class containing the complete neural model. Attributes: Name Type Description dt float simulation time step in ms. __init__ ( self , dt = 1.0 , verbose = 1 , logfile = None ) special \u00b6 Constructor of the Network class. The discretization time contant dt is determined at the network-level and should stay constant during the whole simulation. The verbose level specifies which logging messages will be shown: 0 : only errors and exceptions are printed. 1 : errors, exceptions and warnings are displayed (default). 2 : additional information is also displayed (parsing, etc). 3 : debug information is also displayed (which method is entered, variable values, etc...) When logfile is specified, the logging messages will be saved in that file instead of stdout. Parameters: Name Type Description Default dt float simulation step size in ms. 1.0 verbose int logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 1 logfile str file to save the logs. stdout if left empty. None Source code in ANNarchy_future/api/Network.py def __init__ ( self , dt : float = 1.0 , verbose : int = 1 , logfile : str = None ): \"\"\"Constructor of the `Network` class. The discretization time contant `dt` is determined at the network-level and should stay constant during the whole simulation. The `verbose` level specifies which logging messages will be shown: * 0 : only errors and exceptions are printed. * 1 : errors, exceptions and warnings are displayed (default). * 2 : additional information is also displayed (parsing, etc). * 3 : debug information is also displayed (which method is entered, variable values, etc...) When `logfile` is specified, the logging messages will be saved in that file instead of stdout. Args: dt: simulation step size in ms. verbose: logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 logfile: file to save the logs. stdout if left empty. \"\"\" self . dt : float = dt # Logging module: https://docs.python.org/3/howto/logging.html if logfile is not None : logging . basicConfig ( format = ' %(levelname)s - %(name)s \\n %(message)s ' , filename = logfile , level = verbosity_levels [ verbose ] ) else : logging . basicConfig ( format = ' %(levelname)s - %(name)s \\n %(message)s ' , level = verbosity_levels [ verbose ] ) self . _logger = logging . getLogger ( __name__ ) self . _logger . info ( \"Creating network with dt=\" + str ( self . dt )) # List of populations self . _populations = [] # List of projections self . _projections = [] # List of used neurons self . _neuron_types = {} # List of used synapses self . _synapse_types = {} # Communicator self . _interface = None add ( self , shape , neuron , name = None ) \u00b6 Adds a population to the network. Parameters: Name Type Description Default shape tuple shape of the population as a single integer or tuple. required neuron api.Neuron Neuron instance. required name str optional name. None Returns: Type Description api.Population A Population instance. Source code in ANNarchy_future/api/Network.py def add ( self , shape : tuple , neuron : 'api.Neuron' , name : str = None ) -> 'api.Population' : \"\"\"Adds a population to the network. Args: shape: shape of the population as a single integer or tuple. neuron: `Neuron` instance. name: optional name. Returns: A `Population` instance. \"\"\" if isinstance ( shape , int ): shape = ( shape ,) # Create the population self . _logger . info ( \"Adding Population(\" + str ( shape ) + \", \" + type ( neuron ) . __name__ + \", \" + str ( name ) + \").\" ) pop = api . Population ( shape , neuron , name ) id_pop = len ( self . _populations ) pop . _register ( self , id_pop ) # Have the population analyse its attributes self . _logger . debug ( \"Analysing the population.\" ) pop . _analyse () # Store the neuron if not done already if not pop . neuron_class in self . _neuron_types . keys (): self . _neuron_types [ pop . neuron_class ] = pop . _parser # Store the population self . _populations . append ( pop ) self . _logger . info ( \"Population created.\" ) return pop compile ( self , backend = 'single' ) \u00b6 Compiles and instantiates the network. Parameters: Name Type Description Default backend str choose between 'single' , 'openmp' , 'cuda' or 'mpi' . 'single' Source code in ANNarchy_future/api/Network.py def compile ( self , backend : str = 'single' ): \"\"\"Compiles and instantiates the network. Args: backend: choose between `'single'`, `'openmp'`, `'cuda'` or `'mpi'`. \"\"\" self . _backend = backend # Gather all parsed information self . _description = self . _gather_generated_code () # Create compiler self . _compiler = generator . Compiler ( self , backend = backend ) # Hardware check self . _compiler . hardware_check () # Code generation self . _interface = self . _compiler . compile () # Instantiate the network self . _instantiate () connect ( self , pre , post , target , synapse = None , name = None ) \u00b6 Creates a projection by connecting two populations. Parameters: Name Type Description Default pre api.Population pre-synaptic population. required post api.Population post-synaptic population. required target str postsynaptic variable receving the projection. required synapse api.Synapse Synapse instance. None name str optional name. None Returns: Type Description api.Projection A Projection instance. Source code in ANNarchy_future/api/Network.py def connect ( self , pre : 'api.Population' , post : 'api.Population' , target : str , synapse : 'api.Synapse' = None , name : str = None ) -> 'api.Projection' : \"\"\"Creates a projection by connecting two populations. Args: pre: pre-synaptic population. post: post-synaptic population. target: postsynaptic variable receving the projection. synapse: Synapse instance. name: optional name. Returns: A `Projection` instance. \"\"\" self . _logger . info ( \"Adding Projection(\" + pre . name + \", \" + post . name + \", \" + target + \").\" ) proj = api . Projection ( pre , post , target , synapse , name ) id_proj = len ( self . _projections ) proj . _register ( self , id_proj ) # Have the projection analyse its attributes self . _logger . debug ( \"Analysing the projection.\" ) proj . _analyse () # Store the neuron if not done already if not proj . synapse_class in self . _synapse_types . keys (): self . _synapse_types [ proj . synapse_class ] = proj . _parser self . _projections . append ( proj ) return proj step ( self ) \u00b6 Single simulation step. Source code in ANNarchy_future/api/Network.py def step ( self ): \"\"\"Single simulation step. \"\"\" if self . _interface is None : self . _logger . error ( \"step(): the network is not compiled yet.\" ) sys . exit ( 1 ) self . _interface . step ()","title":"Network"},{"location":"api/network/#network","text":"Network class containing the complete neural model. Attributes: Name Type Description dt float simulation time step in ms.","title":"Network"},{"location":"api/network/#ANNarchy_future.api.Network.Network.__init__","text":"Constructor of the Network class. The discretization time contant dt is determined at the network-level and should stay constant during the whole simulation. The verbose level specifies which logging messages will be shown: 0 : only errors and exceptions are printed. 1 : errors, exceptions and warnings are displayed (default). 2 : additional information is also displayed (parsing, etc). 3 : debug information is also displayed (which method is entered, variable values, etc...) When logfile is specified, the logging messages will be saved in that file instead of stdout. Parameters: Name Type Description Default dt float simulation step size in ms. 1.0 verbose int logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 1 logfile str file to save the logs. stdout if left empty. None Source code in ANNarchy_future/api/Network.py def __init__ ( self , dt : float = 1.0 , verbose : int = 1 , logfile : str = None ): \"\"\"Constructor of the `Network` class. The discretization time contant `dt` is determined at the network-level and should stay constant during the whole simulation. The `verbose` level specifies which logging messages will be shown: * 0 : only errors and exceptions are printed. * 1 : errors, exceptions and warnings are displayed (default). * 2 : additional information is also displayed (parsing, etc). * 3 : debug information is also displayed (which method is entered, variable values, etc...) When `logfile` is specified, the logging messages will be saved in that file instead of stdout. Args: dt: simulation step size in ms. verbose: logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 logfile: file to save the logs. stdout if left empty. \"\"\" self . dt : float = dt # Logging module: https://docs.python.org/3/howto/logging.html if logfile is not None : logging . basicConfig ( format = ' %(levelname)s - %(name)s \\n %(message)s ' , filename = logfile , level = verbosity_levels [ verbose ] ) else : logging . basicConfig ( format = ' %(levelname)s - %(name)s \\n %(message)s ' , level = verbosity_levels [ verbose ] ) self . _logger = logging . getLogger ( __name__ ) self . _logger . info ( \"Creating network with dt=\" + str ( self . dt )) # List of populations self . _populations = [] # List of projections self . _projections = [] # List of used neurons self . _neuron_types = {} # List of used synapses self . _synapse_types = {} # Communicator self . _interface = None","title":"__init__()"},{"location":"api/network/#ANNarchy_future.api.Network.Network.add","text":"Adds a population to the network. Parameters: Name Type Description Default shape tuple shape of the population as a single integer or tuple. required neuron api.Neuron Neuron instance. required name str optional name. None Returns: Type Description api.Population A Population instance. Source code in ANNarchy_future/api/Network.py def add ( self , shape : tuple , neuron : 'api.Neuron' , name : str = None ) -> 'api.Population' : \"\"\"Adds a population to the network. Args: shape: shape of the population as a single integer or tuple. neuron: `Neuron` instance. name: optional name. Returns: A `Population` instance. \"\"\" if isinstance ( shape , int ): shape = ( shape ,) # Create the population self . _logger . info ( \"Adding Population(\" + str ( shape ) + \", \" + type ( neuron ) . __name__ + \", \" + str ( name ) + \").\" ) pop = api . Population ( shape , neuron , name ) id_pop = len ( self . _populations ) pop . _register ( self , id_pop ) # Have the population analyse its attributes self . _logger . debug ( \"Analysing the population.\" ) pop . _analyse () # Store the neuron if not done already if not pop . neuron_class in self . _neuron_types . keys (): self . _neuron_types [ pop . neuron_class ] = pop . _parser # Store the population self . _populations . append ( pop ) self . _logger . info ( \"Population created.\" ) return pop","title":"add()"},{"location":"api/network/#ANNarchy_future.api.Network.Network.compile","text":"Compiles and instantiates the network. Parameters: Name Type Description Default backend str choose between 'single' , 'openmp' , 'cuda' or 'mpi' . 'single' Source code in ANNarchy_future/api/Network.py def compile ( self , backend : str = 'single' ): \"\"\"Compiles and instantiates the network. Args: backend: choose between `'single'`, `'openmp'`, `'cuda'` or `'mpi'`. \"\"\" self . _backend = backend # Gather all parsed information self . _description = self . _gather_generated_code () # Create compiler self . _compiler = generator . Compiler ( self , backend = backend ) # Hardware check self . _compiler . hardware_check () # Code generation self . _interface = self . _compiler . compile () # Instantiate the network self . _instantiate ()","title":"compile()"},{"location":"api/network/#ANNarchy_future.api.Network.Network.connect","text":"Creates a projection by connecting two populations. Parameters: Name Type Description Default pre api.Population pre-synaptic population. required post api.Population post-synaptic population. required target str postsynaptic variable receving the projection. required synapse api.Synapse Synapse instance. None name str optional name. None Returns: Type Description api.Projection A Projection instance. Source code in ANNarchy_future/api/Network.py def connect ( self , pre : 'api.Population' , post : 'api.Population' , target : str , synapse : 'api.Synapse' = None , name : str = None ) -> 'api.Projection' : \"\"\"Creates a projection by connecting two populations. Args: pre: pre-synaptic population. post: post-synaptic population. target: postsynaptic variable receving the projection. synapse: Synapse instance. name: optional name. Returns: A `Projection` instance. \"\"\" self . _logger . info ( \"Adding Projection(\" + pre . name + \", \" + post . name + \", \" + target + \").\" ) proj = api . Projection ( pre , post , target , synapse , name ) id_proj = len ( self . _projections ) proj . _register ( self , id_proj ) # Have the projection analyse its attributes self . _logger . debug ( \"Analysing the projection.\" ) proj . _analyse () # Store the neuron if not done already if not proj . synapse_class in self . _synapse_types . keys (): self . _synapse_types [ proj . synapse_class ] = proj . _parser self . _projections . append ( proj ) return proj","title":"connect()"},{"location":"api/network/#ANNarchy_future.api.Network.Network.step","text":"Single simulation step. Source code in ANNarchy_future/api/Network.py def step ( self ): \"\"\"Single simulation step. \"\"\" if self . _interface is None : self . _logger . error ( \"step(): the network is not compiled yet.\" ) sys . exit ( 1 ) self . _interface . step ()","title":"step()"},{"location":"api/neuron/","text":"Neuron \u00b6 Abstract class defining single neurons. TODO Equations ( self , method = 'euler' ) \u00b6 Returns an Equations context. with self . Equations () as n : n . dr_dt = ( n . ge - n . r ) / n . tau When opening the context as n , the variable has all attributes (parameters and variables) of the neuron as symbols, which can be combined in Sympy equations. Parameters: Name Type Description Default method str numerical method (euler, midpoint, exponential, rk4, event-driven) 'euler' Source code in ANNarchy_future/api/Neuron.py def Equations ( self , method : str = 'euler' ): \"\"\"Returns an Equations context. ```python with self.Equations() as n: n.dr_dt = (n.ge - n.r)/n.tau ``` When opening the context as `n`, the variable has all attributes (parameters and variables) of the neuron as symbols, which can be combined in Sympy equations. Args: method: numerical method (euler, midpoint, exponential, rk4, event-driven) \"\"\" eq = Equations ( neuron = self , method = method ) if not hasattr ( self , '_current_eq' ): self . _current_eq = [] self . _current_eq . append ( eq ) return eq Parameter ( self , value , shared = True , dtype = 'float' ) \u00b6 Defines a parameter for the neuron. Parameters are defined only once for the whole population by default. If each neuron should have different values, set shared=False . Parameters: Name Type Description Default value float initial value. required shared bool locality of the parameter. True dtype str numerical type of the value ('float', 'int', 'bool'). 'float' Returns: Type Description Parameter Parameter instance. Source code in ANNarchy_future/api/Neuron.py def Parameter ( self , value : float , shared : bool = True , dtype : str = 'float' ) -> api . Parameter : \"\"\"Defines a parameter for the neuron. Parameters are defined only once for the whole population by default. If each neuron should have different values, set `shared=False`. Args: value: initial value. shared: locality of the parameter. dtype: numerical type of the value ('float', 'int', 'bool'). Returns: `Parameter` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] self . _inputs = [] self . _outputs = [] val = api . Parameter ( init = value , shared = shared , dtype = dtype ) self . _data . append ( val ) return val Variable ( self , init = 0.0 , shared = False , input = False , output = False , dtype = 'float' ) \u00b6 Defines a variable for the neuron. Variables take a different value for each neuron in the population. If a single value is needed, set shared=True to save some memory. Variables receiving inputs from a projection (weighted sums, conductances) should set input=True . Output variables (e.g. firing rates) that may be used in projections with a delay should set output=True . Parameters: Name Type Description Default init float initial value. 0.0 shared bool locality of the variable. False input bool is it an input variable? False output bool is it an output variable? False dtype str numerical type of the variable ('float', 'int', 'bool'). 'float' Returns: Type Description Variable Variable instance. Source code in ANNarchy_future/api/Neuron.py def Variable ( self , init : float = 0.0 , shared : bool = False , input : bool = False , output : bool = False , dtype : str = 'float' ) -> api . Variable : \"\"\"Defines a variable for the neuron. Variables take a different value for each neuron in the population. If a single value is needed, set `shared=True` to save some memory. Variables receiving inputs from a projection (weighted sums, conductances) should set `input=True`. Output variables (e.g. firing rates) that may be used in projections with a delay should set `output=True`. Args: init: initial value. shared: locality of the variable. input: is it an input variable? output: is it an output variable? dtype: numerical type of the variable ('float', 'int', 'bool'). Returns: `Variable` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] self . _inputs = [] self . _outputs = [] val = api . Variable ( init = init , shared = shared , dtype = dtype ) self . _data . append ( val ) if input : self . _inputs . append ( val ) if output : self . _outputs . append ( val ) return val","title":"Neuron"},{"location":"api/neuron/#neuron","text":"Abstract class defining single neurons. TODO","title":"Neuron"},{"location":"api/neuron/#ANNarchy_future.api.Neuron.Neuron.Equations","text":"Returns an Equations context. with self . Equations () as n : n . dr_dt = ( n . ge - n . r ) / n . tau When opening the context as n , the variable has all attributes (parameters and variables) of the neuron as symbols, which can be combined in Sympy equations. Parameters: Name Type Description Default method str numerical method (euler, midpoint, exponential, rk4, event-driven) 'euler' Source code in ANNarchy_future/api/Neuron.py def Equations ( self , method : str = 'euler' ): \"\"\"Returns an Equations context. ```python with self.Equations() as n: n.dr_dt = (n.ge - n.r)/n.tau ``` When opening the context as `n`, the variable has all attributes (parameters and variables) of the neuron as symbols, which can be combined in Sympy equations. Args: method: numerical method (euler, midpoint, exponential, rk4, event-driven) \"\"\" eq = Equations ( neuron = self , method = method ) if not hasattr ( self , '_current_eq' ): self . _current_eq = [] self . _current_eq . append ( eq ) return eq","title":"Equations()"},{"location":"api/neuron/#ANNarchy_future.api.Neuron.Neuron.Parameter","text":"Defines a parameter for the neuron. Parameters are defined only once for the whole population by default. If each neuron should have different values, set shared=False . Parameters: Name Type Description Default value float initial value. required shared bool locality of the parameter. True dtype str numerical type of the value ('float', 'int', 'bool'). 'float' Returns: Type Description Parameter Parameter instance. Source code in ANNarchy_future/api/Neuron.py def Parameter ( self , value : float , shared : bool = True , dtype : str = 'float' ) -> api . Parameter : \"\"\"Defines a parameter for the neuron. Parameters are defined only once for the whole population by default. If each neuron should have different values, set `shared=False`. Args: value: initial value. shared: locality of the parameter. dtype: numerical type of the value ('float', 'int', 'bool'). Returns: `Parameter` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] self . _inputs = [] self . _outputs = [] val = api . Parameter ( init = value , shared = shared , dtype = dtype ) self . _data . append ( val ) return val","title":"Parameter()"},{"location":"api/neuron/#ANNarchy_future.api.Neuron.Neuron.Variable","text":"Defines a variable for the neuron. Variables take a different value for each neuron in the population. If a single value is needed, set shared=True to save some memory. Variables receiving inputs from a projection (weighted sums, conductances) should set input=True . Output variables (e.g. firing rates) that may be used in projections with a delay should set output=True . Parameters: Name Type Description Default init float initial value. 0.0 shared bool locality of the variable. False input bool is it an input variable? False output bool is it an output variable? False dtype str numerical type of the variable ('float', 'int', 'bool'). 'float' Returns: Type Description Variable Variable instance. Source code in ANNarchy_future/api/Neuron.py def Variable ( self , init : float = 0.0 , shared : bool = False , input : bool = False , output : bool = False , dtype : str = 'float' ) -> api . Variable : \"\"\"Defines a variable for the neuron. Variables take a different value for each neuron in the population. If a single value is needed, set `shared=True` to save some memory. Variables receiving inputs from a projection (weighted sums, conductances) should set `input=True`. Output variables (e.g. firing rates) that may be used in projections with a delay should set `output=True`. Args: init: initial value. shared: locality of the variable. input: is it an input variable? output: is it an output variable? dtype: numerical type of the variable ('float', 'int', 'bool'). Returns: `Variable` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] self . _inputs = [] self . _outputs = [] val = api . Variable ( init = init , shared = shared , dtype = dtype ) self . _data . append ( val ) if input : self . _inputs . append ( val ) if output : self . _outputs . append ( val ) return val","title":"Variable()"},{"location":"api/population/","text":"Population \u00b6 Population of neurons. Populations should not be created explicitly, but returned by Network.add() : net = Network () pop = net . add ( 10 , LIF ()) Attributes: Name Type Description shape tuple shape of the population. size int number of neurons. name str unique name of the population. neuron_class str name of the Neuron class Additionaly, all parameters and variables of the neuron type are accessible as attributes: class Leaky ( Neuron ): def __init__ ( self ): self . tau = self . Parameter ( 20. ) self . r = self . Variable ( 0.0 ) net = Network () pop = net . add ( 10 , Leaky ()) print ( pop . tau ) # 20. print ( pop . r ) # [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] is_spiking ( self ) \u00b6 Returns True if the neuron type is spiking. Source code in ANNarchy_future/api/Population.py def is_spiking ( self ) -> bool : \"Returns True if the neuron type is spiking.\" return self . _neuron_type . is_spiking ()","title":"Population"},{"location":"api/population/#population","text":"Population of neurons. Populations should not be created explicitly, but returned by Network.add() : net = Network () pop = net . add ( 10 , LIF ()) Attributes: Name Type Description shape tuple shape of the population. size int number of neurons. name str unique name of the population. neuron_class str name of the Neuron class Additionaly, all parameters and variables of the neuron type are accessible as attributes: class Leaky ( Neuron ): def __init__ ( self ): self . tau = self . Parameter ( 20. ) self . r = self . Variable ( 0.0 ) net = Network () pop = net . add ( 10 , Leaky ()) print ( pop . tau ) # 20. print ( pop . r ) # [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]","title":"Population"},{"location":"api/population/#ANNarchy_future.api.Population.Population.is_spiking","text":"Returns True if the neuron type is spiking. Source code in ANNarchy_future/api/Population.py def is_spiking ( self ) -> bool : \"Returns True if the neuron type is spiking.\" return self . _neuron_type . is_spiking ()","title":"is_spiking()"},{"location":"api/projection/","text":"Projection \u00b6 Projection between two populations.","title":"Projection"},{"location":"api/projection/#projection","text":"Projection between two populations.","title":"Projection"},{"location":"api/synapse/","text":"Synapse \u00b6 Abstract class defining single synapses. TODO Equations ( self , method = 'euler' ) \u00b6 Returns an Equations context. with self . Equations () as s : s . w += s . eta * s . pre . r * s . post . r When opening the context as s , the variable has all attributes (parameters and variables) of the synapse as symbols, which can be combined in Sympy equations. The attributes of the pre- and post-synaptic neurons are accessible under s.pre and s.post . Parameters: Name Type Description Default method str numerical method (euler, midpoint, exponential, rk4, event-driven) 'euler' Source code in ANNarchy_future/api/Synapse.py def Equations ( self , method : str = 'euler' ): \"\"\"Returns an Equations context. ```python with self.Equations() as s: s.w += s.eta * s.pre.r * s.post.r ``` When opening the context as `s`, the variable has all attributes (parameters and variables) of the synapse as symbols, which can be combined in Sympy equations. The attributes of the pre- and post-synaptic neurons are accessible under `s.pre` and `s.post`. Args: method: numerical method (euler, midpoint, exponential, rk4, event-driven) \"\"\" eq = Equations ( synapse = self , method = method ) if not hasattr ( self , '_current_eq' ): self . _current_eq = [] self . _current_eq . append ( eq ) return eq Parameter ( self , value , shared = True , dtype = 'float' ) \u00b6 Defines a parameter for the synapse. Parameters are defined only once for the whole projection by default. If each neuron should have different values, set shared=False . Parameters: Name Type Description Default value float initial value. required shared bool locality of the parameter. True dtype str numerical type of the value ('float'', 'int', 'bool') 'float' Returns: Type Description Parameter Parameter instance. Source code in ANNarchy_future/api/Synapse.py def Parameter ( self , value : float , shared : bool = True , dtype : str = 'float' ) -> api . Parameter : \"\"\"Defines a parameter for the synapse. Parameters are defined only once for the whole projection by default. If each neuron should have different values, set `shared=False`. Args: value: initial value. shared: locality of the parameter. dtype: numerical type of the value ('float'', 'int', 'bool') Returns: `Parameter` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = api . Parameter ( init = value , shared = shared , dtype = dtype ) self . _data . append ( val ) return val Variable ( self , init = 0.0 , shared = False , dtype = 'float' ) \u00b6 Defines a variable for the synapse. Variables take a different value for each synapse in the projection by default. If a single value for the whole projection is needed, set shared=True to save some memory. Parameters: Name Type Description Default init float initial value. 0.0 shared bool locality of the variable. False dtype str numerical type of the value ('float', 'int', 'bool'). 'float' Returns: Type Description Variable Variable instance. Source code in ANNarchy_future/api/Synapse.py def Variable ( self , init : float = 0.0 , shared : bool = False , dtype : str = 'float' ) -> api . Variable : \"\"\"Defines a variable for the synapse. Variables take a different value for each synapse in the projection by default. If a single value for the whole projection is needed, set `shared=True` to save some memory. Args: init: initial value. shared: locality of the variable. dtype: numerical type of the value ('float', 'int', 'bool'). Returns: `Variable` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = api . Variable ( init = init , shared = shared , dtype = dtype ) self . _data . append ( val ) return val","title":"Synapse"},{"location":"api/synapse/#synapse","text":"Abstract class defining single synapses. TODO","title":"Synapse"},{"location":"api/synapse/#ANNarchy_future.api.Synapse.Synapse.Equations","text":"Returns an Equations context. with self . Equations () as s : s . w += s . eta * s . pre . r * s . post . r When opening the context as s , the variable has all attributes (parameters and variables) of the synapse as symbols, which can be combined in Sympy equations. The attributes of the pre- and post-synaptic neurons are accessible under s.pre and s.post . Parameters: Name Type Description Default method str numerical method (euler, midpoint, exponential, rk4, event-driven) 'euler' Source code in ANNarchy_future/api/Synapse.py def Equations ( self , method : str = 'euler' ): \"\"\"Returns an Equations context. ```python with self.Equations() as s: s.w += s.eta * s.pre.r * s.post.r ``` When opening the context as `s`, the variable has all attributes (parameters and variables) of the synapse as symbols, which can be combined in Sympy equations. The attributes of the pre- and post-synaptic neurons are accessible under `s.pre` and `s.post`. Args: method: numerical method (euler, midpoint, exponential, rk4, event-driven) \"\"\" eq = Equations ( synapse = self , method = method ) if not hasattr ( self , '_current_eq' ): self . _current_eq = [] self . _current_eq . append ( eq ) return eq","title":"Equations()"},{"location":"api/synapse/#ANNarchy_future.api.Synapse.Synapse.Parameter","text":"Defines a parameter for the synapse. Parameters are defined only once for the whole projection by default. If each neuron should have different values, set shared=False . Parameters: Name Type Description Default value float initial value. required shared bool locality of the parameter. True dtype str numerical type of the value ('float'', 'int', 'bool') 'float' Returns: Type Description Parameter Parameter instance. Source code in ANNarchy_future/api/Synapse.py def Parameter ( self , value : float , shared : bool = True , dtype : str = 'float' ) -> api . Parameter : \"\"\"Defines a parameter for the synapse. Parameters are defined only once for the whole projection by default. If each neuron should have different values, set `shared=False`. Args: value: initial value. shared: locality of the parameter. dtype: numerical type of the value ('float'', 'int', 'bool') Returns: `Parameter` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = api . Parameter ( init = value , shared = shared , dtype = dtype ) self . _data . append ( val ) return val","title":"Parameter()"},{"location":"api/synapse/#ANNarchy_future.api.Synapse.Synapse.Variable","text":"Defines a variable for the synapse. Variables take a different value for each synapse in the projection by default. If a single value for the whole projection is needed, set shared=True to save some memory. Parameters: Name Type Description Default init float initial value. 0.0 shared bool locality of the variable. False dtype str numerical type of the value ('float', 'int', 'bool'). 'float' Returns: Type Description Variable Variable instance. Source code in ANNarchy_future/api/Synapse.py def Variable ( self , init : float = 0.0 , shared : bool = False , dtype : str = 'float' ) -> api . Variable : \"\"\"Defines a variable for the synapse. Variables take a different value for each synapse in the projection by default. If a single value for the whole projection is needed, set `shared=True` to save some memory. Args: init: initial value. shared: locality of the variable. dtype: numerical type of the value ('float', 'int', 'bool'). Returns: `Variable` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = api . Variable ( init = init , shared = shared , dtype = dtype ) self . _data . append ( val ) return val","title":"Variable()"},{"location":"contributing/generator/","text":"Generator \u00b6 Compiler \u00b6 ANNarchy_future.generator.Compiler.Compiler \u00b6 Generates code, compiles it and instantiate the network. __init__ ( self , net , backend , annarchy_dir = './annarchy/' ) special \u00b6 Initializes the code generators. Parameters: Name Type Description Default net api.Network Python Network instance. required backend str 'single', 'openmp', 'cuda' or 'mpi'. required annarchy_dir str path to the compilation directory. './annarchy/' Source code in ANNarchy_future/generator/Compiler.py def __init__ ( self , net : 'api.Network' , backend : str , annarchy_dir : str = './annarchy/' ): \"\"\" Initializes the code generators. Args: net: Python Network instance. backend: 'single', 'openmp', 'cuda' or 'mpi'. annarchy_dir: path to the compilation directory. \"\"\" self . net = net self . backend : str = backend self . annarchy_dir = annarchy_dir # Logging self . _logger = logging . getLogger ( __name__ ) self . _logger . info ( \"Compiling.\" ) if backend == \"single\" : self . _generator = generator . SingleThread . SingleThreadGenerator ( self . net . _description , backend ) else : raise NotImplementedError compile ( self ) \u00b6 Compiles the generated code. Returns: Type Description communicator.SimulationInterface a SimulationInterface instance allowing Python to communicate with the C++ kernel. Source code in ANNarchy_future/generator/Compiler.py def compile ( self ) -> 'communicator.SimulationInterface' : \"\"\" Compiles the generated code. Returns: a `SimulationInterface` instance allowing Python to communicate with the C++ kernel. \"\"\" # Call the generator generator() method self . _generator . generate () # Create the compilation folder self . _compilation_folder () # Generate files self . _copy_files () # Compile the code self . _compile () # Import shared library library = \"ANNarchyCore\" if self . backend == \"single\" : interface = communicator . CythonInterface ( self . net , library ) else : raise NotImplementedError return interface hardware_check ( self ) \u00b6 Checks whether the provided network can be compiled on the current hardware. Checks whether: the projection formats are available for the backend. fitting hardware? MPI: host available? CUDA: GPU available? Source code in ANNarchy_future/generator/Compiler.py def hardware_check ( self ): \"\"\"Checks whether the provided network can be compiled on the current hardware. Checks whether: * the projection formats are available for the backend. * fitting hardware? * MPI: host available? * CUDA: GPU available? \"\"\" # If needed: https://github.com/workhorsy/py-cpuinfo pass Single threaded backend \u00b6 ANNarchy_future.generator.SingleThread.PopulationGenerator.PopulationGenerator \u00b6 Generates a C++ file corresponding to a Neuron description. Attributes: Name Type Description name str name of the class. parser 'parser.NeuronParser' instance of NeuronParser. correspondences dictionary of pairs (symbol -> implementation). __init__ ( self , name , parser ) special \u00b6 Parameters: Name Type Description Default name str name of the class. required parser parser.NeuronParser parser for the neuron. required Source code in ANNarchy_future/generator/SingleThread/PopulationGenerator.py def __init__ ( self , name : str , parser : 'parser.NeuronParser' ): \"\"\" Args: name (str): name of the class. parser (parser.NeuronParser): parser for the neuron. \"\"\" self . name : str = name self . parser : 'parser.NeuronParser' = parser # Build a correspondance dictionary self . correspondences = { 't' : 'this->t' , 'dt' : 'this->dt' , } for attr in self . parser . attributes : if attr in self . parser . shared : self . correspondences [ attr ] = \"this->\" + attr else : self . correspondences [ attr ] = \"this->\" + attr + \"[i]\" cython_export ( self ) \u00b6 Generates declaration of the C++ class for Cython. Source code in ANNarchy_future/generator/SingleThread/PopulationGenerator.py def cython_export ( self ): \"\"\"Generates declaration of the C++ class for Cython. \"\"\" # Parameters parameters = \"\" for attr in self . parser . parameters : if attr in self . parser . shared : parameters += Template ( \" double $attr \\n \" ) . substitute ( attr = attr ) else : parameters += Template ( \" vector[double] $attr \\n \" ) . substitute ( attr = attr ) # Variables variables = \"\" for attr in self . parser . variables : if attr in self . parser . shared : variables += Template ( \" double $attr \\n \" ) . substitute ( attr = attr ) else : variables += Template ( \" vector[double] $attr \\n \" ) . substitute ( attr = attr ) code = Template ( \"\"\" # $name cdef cppclass $name : # Constructor $name(int, double) except + # Number of neurons int size # Neural equations void update() # Reset the population void reset() # Parameters $parameters # Variables $variables \"\"\" ) . substitute ( name = self . name , parameters = parameters , variables = variables , ) return code generate ( self ) \u00b6 Generates the C++ code. Calls: `self.update()` `self.spike()` `self.reset()` Returns: Type Description str a multiline string for the .h header file. Source code in ANNarchy_future/generator/SingleThread/PopulationGenerator.py def generate ( self ) -> str : \"\"\"Generates the C++ code. Calls: `self.update()` `self.spike()` `self.reset()` Returns: a multiline string for the .h header file. \"\"\" # Get the template tpl = str ( ANNarchy_future . __path__ [ 0 ]) + '/generator/SingleThread/Population.h' # Open the template with open ( tpl , 'r' ) as f : template = f . readlines () template = Template ( \"\" . join ( template )) # Initialize arrays initialize_arrays = \"\" # Parameters declared_parameters = \"\" for attr in self . parser . parameters : if attr in self . parser . shared : declared_parameters += Template ( \" double $attr; \\n \" ) . substitute ( attr = attr ) else : declared_parameters += Template ( \" std::vector<double> $attr; \\n \" ) . substitute ( attr = attr ) initialize_arrays += Template ( \" this->$attr = std::vector<double>(size, 0.0); \\n \" ) . substitute ( attr = attr ) # Variables declared_variables = \"\" for attr in self . parser . variables : if attr in self . parser . shared : declared_variables += Template ( \" double $attr; \\n \" ) . substitute ( attr = attr ) else : declared_variables += Template ( \" std::vector<double> $attr; \\n \" ) . substitute ( attr = attr ) initialize_arrays += Template ( \" this->$attr = std::vector<double>(size, 0.0); \\n \" ) . substitute ( attr = attr ) # Update method update_method = self . update () # Spiking specifics initialize_spiking = \"\" declared_spiking = \"\" spike_method = \"\" reset_method = \"\" if self . parser . is_spiking (): # Declare spike arrays declared_spiking = \"\"\" // Spiking neuron std::vector<int> spikes;\"\"\" initialize_spiking = \"\"\" // Spiking neuron this->spikes = std::vector<int>(0);\"\"\" # Spike method spike_method = self . spike () # Reset method reset_method = self . reset () # Generate code code = template . substitute ( class_name = self . name , initialize_arrays = initialize_arrays , initialize_spiking = initialize_spiking , declared_parameters = declared_parameters , declared_variables = declared_variables , declared_spiking = declared_spiking , update_method = update_method , spike_method = spike_method , reset_method = reset_method , ) return code reset ( self ) \u00b6 Processes the Neuron.reset() field. Returns: Type Description str the whole reset() C++ method. Source code in ANNarchy_future/generator/SingleThread/PopulationGenerator.py def reset ( self ) -> str : \"\"\"Processes the Neuron.reset() field. Returns: the whole `reset()` C++ method. \"\"\" tpl_reset = Template ( \"\"\" // Reset void reset(){ for(unsigned int idx = 0; idx< this->spikes.size(); idx++){ int i = this->spikes[idx]; $reset } } \"\"\" ) # Equation template tpl_eq = Template ( \"\"\" // $hr $lhs $op $rhs; \"\"\" ) # Iterate over all blocks of equations code = \"\" for block in self . parser . reset_equations : for eq in block . equations : code += tpl_eq . substitute ( lhs = eq [ 'name' ] if eq [ 'name' ] in self . parser . shared else eq [ 'name' ] + \"[i]\" , op = eq [ 'op' ], rhs = parser . code_generation ( eq [ 'rhs' ], self . correspondences ), hr = eq [ 'human-readable' ] ) return tpl_reset . substitute ( reset = code ) spike ( self ) \u00b6 Processes the Neuron.spike() field. Returns: Type Description str the whole spike() C++ method. Source code in ANNarchy_future/generator/SingleThread/PopulationGenerator.py def spike ( self ) -> str : \"\"\"Processes the Neuron.spike() field. Returns: the whole `spike()` C++ method. \"\"\" tpl_spike = Template ( \"\"\" // Spike emission void spike(){ for(unsigned int i = 0; i< this->size; i++){ if ($condition){ this->spikes.push_back(i); } } } \"\"\" ) cond = parser . code_generation ( self . parser . spike_condition . equation [ 'eq' ], self . correspondences ) return tpl_spike . substitute ( condition = cond ) update ( self ) \u00b6 Processes the Neuron.update() field. Returns: Type Description str the content of the update() C++ method. Source code in ANNarchy_future/generator/SingleThread/PopulationGenerator.py def update ( self ) -> str : \"\"\"Processes the Neuron.update() field. Returns: the content of the `update()` C++ method. \"\"\" # Block template tlp_block = Template ( \"\"\" for(unsigned int i = 0; i< this->size; i++){ $update }\"\"\" ) # Equation template tpl_eq = Template ( \"\"\" // $hr $lhs $op $rhs; \"\"\" ) # Iterate over all blocks of equations code = \"\" for block in self . parser . update_equations : for eq in block . equations : # Temporary variables if eq [ 'type' ] == 'tmp' : code += tpl_eq . substitute ( lhs = \"double \" + eq [ 'name' ], op = eq [ 'op' ], rhs = parser . code_generation ( eq [ 'rhs' ], self . correspondences ), hr = eq [ 'human-readable' ] ) else : code += tpl_eq . substitute ( lhs = eq [ 'name' ] if eq [ 'name' ] in self . parser . shared else eq [ 'name' ] + \"[i]\" , op = eq [ 'op' ], rhs = parser . code_generation ( eq [ 'rhs' ], self . correspondences ), hr = eq [ 'human-readable' ] ) return tlp_block . substitute ( update = code ) ANNarchy_future.generator.SingleThread.ProjectionGenerator.ProjectionGenerator \u00b6 Generates a C++ file corresponding to a Synapse description. Attributes: Name Type Description name str name of the class. parser 'parser.SynapseParser' instance of SynapseParser. correspondences dictionary of pairs (symbol -> implementation). __init__ ( self , name , parser ) special \u00b6 Parameters: Name Type Description Default name str name of the class. required parser parser.SynapseParser parser for the synapse. required Source code in ANNarchy_future/generator/SingleThread/ProjectionGenerator.py def __init__ ( self , name : str , parser : 'parser.SynapseParser' ): \"\"\" Args: name (str): name of the class. parser (parser.SynapseParser): parser for the synapse. \"\"\" self . name : str = name self . parser : 'parser.SynapseParser' = parser # Build a correspondance dictionary self . correspondences = { 't' : 'this->t' , 'dt' : 'this->dt' , } for attr in self . parser . attributes : if attr in self . parser . shared : self . correspondences [ attr ] = \"this->\" + attr else : self . correspondences [ attr ] = \"this->\" + attr + \"[i][j]\" for attr in self . parser . synapse . pre_attributes : if attr in self . parser . pre . _parser . shared : self . correspondences [ \"pre.\" + attr ] = \"this->pre->\" + attr else : self . correspondences [ \"pre.\" + attr ] = \"this->pre->\" + attr + \"[i]\" for attr in self . parser . synapse . post_attributes : if attr in self . parser . post . _parser . shared : self . correspondences [ \"post.\" + attr ] = \"this->post->\" + attr else : self . correspondences [ \"post.\" + attr ] = \"this->post->\" + attr + \"[j]\" generate ( self ) \u00b6 Generates the C++ code. Calls: `self.update()` Returns: Type Description str a multiline string for the .h header file. Source code in ANNarchy_future/generator/SingleThread/ProjectionGenerator.py def generate ( self ) -> str : \"\"\"Generates the C++ code. Calls: `self.update()` Returns: a multiline string for the .h header file. \"\"\" # Get the template tpl = str ( ANNarchy_future . __path__ [ 0 ]) + '/generator/SingleThread/Projection.h' # Open the template with open ( tpl , 'r' ) as f : template = f . readlines () template = Template ( \"\" . join ( template )) # Initialize arrays initialize_arrays = \"\" # Parameters declared_parameters = \"\" for attr in self . parser . parameters : if attr in self . parser . shared : declared_parameters += Template ( \" double $attr; \\n \" ) . substitute ( attr = attr ) else : declared_parameters += Template ( \" std::vector<double> $attr; \\n \" ) . substitute ( attr = attr ) initialize_arrays += Template ( \" this->$attr = std::vector<double>(size, 0.0); \\n \" ) . substitute ( attr = attr ) # Variables declared_variables = \"\" for attr in self . parser . variables : if attr in self . parser . shared : declared_variables += Template ( \" double $attr; \\n \" ) . substitute ( attr = attr ) else : declared_variables += Template ( \" std::vector<double> $attr; \\n \" ) . substitute ( attr = attr ) initialize_arrays += Template ( \" this->$attr = std::vector<double>(size, 0.0); \\n \" ) . substitute ( attr = attr ) # Update method update_method = self . update () # Generate code code = template . substitute ( class_name = self . name , initialize_arrays = initialize_arrays , declared_parameters = declared_parameters , declared_variables = declared_variables , update_method = update_method , ) return code update ( self ) \u00b6 Processes the Synapse.update() field. Returns: Type Description str the content of the update() C++ method. Source code in ANNarchy_future/generator/SingleThread/ProjectionGenerator.py def update ( self ) -> str : \"\"\"Processes the Synapse.update() field. Returns: the content of the `update()` C++ method. \"\"\" # Block template tlp_block = Template ( \"\"\" for(unsigned int i = 0; i< this->size; i++){ $update }\"\"\" ) # Equation template tpl_eq = Template ( \"\"\" // $hr $lhs $op $rhs; \"\"\" ) # Iterate over all blocks of equations code = \"\" for block in self . parser . update_equations : for eq in block . equations : # Temporary variables if eq [ 'type' ] == 'tmp' : code += tpl_eq . substitute ( lhs = \"double \" + eq [ 'name' ], op = eq [ 'op' ], rhs = parser . code_generation ( eq [ 'rhs' ], self . correspondences ), hr = eq [ 'human-readable' ] ) else : code += tpl_eq . substitute ( lhs = eq [ 'name' ] if eq [ 'name' ] in self . parser . shared else eq [ 'name' ] + \"[i]\" , op = eq [ 'op' ], rhs = parser . code_generation ( eq [ 'rhs' ], self . correspondences ), hr = eq [ 'human-readable' ] ) return tlp_block . substitute ( update = code )","title":"Generator"},{"location":"contributing/generator/#generator","text":"","title":"Generator"},{"location":"contributing/generator/#compiler","text":"","title":"Compiler"},{"location":"contributing/generator/#ANNarchy_future.generator.Compiler.Compiler","text":"Generates code, compiles it and instantiate the network.","title":"Compiler"},{"location":"contributing/generator/#ANNarchy_future.generator.Compiler.Compiler.__init__","text":"Initializes the code generators. Parameters: Name Type Description Default net api.Network Python Network instance. required backend str 'single', 'openmp', 'cuda' or 'mpi'. required annarchy_dir str path to the compilation directory. './annarchy/' Source code in ANNarchy_future/generator/Compiler.py def __init__ ( self , net : 'api.Network' , backend : str , annarchy_dir : str = './annarchy/' ): \"\"\" Initializes the code generators. Args: net: Python Network instance. backend: 'single', 'openmp', 'cuda' or 'mpi'. annarchy_dir: path to the compilation directory. \"\"\" self . net = net self . backend : str = backend self . annarchy_dir = annarchy_dir # Logging self . _logger = logging . getLogger ( __name__ ) self . _logger . info ( \"Compiling.\" ) if backend == \"single\" : self . _generator = generator . SingleThread . SingleThreadGenerator ( self . net . _description , backend ) else : raise NotImplementedError","title":"__init__()"},{"location":"contributing/generator/#ANNarchy_future.generator.Compiler.Compiler.compile","text":"Compiles the generated code. Returns: Type Description communicator.SimulationInterface a SimulationInterface instance allowing Python to communicate with the C++ kernel. Source code in ANNarchy_future/generator/Compiler.py def compile ( self ) -> 'communicator.SimulationInterface' : \"\"\" Compiles the generated code. Returns: a `SimulationInterface` instance allowing Python to communicate with the C++ kernel. \"\"\" # Call the generator generator() method self . _generator . generate () # Create the compilation folder self . _compilation_folder () # Generate files self . _copy_files () # Compile the code self . _compile () # Import shared library library = \"ANNarchyCore\" if self . backend == \"single\" : interface = communicator . CythonInterface ( self . net , library ) else : raise NotImplementedError return interface","title":"compile()"},{"location":"contributing/generator/#ANNarchy_future.generator.Compiler.Compiler.hardware_check","text":"Checks whether the provided network can be compiled on the current hardware. Checks whether: the projection formats are available for the backend. fitting hardware? MPI: host available? CUDA: GPU available? Source code in ANNarchy_future/generator/Compiler.py def hardware_check ( self ): \"\"\"Checks whether the provided network can be compiled on the current hardware. Checks whether: * the projection formats are available for the backend. * fitting hardware? * MPI: host available? * CUDA: GPU available? \"\"\" # If needed: https://github.com/workhorsy/py-cpuinfo pass","title":"hardware_check()"},{"location":"contributing/generator/#single-threaded-backend","text":"","title":"Single threaded backend"},{"location":"contributing/generator/#ANNarchy_future.generator.SingleThread.PopulationGenerator.PopulationGenerator","text":"Generates a C++ file corresponding to a Neuron description. Attributes: Name Type Description name str name of the class. parser 'parser.NeuronParser' instance of NeuronParser. correspondences dictionary of pairs (symbol -> implementation).","title":"PopulationGenerator"},{"location":"contributing/generator/#ANNarchy_future.generator.SingleThread.PopulationGenerator.PopulationGenerator.__init__","text":"Parameters: Name Type Description Default name str name of the class. required parser parser.NeuronParser parser for the neuron. required Source code in ANNarchy_future/generator/SingleThread/PopulationGenerator.py def __init__ ( self , name : str , parser : 'parser.NeuronParser' ): \"\"\" Args: name (str): name of the class. parser (parser.NeuronParser): parser for the neuron. \"\"\" self . name : str = name self . parser : 'parser.NeuronParser' = parser # Build a correspondance dictionary self . correspondences = { 't' : 'this->t' , 'dt' : 'this->dt' , } for attr in self . parser . attributes : if attr in self . parser . shared : self . correspondences [ attr ] = \"this->\" + attr else : self . correspondences [ attr ] = \"this->\" + attr + \"[i]\"","title":"__init__()"},{"location":"contributing/generator/#ANNarchy_future.generator.SingleThread.PopulationGenerator.PopulationGenerator.cython_export","text":"Generates declaration of the C++ class for Cython. Source code in ANNarchy_future/generator/SingleThread/PopulationGenerator.py def cython_export ( self ): \"\"\"Generates declaration of the C++ class for Cython. \"\"\" # Parameters parameters = \"\" for attr in self . parser . parameters : if attr in self . parser . shared : parameters += Template ( \" double $attr \\n \" ) . substitute ( attr = attr ) else : parameters += Template ( \" vector[double] $attr \\n \" ) . substitute ( attr = attr ) # Variables variables = \"\" for attr in self . parser . variables : if attr in self . parser . shared : variables += Template ( \" double $attr \\n \" ) . substitute ( attr = attr ) else : variables += Template ( \" vector[double] $attr \\n \" ) . substitute ( attr = attr ) code = Template ( \"\"\" # $name cdef cppclass $name : # Constructor $name(int, double) except + # Number of neurons int size # Neural equations void update() # Reset the population void reset() # Parameters $parameters # Variables $variables \"\"\" ) . substitute ( name = self . name , parameters = parameters , variables = variables , ) return code","title":"cython_export()"},{"location":"contributing/generator/#ANNarchy_future.generator.SingleThread.PopulationGenerator.PopulationGenerator.generate","text":"Generates the C++ code. Calls: `self.update()` `self.spike()` `self.reset()` Returns: Type Description str a multiline string for the .h header file. Source code in ANNarchy_future/generator/SingleThread/PopulationGenerator.py def generate ( self ) -> str : \"\"\"Generates the C++ code. Calls: `self.update()` `self.spike()` `self.reset()` Returns: a multiline string for the .h header file. \"\"\" # Get the template tpl = str ( ANNarchy_future . __path__ [ 0 ]) + '/generator/SingleThread/Population.h' # Open the template with open ( tpl , 'r' ) as f : template = f . readlines () template = Template ( \"\" . join ( template )) # Initialize arrays initialize_arrays = \"\" # Parameters declared_parameters = \"\" for attr in self . parser . parameters : if attr in self . parser . shared : declared_parameters += Template ( \" double $attr; \\n \" ) . substitute ( attr = attr ) else : declared_parameters += Template ( \" std::vector<double> $attr; \\n \" ) . substitute ( attr = attr ) initialize_arrays += Template ( \" this->$attr = std::vector<double>(size, 0.0); \\n \" ) . substitute ( attr = attr ) # Variables declared_variables = \"\" for attr in self . parser . variables : if attr in self . parser . shared : declared_variables += Template ( \" double $attr; \\n \" ) . substitute ( attr = attr ) else : declared_variables += Template ( \" std::vector<double> $attr; \\n \" ) . substitute ( attr = attr ) initialize_arrays += Template ( \" this->$attr = std::vector<double>(size, 0.0); \\n \" ) . substitute ( attr = attr ) # Update method update_method = self . update () # Spiking specifics initialize_spiking = \"\" declared_spiking = \"\" spike_method = \"\" reset_method = \"\" if self . parser . is_spiking (): # Declare spike arrays declared_spiking = \"\"\" // Spiking neuron std::vector<int> spikes;\"\"\" initialize_spiking = \"\"\" // Spiking neuron this->spikes = std::vector<int>(0);\"\"\" # Spike method spike_method = self . spike () # Reset method reset_method = self . reset () # Generate code code = template . substitute ( class_name = self . name , initialize_arrays = initialize_arrays , initialize_spiking = initialize_spiking , declared_parameters = declared_parameters , declared_variables = declared_variables , declared_spiking = declared_spiking , update_method = update_method , spike_method = spike_method , reset_method = reset_method , ) return code","title":"generate()"},{"location":"contributing/generator/#ANNarchy_future.generator.SingleThread.PopulationGenerator.PopulationGenerator.reset","text":"Processes the Neuron.reset() field. Returns: Type Description str the whole reset() C++ method. Source code in ANNarchy_future/generator/SingleThread/PopulationGenerator.py def reset ( self ) -> str : \"\"\"Processes the Neuron.reset() field. Returns: the whole `reset()` C++ method. \"\"\" tpl_reset = Template ( \"\"\" // Reset void reset(){ for(unsigned int idx = 0; idx< this->spikes.size(); idx++){ int i = this->spikes[idx]; $reset } } \"\"\" ) # Equation template tpl_eq = Template ( \"\"\" // $hr $lhs $op $rhs; \"\"\" ) # Iterate over all blocks of equations code = \"\" for block in self . parser . reset_equations : for eq in block . equations : code += tpl_eq . substitute ( lhs = eq [ 'name' ] if eq [ 'name' ] in self . parser . shared else eq [ 'name' ] + \"[i]\" , op = eq [ 'op' ], rhs = parser . code_generation ( eq [ 'rhs' ], self . correspondences ), hr = eq [ 'human-readable' ] ) return tpl_reset . substitute ( reset = code )","title":"reset()"},{"location":"contributing/generator/#ANNarchy_future.generator.SingleThread.PopulationGenerator.PopulationGenerator.spike","text":"Processes the Neuron.spike() field. Returns: Type Description str the whole spike() C++ method. Source code in ANNarchy_future/generator/SingleThread/PopulationGenerator.py def spike ( self ) -> str : \"\"\"Processes the Neuron.spike() field. Returns: the whole `spike()` C++ method. \"\"\" tpl_spike = Template ( \"\"\" // Spike emission void spike(){ for(unsigned int i = 0; i< this->size; i++){ if ($condition){ this->spikes.push_back(i); } } } \"\"\" ) cond = parser . code_generation ( self . parser . spike_condition . equation [ 'eq' ], self . correspondences ) return tpl_spike . substitute ( condition = cond )","title":"spike()"},{"location":"contributing/generator/#ANNarchy_future.generator.SingleThread.PopulationGenerator.PopulationGenerator.update","text":"Processes the Neuron.update() field. Returns: Type Description str the content of the update() C++ method. Source code in ANNarchy_future/generator/SingleThread/PopulationGenerator.py def update ( self ) -> str : \"\"\"Processes the Neuron.update() field. Returns: the content of the `update()` C++ method. \"\"\" # Block template tlp_block = Template ( \"\"\" for(unsigned int i = 0; i< this->size; i++){ $update }\"\"\" ) # Equation template tpl_eq = Template ( \"\"\" // $hr $lhs $op $rhs; \"\"\" ) # Iterate over all blocks of equations code = \"\" for block in self . parser . update_equations : for eq in block . equations : # Temporary variables if eq [ 'type' ] == 'tmp' : code += tpl_eq . substitute ( lhs = \"double \" + eq [ 'name' ], op = eq [ 'op' ], rhs = parser . code_generation ( eq [ 'rhs' ], self . correspondences ), hr = eq [ 'human-readable' ] ) else : code += tpl_eq . substitute ( lhs = eq [ 'name' ] if eq [ 'name' ] in self . parser . shared else eq [ 'name' ] + \"[i]\" , op = eq [ 'op' ], rhs = parser . code_generation ( eq [ 'rhs' ], self . correspondences ), hr = eq [ 'human-readable' ] ) return tlp_block . substitute ( update = code )","title":"update()"},{"location":"contributing/generator/#ANNarchy_future.generator.SingleThread.ProjectionGenerator.ProjectionGenerator","text":"Generates a C++ file corresponding to a Synapse description. Attributes: Name Type Description name str name of the class. parser 'parser.SynapseParser' instance of SynapseParser. correspondences dictionary of pairs (symbol -> implementation).","title":"ProjectionGenerator"},{"location":"contributing/generator/#ANNarchy_future.generator.SingleThread.ProjectionGenerator.ProjectionGenerator.__init__","text":"Parameters: Name Type Description Default name str name of the class. required parser parser.SynapseParser parser for the synapse. required Source code in ANNarchy_future/generator/SingleThread/ProjectionGenerator.py def __init__ ( self , name : str , parser : 'parser.SynapseParser' ): \"\"\" Args: name (str): name of the class. parser (parser.SynapseParser): parser for the synapse. \"\"\" self . name : str = name self . parser : 'parser.SynapseParser' = parser # Build a correspondance dictionary self . correspondences = { 't' : 'this->t' , 'dt' : 'this->dt' , } for attr in self . parser . attributes : if attr in self . parser . shared : self . correspondences [ attr ] = \"this->\" + attr else : self . correspondences [ attr ] = \"this->\" + attr + \"[i][j]\" for attr in self . parser . synapse . pre_attributes : if attr in self . parser . pre . _parser . shared : self . correspondences [ \"pre.\" + attr ] = \"this->pre->\" + attr else : self . correspondences [ \"pre.\" + attr ] = \"this->pre->\" + attr + \"[i]\" for attr in self . parser . synapse . post_attributes : if attr in self . parser . post . _parser . shared : self . correspondences [ \"post.\" + attr ] = \"this->post->\" + attr else : self . correspondences [ \"post.\" + attr ] = \"this->post->\" + attr + \"[j]\"","title":"__init__()"},{"location":"contributing/generator/#ANNarchy_future.generator.SingleThread.ProjectionGenerator.ProjectionGenerator.generate","text":"Generates the C++ code. Calls: `self.update()` Returns: Type Description str a multiline string for the .h header file. Source code in ANNarchy_future/generator/SingleThread/ProjectionGenerator.py def generate ( self ) -> str : \"\"\"Generates the C++ code. Calls: `self.update()` Returns: a multiline string for the .h header file. \"\"\" # Get the template tpl = str ( ANNarchy_future . __path__ [ 0 ]) + '/generator/SingleThread/Projection.h' # Open the template with open ( tpl , 'r' ) as f : template = f . readlines () template = Template ( \"\" . join ( template )) # Initialize arrays initialize_arrays = \"\" # Parameters declared_parameters = \"\" for attr in self . parser . parameters : if attr in self . parser . shared : declared_parameters += Template ( \" double $attr; \\n \" ) . substitute ( attr = attr ) else : declared_parameters += Template ( \" std::vector<double> $attr; \\n \" ) . substitute ( attr = attr ) initialize_arrays += Template ( \" this->$attr = std::vector<double>(size, 0.0); \\n \" ) . substitute ( attr = attr ) # Variables declared_variables = \"\" for attr in self . parser . variables : if attr in self . parser . shared : declared_variables += Template ( \" double $attr; \\n \" ) . substitute ( attr = attr ) else : declared_variables += Template ( \" std::vector<double> $attr; \\n \" ) . substitute ( attr = attr ) initialize_arrays += Template ( \" this->$attr = std::vector<double>(size, 0.0); \\n \" ) . substitute ( attr = attr ) # Update method update_method = self . update () # Generate code code = template . substitute ( class_name = self . name , initialize_arrays = initialize_arrays , declared_parameters = declared_parameters , declared_variables = declared_variables , update_method = update_method , ) return code","title":"generate()"},{"location":"contributing/generator/#ANNarchy_future.generator.SingleThread.ProjectionGenerator.ProjectionGenerator.update","text":"Processes the Synapse.update() field. Returns: Type Description str the content of the update() C++ method. Source code in ANNarchy_future/generator/SingleThread/ProjectionGenerator.py def update ( self ) -> str : \"\"\"Processes the Synapse.update() field. Returns: the content of the `update()` C++ method. \"\"\" # Block template tlp_block = Template ( \"\"\" for(unsigned int i = 0; i< this->size; i++){ $update }\"\"\" ) # Equation template tpl_eq = Template ( \"\"\" // $hr $lhs $op $rhs; \"\"\" ) # Iterate over all blocks of equations code = \"\" for block in self . parser . update_equations : for eq in block . equations : # Temporary variables if eq [ 'type' ] == 'tmp' : code += tpl_eq . substitute ( lhs = \"double \" + eq [ 'name' ], op = eq [ 'op' ], rhs = parser . code_generation ( eq [ 'rhs' ], self . correspondences ), hr = eq [ 'human-readable' ] ) else : code += tpl_eq . substitute ( lhs = eq [ 'name' ] if eq [ 'name' ] in self . parser . shared else eq [ 'name' ] + \"[i]\" , op = eq [ 'op' ], rhs = parser . code_generation ( eq [ 'rhs' ], self . correspondences ), hr = eq [ 'human-readable' ] ) return tlp_block . substitute ( update = code )","title":"update()"},{"location":"contributing/parser/","text":"Parser \u00b6 Config \u00b6 ANNarchy_future . parser . Config . symbols_dict \u00b6 ANNarchy_future . parser . Config . reserved_attributes \u00b6 Neuron / synapse parsers \u00b6 ANNarchy_future.parser.NeuronParser.NeuronParser \u00b6 Neuron parser. Attributes: Name Type Description neuron api.Neuron Neuron class. name str name of the Neuron class. attributes list list of attributes (parameters and variables). parameters list list of parameters. variables list list of variables. inputs list list of input variables (conductances). outputs list list of output variables (firing rate). update_equations list update equations. spike_condition Condition spike condition. reset_equations list reset equations. __init__ ( self , neuron ) special \u00b6 Initializes the parser. Sets: self.neuron self.name Source code in ANNarchy_future/parser/NeuronParser.py def __init__ ( self , neuron : 'api.Neuron' ): \"\"\"Initializes the parser. Sets: * `self.neuron` * `self.name` \"\"\" self . neuron = neuron self . _spiking = False self . name = self . neuron . __class__ . __name__ # Logging self . _logger = logging . getLogger ( __name__ ) self . _logger . debug ( \"Neuron parser created.\" ) # Attributes self . attributes = [] self . parameters = [] self . variables = [] self . shared = [] self . inputs = [] self . outputs = [] # Equations to retrieve self . update_equations = [] self . spike_condition = [] self . reset_equations = [] analyse_equations ( self ) \u00b6 Analyses the neuron equations. Calls update(), spike() and reset() to retrieve the Equations objects. Sets: self.update_equations self.spike_condition self.reset_equations Source code in ANNarchy_future/parser/NeuronParser.py def analyse_equations ( self ): \"\"\"Analyses the neuron equations. Calls update(), spike() and reset() to retrieve the `Equations` objects. Sets: * `self.update_equations` * `self.spike_condition` * `self.reset_equations` \"\"\" # List of methods callables = [ f for f in dir ( self . neuron ) if callable ( getattr ( self . neuron , f ))] # Analyse update() if 'update' in callables : self . _logger . info ( \"Calling Neuron.update().\" ) try : self . neuron . update () except Exception : self . _logger . exception ( \"Unable to analyse \" + self . name + \".update()\" ) sys . exit ( 1 ) self . update_equations = self . process_equations ( self . neuron . _current_eq ) self . neuron . _current_eq = [] # For spiking neurons only if 'spike' in callables : self . _logger . info ( \"Neuron has a spike() method.\" ) self . _spiking = True self . _logger . info ( \"Calling Neuron.spike().\" ) # Analyse spike() try : self . neuron . spike () except Exception : self . _logger . exception ( \"Unable to analyse spike().\" ) sys . exit ( 1 ) self . spike_condition = self . process_condition ( self . neuron . _current_eq ) self . neuron . _current_eq = [] # Analyse reset() self . _logger . info ( \"Calling Neuron.reset().\" ) try : self . neuron . reset () except Exception : self . _logger . exception ( \"Unable to analyse reset().\" ) sys . exit ( 1 ) self . reset_equations = self . process_equations ( self . neuron . _current_eq ) self . neuron . _current_eq = [] extract_variables ( self ) \u00b6 Iterates over neuron.__dict__ and extracts all Parameter() and Variable() instances. Sets: self._spiking self.attributes self.parameters self.variables self.shared self.inputs self.outputs Source code in ANNarchy_future/parser/NeuronParser.py def extract_variables ( self ): \"\"\"Iterates over `neuron.__dict__` and extracts all `Parameter()` and `Variable()` instances. Sets: * `self._spiking` * `self.attributes` * `self.parameters` * `self.variables` * `self.shared` * `self.inputs` * `self.outputs` \"\"\" # List attributes current_attributes = list ( self . neuron . __dict__ . keys ()) for attr in current_attributes : var = getattr ( self . neuron , attr ) # Parameter if isinstance ( var , ( api . Parameter , )): self . parameters . append ( attr ) self . attributes . append ( attr ) # Variable if isinstance ( var , ( api . Variable , )): self . variables . append ( attr ) self . attributes . append ( attr ) if var in self . neuron . _inputs : self . inputs . append ( attr ) if var in self . neuron . _outputs : self . outputs . append ( attr ) # Shared variables for attr in self . attributes : if getattr ( self . neuron , attr ) . _shared : self . shared . append ( attr ) # Get lists of parameters and variables self . _logger . info ( \"Attributes: \" + str ( self . attributes )) self . _logger . info ( \"Parameters: \" + str ( self . parameters )) self . _logger . info ( \"Variables: \" + str ( self . variables )) # Set the attributes to the neuron self . neuron . attributes = self . attributes self . neuron . _parser = self is_spiking ( self ) \u00b6 Returns True if the Neuron class is spiking. Source code in ANNarchy_future/parser/NeuronParser.py def is_spiking ( self ) -> bool : \"Returns True if the Neuron class is spiking.\" return self . _spiking process_equations ( self , equations ) \u00b6 Checks all declared equations and applies a numerical method if necessary. Parameters: Name Type Description Default equations list of Equations objects. required Returns: Type Description list a list of blocks, which are lists of equations of three types: assignments, ODEs and conditions. Source code in ANNarchy_future/parser/NeuronParser.py def process_equations ( self , equations ) -> list : \"\"\"Checks all declared equations and applies a numerical method if necessary. Args: equations: list of Equations objects. Returns: a list of blocks, which are lists of equations of three types: assignments, ODEs and conditions. \"\"\" blocks = parser . get_blocks ( self , equations ) for block in blocks : block . dependencies () block . parse () return blocks ANNarchy_future.parser.SynapseParser.SynapseParser \u00b6 Synapse parser. Attributes: Name Type Description synapse api.Synapse Synapse class. pre api.Neuron pre-synaptic Neuron class. post api.Neuron post-synaptic Neuron class. name str name of the Neuron class attributes list list of attributes (parameters and variables) parameters list list of parameters variables list list of variables TODO update_equations list update equations. spike_condition Condition spike condition. reset_equations list reset equations. __init__ ( self , synapse , pre , post ) special \u00b6 Initializes the parser. Sets: self.synapse self.name Source code in ANNarchy_future/parser/SynapseParser.py def __init__ ( self , synapse : 'api.Synapse' , pre : 'api.Neuron' , post : 'api.Neuron' ): \"\"\"Initializes the parser. Sets: * `self.synapse` * `self.name` \"\"\" self . synapse = synapse self . pre = pre self . post = post self . _spiking = False self . name = self . synapse . __class__ . __name__ # Logging self . _logger = logging . getLogger ( __name__ ) self . _logger . debug ( \"Synapse parser created.\" ) # Attributes self . attributes = [] self . parameters = [] self . variables = [] self . shared = [] # Equations to retrieve self . update_equations = [] analyse_equations ( self ) \u00b6 Analyses the synapse equations. Calls update(), spike() and reset() to retrieve the Equations objects. Sets: self.update_equations self.spike_condition self.reset_equations Source code in ANNarchy_future/parser/SynapseParser.py def analyse_equations ( self ): \"\"\"Analyses the synapse equations. Calls update(), spike() and reset() to retrieve the `Equations` objects. Sets: * `self.update_equations` * `self.spike_condition` * `self.reset_equations` \"\"\" # List of methods callables = [ f for f in dir ( self . synapse ) if callable ( getattr ( self . synapse , f ))] if 'update' in callables : self . _logger . info ( \"Calling Synapse.update().\" ) try : self . synapse . update () except Exception : self . _logger . exception ( \"Error when parsing \" + self . name + \".update().\" ) sys . exit ( 1 ) else : self . update_equations = self . process_equations ( self . synapse . _current_eq ) self . synapse . _current_eq = [] extract_variables ( self ) \u00b6 Iterates over synapse.__dict__ and extracts all Parameter() and Variable() instances. Sets: self._spiking self.attributes self.parameters self.variables self.shared Source code in ANNarchy_future/parser/SynapseParser.py def extract_variables ( self ): \"\"\"Iterates over `synapse.__dict__` and extracts all `Parameter()` and `Variable()` instances. Sets: * `self._spiking` * `self.attributes` * `self.parameters` * `self.variables` * `self.shared` \"\"\" # List attributes current_attributes = list ( self . synapse . __dict__ . keys ()) for attr in current_attributes : # Parameter if isinstance ( getattr ( self . synapse , attr ), ( api . Parameter , )): self . parameters . append ( attr ) self . attributes . append ( attr ) # Variable if isinstance ( getattr ( self . synapse , attr ), ( api . Variable , )): self . variables . append ( attr ) self . attributes . append ( attr ) # Shared variables for attr in self . attributes : if getattr ( self . synapse , attr ) . _shared : self . shared . append ( attr ) # Get lists of parameters and variables self . _logger . info ( \"Attributes: \" + str ( self . attributes )) self . _logger . info ( \"Parameters: \" + str ( self . parameters )) self . _logger . info ( \"Variables: \" + str ( self . variables )) # Set the attributes to the synapse self . synapse . attributes = self . attributes self . synapse . pre_attributes = self . pre . attributes self . synapse . post_attributes = self . post . attributes self . synapse . _parser = self is_spiking ( self ) \u00b6 Returns True if the Neuron class is spiking. Source code in ANNarchy_future/parser/SynapseParser.py def is_spiking ( self ) -> bool : \"Returns True if the Neuron class is spiking.\" return self . _spiking process_equations ( self , equations ) \u00b6 Checks all declared equations and applies a numerical method if necessary. Parameters: Name Type Description Default equations list of Equations objects. required Returns: Type Description list a list of blocks, which are lists of equations of three types: assignments, ODEs and conditions. Source code in ANNarchy_future/parser/SynapseParser.py def process_equations ( self , equations ) -> list : \"\"\"Checks all declared equations and applies a numerical method if necessary. Args: equations: list of Equations objects. Returns: a list of blocks, which are lists of equations of three types: assignments, ODEs and conditions. \"\"\" blocks = [] # Iterate over the equations to group them into blocks for context in equations : _current_assignment_block = None _current_ODE_block = None for name , eq in context . equations : # ODE block if name . startswith ( \"d\" ) and name . endswith ( '_dt' ): if _current_assignment_block is not None : blocks . append ( _current_assignment_block ) _current_assignment_block = None if _current_ODE_block is None : _current_ODE_block = parser . ODEBlock ( self , context . method ) _current_ODE_block . add ( name [ 1 : - 3 ], eq ) # Assignment block else : if _current_ODE_block is not None : blocks . append ( _current_ODE_block ) _current_ODE_block = None if _current_assignment_block is None : _current_assignment_block = parser . AssignmentBlock ( self ) _current_assignment_block . add ( name , eq ) # Append the last block if _current_assignment_block is not None : blocks . append ( _current_assignment_block ) if _current_ODE_block is not None : blocks . append ( _current_ODE_block ) for block in blocks : block . dependencies () block . parse () return blocks Equation parser \u00b6 ANNarchy_future . parser . EquationParser . get_blocks ( parser , equations ) \u00b6 Splits multiple Equations() calls into blocks of AssignmentBlocks and ODEBlocks. Parameters: Name Type Description Default parser NeuronParser or SynapseParser parser. required equations list a list of Equations() contexts. required Returns: Type Description list A list of blocks. Source code in ANNarchy_future/parser/EquationParser.py def get_blocks ( parser , equations : list ) -> list : \"\"\"Splits multiple Equations() calls into blocks of AssignmentBlocks and ODEBlocks. Args: parser (NeuronParser or SynapseParser): parser. equations: a list of Equations() contexts. Returns: A list of blocks. \"\"\" blocks = [] # Iterate over the equations to group them into blocks for context in equations : _current_assignment_block = None _current_ODE_block = None for name , eq in context . equations : # ODE block if name . startswith ( \"d\" ) and name . endswith ( '_dt' ): if _current_assignment_block is not None : blocks . append ( _current_assignment_block ) _current_assignment_block = None if _current_ODE_block is None : _current_ODE_block = ODEBlock ( parser , context . method ) _current_ODE_block . add ( name [ 1 : - 3 ], eq ) # Assignment block else : if _current_ODE_block is not None : blocks . append ( _current_ODE_block ) _current_ODE_block = None if _current_assignment_block is None : _current_assignment_block = AssignmentBlock ( parser ) _current_assignment_block . add ( name , eq ) # Append the last block if _current_assignment_block is not None : blocks . append ( _current_assignment_block ) if _current_ODE_block is not None : blocks . append ( _current_ODE_block ) return blocks ANNarchy_future.parser.EquationParser.Condition \u00b6 Parser for single conditions. Examples: neuron.spike synapse.transmit __init__ ( self , parser , name , equation ) special \u00b6 Parameters: Name Type Description Default parser NeuronParser or SynapseParser parser. required name str name of the condition. required equation sympy.Expression condition. required Source code in ANNarchy_future/parser/EquationParser.py def __init__ ( self , parser , name : str , equation ): \"\"\" Args: parser (NeuronParser or SynapseParser): parser. name (str): name of the condition. equation (sympy.Expression): condition. \"\"\" self . parser = parser self . name = name self . _equation = equation parse ( self ) \u00b6 Parses the boolean condition. Source code in ANNarchy_future/parser/EquationParser.py def parse ( self ): \"Parses the boolean condition.\" hr = parser . ccode ( self . _equation ) self . equation = { 'name' : self . name , 'eq' : self . _equation , 'human-readable' : hr , } raw ( self ) \u00b6 Raw representation of the equation. Source code in ANNarchy_future/parser/EquationParser.py def raw ( self ): \"Raw representation of the equation.\" return self . equation [ 'human-readable' ] ANNarchy_future.parser.EquationParser.Block \u00b6 Base class for blocks. __init__ ( self , parser ) special \u00b6 Parameters: Name Type Description Default parser NeuronParser or SynapseParser parser. required Source code in ANNarchy_future/parser/EquationParser.py def __init__ ( self , parser ): \"\"\" Args: parser (NeuronParser or SynapseParser): parser. \"\"\" self . parser = parser self . _modified_variables = [] self . _dependencies = [] self . _equations = [] # Processed equations accessible from outside self . equations = [] add ( self , name , eq ) \u00b6 Adds a single equation to the block. Source code in ANNarchy_future/parser/EquationParser.py def add ( self , name , eq ): \"\"\"Adds a single equation to the block. \"\"\" self . _equations . append (( name , eq )) self . _modified_variables . append ( name ) dependencies ( self ) \u00b6 Sets all dependencies in the block in self._dependencies : Source code in ANNarchy_future/parser/EquationParser.py def dependencies ( self ): \"\"\" Sets all dependencies in the block in `self._dependencies`: \"\"\" for _ , eq in self . _equations : try : symbols = list ( eq . free_symbols ) except : # e.g. v = 0 would return an int, so free_symbols is not set continue for symbol in symbols : if symbol in self . parser . attributes : self . _dependencies . append ( symbol ) self . _dependencies = list ( set ( self . _dependencies )) raw ( self ) \u00b6 Raw representation of the equations. Source code in ANNarchy_future/parser/EquationParser.py def raw ( self ): \"Raw representation of the equations.\" code = \"\" for name , eq in self . _equations : code += name + \" = \" + \" \" . join ( sp . ccode ( eq ) . replace ( ' \\n ' , ' ' ) . split ()) + \" \\n \" return code ANNarchy_future.parser.EquationParser.AssignmentBlock \u00b6 Block of assignments. parse ( self ) \u00b6 Parses the block of assignments. Source code in ANNarchy_future/parser/EquationParser.py def parse ( self ): \"\"\"Parses the block of assignments. \"\"\" for name , eq in self . _equations : hr = name + \" = \" + parser . ccode ( eq ) self . equations . append ( { 'type' : 'assignment' , 'name' : name , 'op' : \"=\" , 'rhs' : eq , 'human-readable' : hr , } ) ANNarchy_future.parser.EquationParser.ODEBlock \u00b6 Block of ODEs. __init__ ( self , parser , method ) special \u00b6 Parameters: Name Type Description Default parser NeuronParser or SynapseParser parser. required method str numerical method. required Source code in ANNarchy_future/parser/EquationParser.py def __init__ ( self , parser , method ): \"\"\" Args: parser (NeuronParser or SynapseParser): parser. method (str): numerical method. \"\"\" self . method = method super ( ODEBlock , self ) . __init__ ( parser ) parse ( self ) \u00b6 Parses the block of ODEs by calling the numerical method. Source code in ANNarchy_future/parser/EquationParser.py def parse ( self ): \"\"\"Parses the block of ODEs by calling the numerical method. \"\"\" if self . method == 'euler' : self . equations = parser . NM . euler ( self . _equations ) elif self . method == 'exponential' : self . equations = parser . NM . exponential ( self . _equations ) elif self . method == 'midpoint' : self . equations = parser . NM . midpoint ( self . _equations ) elif self . method == 'rk4' : self . equations = parser . NM . rk4 ( self . _equations ) else : self . parser . logger . error ( self . method + \" is not implemented yet.\" ) sys . exit ( 1 ) Numerical methods \u00b6 ANNarchy_future . parser . NumericalMethods . euler ( equations ) \u00b6 Source code in ANNarchy_future/parser/NumericalMethods.py def euler ( equations ): gradients = [] updates = [] if len ( equations ) == 0 : pass elif len ( equations ) == 1 : name , eq = equations [ 0 ] # Update the variable update = sp . Symbol ( 'dt' ) * eq update_hr = name + \" += \" + parser . ccode ( update ) updates . append ( { 'type' : 'assignment' , 'name' : name , 'op' : \"+=\" , 'rhs' : update , 'human-readable' : update_hr , } ) else : # More than one equation for name , eq in equations : # Compute the gradient gradient_var = \"__k__\" + name gradient_hr = gradient_var + \" = \" + parser . ccode ( eq ) # Update the variable update = sp . Symbol ( 'dt' ) * sp . Symbol ( gradient_var ) update_hr = name + \" += \" + parser . ccode ( update ) gradients . append ( { 'type' : 'tmp' , 'name' : gradient_var , 'op' : \"=\" , 'rhs' : eq , 'human-readable' : gradient_hr , } ) updates . append ( { 'type' : 'assignment' , 'name' : name , 'op' : \"+=\" , 'rhs' : update , 'human-readable' : update_hr , } ) # Gather equations in the right order processed_equations = [] for gradient in gradients : processed_equations . append ( gradient ) for update in updates : processed_equations . append ( update ) return processed_equations ANNarchy_future . parser . NumericalMethods . exponential ( equations ) \u00b6 Source code in ANNarchy_future/parser/NumericalMethods.py def exponential ( equations ): gradients = [] updates = [] for name , eq in equations : # Gradient is of the form v' = (A - v)/tau # Expand the equation to better find the time constant: # v' = A/tau - v/tau expanded = eq . expand ( modulus = None , power_base = False , power_exp = False , mul = True , log = False , multinomial = False ) # Current variable v var = sp . Symbol ( name ) # Gradient name gradient_var = \"__k__\" + name # Factorize over the variable v: X*1 - v/tau collected_var = sp . collect ( expanded , var , evaluate = False , exact = False ) # Inverse the factor multiplying v to get tau tau = - 1 / collected_var [ var ] # Step size is (1 - exp(-dt/tau)) step_size = sp . simplify ( 1. - sp . exp ( - sp . Symbol ( 'dt' ) / tau )) # Multiply the gradient by tau to get (A - v) steady = sp . simplify ( tau * expanded ) # Compute the gradient v' = (1- exp(-dt/tau))*(A - v) gradient = step_size * steady gradient_hr = gradient_var + \" = \" + parser . ccode ( gradient ) # Update the variable r += v' update_hr = name + \" += \" + gradient_var gradients . append ( { 'type' : 'tmp' , 'name' : gradient_var , 'op' : \"=\" , 'rhs' : gradient , 'human-readable' : gradient_hr , } ) updates . append ( { 'type' : 'assignment' , 'name' : name , 'op' : \"+=\" , 'rhs' : sp . Symbol ( gradient_var ), 'human-readable' : update_hr , } ) # Gather equations in the right order processed_equations = [] for gradient in gradients : processed_equations . append ( gradient ) for update in updates : processed_equations . append ( update ) return processed_equations ANNarchy_future . parser . NumericalMethods . midpoint ( equations ) \u00b6 Source code in ANNarchy_future/parser/NumericalMethods.py def midpoint ( equations ): midpoints = [] midpoint_vars = {} updates = [] for name , eq in equations : # Current symbol v var = sp . Symbol ( name ) # Midpoint name midpoint_var = \"__k1__\" + name midpoint_vars [ var ] = sp . Symbol ( midpoint_var ) # Compute v + dt/2*v' midpoint = var + sp . Symbol ( 'dt' ) * eq / 2.0 midpoint_hr = midpoint_var + \" = \" + parser . ccode ( midpoint ) midpoints . append ( { 'type' : 'tmp' , 'name' : midpoint_var , 'op' : \"=\" , 'rhs' : midpoint , 'human-readable' : midpoint_hr , } ) for name , eq in equations : # Evaluate gradient in v + dt/2*v' new_eq = sp . Symbol ( 'dt' ) * eq . subs ( midpoint_vars ) # Human readable update_hr = name + \" += \" + parser . ccode ( new_eq ) updates . append ( { 'type' : 'assignment' , 'name' : name , 'op' : \"+=\" , 'rhs' : new_eq , 'human-readable' : update_hr , } ) # Gather equations in the right order processed_equations = [] for midpoint in midpoints : processed_equations . append ( midpoint ) for update in updates : processed_equations . append ( update ) return processed_equations ANNarchy_future . parser . NumericalMethods . rk4 ( equations ) \u00b6 Source code in ANNarchy_future/parser/NumericalMethods.py def rk4 ( equations ): k1s = [] k2s = [] k3s = [] k4s = [] p2s = [] p3s = [] p4s = [] k2_vars = {} k3_vars = {} k4_vars = {} updates = [] # k1 = f'(x, y) for name , eq in equations : # Current symbol v var = sp . Symbol ( name ) # k1 k1_var = \"__k1__\" + name p2_var = \"__p2__\" + name k2_vars [ var ] = sp . Symbol ( p2_var ) p2 = var + sp . Symbol ( 'dt' ) * sp . Symbol ( k1_var ) / 2.0 k1_hr = k1_var + \" = \" + parser . ccode ( eq ) p2_hr = p2_var + \" = \" + parser . ccode ( p2 ) k1s . append ( { 'type' : 'tmp' , 'name' : k1_var , 'op' : \"=\" , 'rhs' : eq , 'human-readable' : k1_hr , } ) p2s . append ( { 'type' : 'tmp' , 'name' : p2_var , 'op' : \"=\" , 'rhs' : p2 , 'human-readable' : p2_hr , } ) # k2 = f'(x + dt*k1/2, y + dt*k1/2) for name , eq in equations : # Current symbol v var = sp . Symbol ( name ) # Compute v + dt/2*v' k2 = sp . simplify ( eq . subs ( k2_vars )) # k1 k2_var = \"__k2__\" + name p3_var = \"__p3__\" + name k3_vars [ var ] = sp . Symbol ( p3_var ) p3 = var + sp . Symbol ( 'dt' ) * sp . Symbol ( k2_var ) / 2.0 k2_hr = k2_var + \" = \" + parser . ccode ( k2 ) p3_hr = p3_var + \" = \" + parser . ccode ( p3 ) k2s . append ( { 'type' : 'tmp' , 'name' : k2_var , 'op' : \"=\" , 'rhs' : k2 , 'human-readable' : k2_hr , } ) p3s . append ( { 'type' : 'tmp' , 'name' : p3_var , 'op' : \"=\" , 'rhs' : p3 , 'human-readable' : p3_hr , } ) # k3 = f'(x + dt*k2/2, y + dt*k2/2) for name , eq in equations : # Current symbol v var = sp . Symbol ( name ) # Substitute k3 = sp . simplify ( eq . subs ( k3_vars )) # k3 k3_var = \"__k3__\" + name p4_var = \"__p4__\" + name k4_vars [ var ] = sp . Symbol ( p4_var ) p4 = var + sp . Symbol ( 'dt' ) * sp . Symbol ( k3_var ) k3_hr = k3_var + \" = \" + parser . ccode ( k3 ) p4_hr = p4_var + \" = \" + parser . ccode ( p4 ) k3s . append ( { 'type' : 'tmp' , 'name' : k3_var , 'op' : \"=\" , 'rhs' : k3 , 'human-readable' : k3_hr , } ) p4s . append ( { 'type' : 'tmp' , 'name' : p4_var , 'op' : \"=\" , 'rhs' : p4 , 'human-readable' : p4_hr , } ) # k4 = f'(x + dt*k3, y + dt*k3) for name , eq in equations : # Current symbol v var = sp . Symbol ( name ) # Substitute k4 = sp . simplify ( eq . subs ( k4_vars )) # k4 k4_var = \"__k4__\" + name k4_hr = k4_var + \" = \" + parser . ccode ( k4 ) k4s . append ( { 'type' : 'tmp' , 'name' : k4_var , 'op' : \"=\" , 'rhs' : k4 , 'human-readable' : k4_hr , } ) for name , eq in equations : # tmp vars var = sp . Symbol ( name ) k1 = sp . Symbol ( \"__k1__\" + name ) k2 = sp . Symbol ( \"__k2__\" + name ) k3 = sp . Symbol ( \"__k3__\" + name ) k4 = sp . Symbol ( \"__k4__\" + name ) # Evaluate gradient in v + dt/2*v' new_eq = sp . Symbol ( 'dt' ) * ( k1 + 2 * k2 + 2 * k3 + k4 ) / sp . Symbol ( \"6.0\" ) # Human readable update_hr = name + \" += \" + parser . ccode ( new_eq ) updates . append ( { 'type' : 'assignment' , 'name' : name , 'op' : \"+=\" , 'rhs' : new_eq , 'human-readable' : update_hr , } ) # Gather equations in the right order processed_equations = [] for k1 in k1s : processed_equations . append ( k1 ) for p2 in p2s : processed_equations . append ( p2 ) for k2 in k2s : processed_equations . append ( k2 ) for p3 in p3s : processed_equations . append ( p3 ) for k3 in k3s : processed_equations . append ( k3 ) for p4 in p4s : processed_equations . append ( p4 ) for k4 in k4s : processed_equations . append ( k4 ) for update in updates : processed_equations . append ( update ) return processed_equations Code generation \u00b6 ANNarchy_future . parser . CodeGeneration . ccode ( eq ) \u00b6 Transforms a sympy expression into C99 code. Applies C99 optimizations ( sympy.codegen.rewriting.optims_c99 ). Expands pow(x; 2) into x*x and pow(x, 3) into x*x*x for performance. Parameters: Name Type Description Default eq sympy expression expression to convert. required Returns: Type Description str a string representing the C code. Source code in ANNarchy_future/parser/CodeGeneration.py def ccode ( eq ) -> str : \"\"\"Transforms a sympy expression into C99 code. Applies C99 optimizations (`sympy.codegen.rewriting.optims_c99`). Expands `pow(x; 2)` into `x*x` and `pow(x, 3)` into `x*x*x` for performance. Args: eq (sympy expression): expression to convert. Returns: a string representing the C code. \"\"\" # If the rhs is a int or float (v = 0.0), cast it to a symbol to avoid numerical errors. if isinstance ( eq , ( float )): eq = sp . Symbol ( str ( float ( eq ))) elif isinstance ( eq , ( int )): eq = sp . Symbol ( str ( int ( eq ))) # Optimize for C99 try : eq = optimize ( eq , optims_c99 ) except : logger = logging . getLogger ( __name__ ) logger . exception ( str ( eq )) sys . exit ( 1 ) # Explicitly expand the use of pow(x, 2) pow2 = ReplaceOptim ( lambda p : p . is_Pow and p . exp == 2 , lambda p : UnevaluatedExpr ( Mul ( p . base , p . base , evaluate = False )) ) eq = pow2 ( eq ) # Explicitly expand the use of pow(x, 3) pow3 = ReplaceOptim ( lambda p : p . is_Pow and p . exp == 3 , lambda p : UnevaluatedExpr ( Mul ( Mul ( p . base , p . base , evaluate = False ), p . base , evaluate = False )) ) eq = pow3 ( eq ) # Get the equivalent C code eq = sp . ccode ( eq ) # Remove the extralines of Piecewise return \" \" . join ( eq . replace ( ' \\n ' , ' ' ) . split ()) ANNarchy_future . parser . CodeGeneration . code_generation ( eq , correspondance = {}) \u00b6 Gets a dictionary of correspondances and changes all symbols in the sympy expression. Calls eq.subs() and ccode . Parameters: Name Type Description Default eq sympy expression expression. required correspondance dict dictionary of correspondances. {} Returns: Type Description str a string representing the C code. Examples: >>> code_generation ( sp . Symbol ( tau ) * sp . Symbol ( r ), { 'tau' : 'this->tau' , 'r' : 'this->r[i]' }) this -> tau * this -> r [ i ] Source code in ANNarchy_future/parser/CodeGeneration.py def code_generation ( eq , correspondance : dict = {}) -> str : \"\"\"Gets a dictionary of correspondances and changes all symbols in the sympy expression. Calls `eq.subs()` and `ccode`. Args: eq (sympy expression): expression. correspondance (dict): dictionary of correspondances. Returns: a string representing the C code. Example: >>> code_generation( sp.Symbol(tau) * sp.Symbol(r), {'tau': 'this->tau', 'r': 'this->r[i]'}) this->tau*this->r[i] \"\"\" # If the rhs is a int or float (v = 0.0), cast it to a symbol to avoid numerical errors. if isinstance ( eq , ( float )): eq = sp . Symbol ( str ( float ( eq ))) elif isinstance ( eq , ( int )): eq = sp . Symbol ( str ( int ( eq ))) # Build a dictionary of sp.Symbols() replacements = {} for pre , post in correspondance . items (): replacements [ sp . Symbol ( pre )] = sp . Symbol ( post ) # Replace the symbols new_eq = eq . subs ( replacements ) return ccode ( new_eq )","title":"Parser"},{"location":"contributing/parser/#parser","text":"","title":"Parser"},{"location":"contributing/parser/#config","text":"","title":"Config"},{"location":"contributing/parser/#ANNarchy_future.parser.Config.symbols_dict","text":"","title":"symbols_dict"},{"location":"contributing/parser/#ANNarchy_future.parser.Config.reserved_attributes","text":"","title":"reserved_attributes"},{"location":"contributing/parser/#neuron-synapse-parsers","text":"","title":"Neuron / synapse parsers"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser","text":"Neuron parser. Attributes: Name Type Description neuron api.Neuron Neuron class. name str name of the Neuron class. attributes list list of attributes (parameters and variables). parameters list list of parameters. variables list list of variables. inputs list list of input variables (conductances). outputs list list of output variables (firing rate). update_equations list update equations. spike_condition Condition spike condition. reset_equations list reset equations.","title":"NeuronParser"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.__init__","text":"Initializes the parser. Sets: self.neuron self.name Source code in ANNarchy_future/parser/NeuronParser.py def __init__ ( self , neuron : 'api.Neuron' ): \"\"\"Initializes the parser. Sets: * `self.neuron` * `self.name` \"\"\" self . neuron = neuron self . _spiking = False self . name = self . neuron . __class__ . __name__ # Logging self . _logger = logging . getLogger ( __name__ ) self . _logger . debug ( \"Neuron parser created.\" ) # Attributes self . attributes = [] self . parameters = [] self . variables = [] self . shared = [] self . inputs = [] self . outputs = [] # Equations to retrieve self . update_equations = [] self . spike_condition = [] self . reset_equations = []","title":"__init__()"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.analyse_equations","text":"Analyses the neuron equations. Calls update(), spike() and reset() to retrieve the Equations objects. Sets: self.update_equations self.spike_condition self.reset_equations Source code in ANNarchy_future/parser/NeuronParser.py def analyse_equations ( self ): \"\"\"Analyses the neuron equations. Calls update(), spike() and reset() to retrieve the `Equations` objects. Sets: * `self.update_equations` * `self.spike_condition` * `self.reset_equations` \"\"\" # List of methods callables = [ f for f in dir ( self . neuron ) if callable ( getattr ( self . neuron , f ))] # Analyse update() if 'update' in callables : self . _logger . info ( \"Calling Neuron.update().\" ) try : self . neuron . update () except Exception : self . _logger . exception ( \"Unable to analyse \" + self . name + \".update()\" ) sys . exit ( 1 ) self . update_equations = self . process_equations ( self . neuron . _current_eq ) self . neuron . _current_eq = [] # For spiking neurons only if 'spike' in callables : self . _logger . info ( \"Neuron has a spike() method.\" ) self . _spiking = True self . _logger . info ( \"Calling Neuron.spike().\" ) # Analyse spike() try : self . neuron . spike () except Exception : self . _logger . exception ( \"Unable to analyse spike().\" ) sys . exit ( 1 ) self . spike_condition = self . process_condition ( self . neuron . _current_eq ) self . neuron . _current_eq = [] # Analyse reset() self . _logger . info ( \"Calling Neuron.reset().\" ) try : self . neuron . reset () except Exception : self . _logger . exception ( \"Unable to analyse reset().\" ) sys . exit ( 1 ) self . reset_equations = self . process_equations ( self . neuron . _current_eq ) self . neuron . _current_eq = []","title":"analyse_equations()"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.extract_variables","text":"Iterates over neuron.__dict__ and extracts all Parameter() and Variable() instances. Sets: self._spiking self.attributes self.parameters self.variables self.shared self.inputs self.outputs Source code in ANNarchy_future/parser/NeuronParser.py def extract_variables ( self ): \"\"\"Iterates over `neuron.__dict__` and extracts all `Parameter()` and `Variable()` instances. Sets: * `self._spiking` * `self.attributes` * `self.parameters` * `self.variables` * `self.shared` * `self.inputs` * `self.outputs` \"\"\" # List attributes current_attributes = list ( self . neuron . __dict__ . keys ()) for attr in current_attributes : var = getattr ( self . neuron , attr ) # Parameter if isinstance ( var , ( api . Parameter , )): self . parameters . append ( attr ) self . attributes . append ( attr ) # Variable if isinstance ( var , ( api . Variable , )): self . variables . append ( attr ) self . attributes . append ( attr ) if var in self . neuron . _inputs : self . inputs . append ( attr ) if var in self . neuron . _outputs : self . outputs . append ( attr ) # Shared variables for attr in self . attributes : if getattr ( self . neuron , attr ) . _shared : self . shared . append ( attr ) # Get lists of parameters and variables self . _logger . info ( \"Attributes: \" + str ( self . attributes )) self . _logger . info ( \"Parameters: \" + str ( self . parameters )) self . _logger . info ( \"Variables: \" + str ( self . variables )) # Set the attributes to the neuron self . neuron . attributes = self . attributes self . neuron . _parser = self","title":"extract_variables()"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.is_spiking","text":"Returns True if the Neuron class is spiking. Source code in ANNarchy_future/parser/NeuronParser.py def is_spiking ( self ) -> bool : \"Returns True if the Neuron class is spiking.\" return self . _spiking","title":"is_spiking()"},{"location":"contributing/parser/#ANNarchy_future.parser.NeuronParser.NeuronParser.process_equations","text":"Checks all declared equations and applies a numerical method if necessary. Parameters: Name Type Description Default equations list of Equations objects. required Returns: Type Description list a list of blocks, which are lists of equations of three types: assignments, ODEs and conditions. Source code in ANNarchy_future/parser/NeuronParser.py def process_equations ( self , equations ) -> list : \"\"\"Checks all declared equations and applies a numerical method if necessary. Args: equations: list of Equations objects. Returns: a list of blocks, which are lists of equations of three types: assignments, ODEs and conditions. \"\"\" blocks = parser . get_blocks ( self , equations ) for block in blocks : block . dependencies () block . parse () return blocks","title":"process_equations()"},{"location":"contributing/parser/#ANNarchy_future.parser.SynapseParser.SynapseParser","text":"Synapse parser. Attributes: Name Type Description synapse api.Synapse Synapse class. pre api.Neuron pre-synaptic Neuron class. post api.Neuron post-synaptic Neuron class. name str name of the Neuron class attributes list list of attributes (parameters and variables) parameters list list of parameters variables list list of variables TODO update_equations list update equations. spike_condition Condition spike condition. reset_equations list reset equations.","title":"SynapseParser"},{"location":"contributing/parser/#ANNarchy_future.parser.SynapseParser.SynapseParser.__init__","text":"Initializes the parser. Sets: self.synapse self.name Source code in ANNarchy_future/parser/SynapseParser.py def __init__ ( self , synapse : 'api.Synapse' , pre : 'api.Neuron' , post : 'api.Neuron' ): \"\"\"Initializes the parser. Sets: * `self.synapse` * `self.name` \"\"\" self . synapse = synapse self . pre = pre self . post = post self . _spiking = False self . name = self . synapse . __class__ . __name__ # Logging self . _logger = logging . getLogger ( __name__ ) self . _logger . debug ( \"Synapse parser created.\" ) # Attributes self . attributes = [] self . parameters = [] self . variables = [] self . shared = [] # Equations to retrieve self . update_equations = []","title":"__init__()"},{"location":"contributing/parser/#ANNarchy_future.parser.SynapseParser.SynapseParser.analyse_equations","text":"Analyses the synapse equations. Calls update(), spike() and reset() to retrieve the Equations objects. Sets: self.update_equations self.spike_condition self.reset_equations Source code in ANNarchy_future/parser/SynapseParser.py def analyse_equations ( self ): \"\"\"Analyses the synapse equations. Calls update(), spike() and reset() to retrieve the `Equations` objects. Sets: * `self.update_equations` * `self.spike_condition` * `self.reset_equations` \"\"\" # List of methods callables = [ f for f in dir ( self . synapse ) if callable ( getattr ( self . synapse , f ))] if 'update' in callables : self . _logger . info ( \"Calling Synapse.update().\" ) try : self . synapse . update () except Exception : self . _logger . exception ( \"Error when parsing \" + self . name + \".update().\" ) sys . exit ( 1 ) else : self . update_equations = self . process_equations ( self . synapse . _current_eq ) self . synapse . _current_eq = []","title":"analyse_equations()"},{"location":"contributing/parser/#ANNarchy_future.parser.SynapseParser.SynapseParser.extract_variables","text":"Iterates over synapse.__dict__ and extracts all Parameter() and Variable() instances. Sets: self._spiking self.attributes self.parameters self.variables self.shared Source code in ANNarchy_future/parser/SynapseParser.py def extract_variables ( self ): \"\"\"Iterates over `synapse.__dict__` and extracts all `Parameter()` and `Variable()` instances. Sets: * `self._spiking` * `self.attributes` * `self.parameters` * `self.variables` * `self.shared` \"\"\" # List attributes current_attributes = list ( self . synapse . __dict__ . keys ()) for attr in current_attributes : # Parameter if isinstance ( getattr ( self . synapse , attr ), ( api . Parameter , )): self . parameters . append ( attr ) self . attributes . append ( attr ) # Variable if isinstance ( getattr ( self . synapse , attr ), ( api . Variable , )): self . variables . append ( attr ) self . attributes . append ( attr ) # Shared variables for attr in self . attributes : if getattr ( self . synapse , attr ) . _shared : self . shared . append ( attr ) # Get lists of parameters and variables self . _logger . info ( \"Attributes: \" + str ( self . attributes )) self . _logger . info ( \"Parameters: \" + str ( self . parameters )) self . _logger . info ( \"Variables: \" + str ( self . variables )) # Set the attributes to the synapse self . synapse . attributes = self . attributes self . synapse . pre_attributes = self . pre . attributes self . synapse . post_attributes = self . post . attributes self . synapse . _parser = self","title":"extract_variables()"},{"location":"contributing/parser/#ANNarchy_future.parser.SynapseParser.SynapseParser.is_spiking","text":"Returns True if the Neuron class is spiking. Source code in ANNarchy_future/parser/SynapseParser.py def is_spiking ( self ) -> bool : \"Returns True if the Neuron class is spiking.\" return self . _spiking","title":"is_spiking()"},{"location":"contributing/parser/#ANNarchy_future.parser.SynapseParser.SynapseParser.process_equations","text":"Checks all declared equations and applies a numerical method if necessary. Parameters: Name Type Description Default equations list of Equations objects. required Returns: Type Description list a list of blocks, which are lists of equations of three types: assignments, ODEs and conditions. Source code in ANNarchy_future/parser/SynapseParser.py def process_equations ( self , equations ) -> list : \"\"\"Checks all declared equations and applies a numerical method if necessary. Args: equations: list of Equations objects. Returns: a list of blocks, which are lists of equations of three types: assignments, ODEs and conditions. \"\"\" blocks = [] # Iterate over the equations to group them into blocks for context in equations : _current_assignment_block = None _current_ODE_block = None for name , eq in context . equations : # ODE block if name . startswith ( \"d\" ) and name . endswith ( '_dt' ): if _current_assignment_block is not None : blocks . append ( _current_assignment_block ) _current_assignment_block = None if _current_ODE_block is None : _current_ODE_block = parser . ODEBlock ( self , context . method ) _current_ODE_block . add ( name [ 1 : - 3 ], eq ) # Assignment block else : if _current_ODE_block is not None : blocks . append ( _current_ODE_block ) _current_ODE_block = None if _current_assignment_block is None : _current_assignment_block = parser . AssignmentBlock ( self ) _current_assignment_block . add ( name , eq ) # Append the last block if _current_assignment_block is not None : blocks . append ( _current_assignment_block ) if _current_ODE_block is not None : blocks . append ( _current_ODE_block ) for block in blocks : block . dependencies () block . parse () return blocks","title":"process_equations()"},{"location":"contributing/parser/#equation-parser","text":"","title":"Equation parser"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.get_blocks","text":"Splits multiple Equations() calls into blocks of AssignmentBlocks and ODEBlocks. Parameters: Name Type Description Default parser NeuronParser or SynapseParser parser. required equations list a list of Equations() contexts. required Returns: Type Description list A list of blocks. Source code in ANNarchy_future/parser/EquationParser.py def get_blocks ( parser , equations : list ) -> list : \"\"\"Splits multiple Equations() calls into blocks of AssignmentBlocks and ODEBlocks. Args: parser (NeuronParser or SynapseParser): parser. equations: a list of Equations() contexts. Returns: A list of blocks. \"\"\" blocks = [] # Iterate over the equations to group them into blocks for context in equations : _current_assignment_block = None _current_ODE_block = None for name , eq in context . equations : # ODE block if name . startswith ( \"d\" ) and name . endswith ( '_dt' ): if _current_assignment_block is not None : blocks . append ( _current_assignment_block ) _current_assignment_block = None if _current_ODE_block is None : _current_ODE_block = ODEBlock ( parser , context . method ) _current_ODE_block . add ( name [ 1 : - 3 ], eq ) # Assignment block else : if _current_ODE_block is not None : blocks . append ( _current_ODE_block ) _current_ODE_block = None if _current_assignment_block is None : _current_assignment_block = AssignmentBlock ( parser ) _current_assignment_block . add ( name , eq ) # Append the last block if _current_assignment_block is not None : blocks . append ( _current_assignment_block ) if _current_ODE_block is not None : blocks . append ( _current_ODE_block ) return blocks","title":"get_blocks()"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.Condition","text":"Parser for single conditions. Examples: neuron.spike synapse.transmit","title":"Condition"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.Condition.__init__","text":"Parameters: Name Type Description Default parser NeuronParser or SynapseParser parser. required name str name of the condition. required equation sympy.Expression condition. required Source code in ANNarchy_future/parser/EquationParser.py def __init__ ( self , parser , name : str , equation ): \"\"\" Args: parser (NeuronParser or SynapseParser): parser. name (str): name of the condition. equation (sympy.Expression): condition. \"\"\" self . parser = parser self . name = name self . _equation = equation","title":"__init__()"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.Condition.parse","text":"Parses the boolean condition. Source code in ANNarchy_future/parser/EquationParser.py def parse ( self ): \"Parses the boolean condition.\" hr = parser . ccode ( self . _equation ) self . equation = { 'name' : self . name , 'eq' : self . _equation , 'human-readable' : hr , }","title":"parse()"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.Condition.raw","text":"Raw representation of the equation. Source code in ANNarchy_future/parser/EquationParser.py def raw ( self ): \"Raw representation of the equation.\" return self . equation [ 'human-readable' ]","title":"raw()"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.Block","text":"Base class for blocks.","title":"Block"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.Block.__init__","text":"Parameters: Name Type Description Default parser NeuronParser or SynapseParser parser. required Source code in ANNarchy_future/parser/EquationParser.py def __init__ ( self , parser ): \"\"\" Args: parser (NeuronParser or SynapseParser): parser. \"\"\" self . parser = parser self . _modified_variables = [] self . _dependencies = [] self . _equations = [] # Processed equations accessible from outside self . equations = []","title":"__init__()"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.Block.add","text":"Adds a single equation to the block. Source code in ANNarchy_future/parser/EquationParser.py def add ( self , name , eq ): \"\"\"Adds a single equation to the block. \"\"\" self . _equations . append (( name , eq )) self . _modified_variables . append ( name )","title":"add()"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.Block.dependencies","text":"Sets all dependencies in the block in self._dependencies : Source code in ANNarchy_future/parser/EquationParser.py def dependencies ( self ): \"\"\" Sets all dependencies in the block in `self._dependencies`: \"\"\" for _ , eq in self . _equations : try : symbols = list ( eq . free_symbols ) except : # e.g. v = 0 would return an int, so free_symbols is not set continue for symbol in symbols : if symbol in self . parser . attributes : self . _dependencies . append ( symbol ) self . _dependencies = list ( set ( self . _dependencies ))","title":"dependencies()"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.Block.raw","text":"Raw representation of the equations. Source code in ANNarchy_future/parser/EquationParser.py def raw ( self ): \"Raw representation of the equations.\" code = \"\" for name , eq in self . _equations : code += name + \" = \" + \" \" . join ( sp . ccode ( eq ) . replace ( ' \\n ' , ' ' ) . split ()) + \" \\n \" return code","title":"raw()"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.AssignmentBlock","text":"Block of assignments.","title":"AssignmentBlock"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.AssignmentBlock.parse","text":"Parses the block of assignments. Source code in ANNarchy_future/parser/EquationParser.py def parse ( self ): \"\"\"Parses the block of assignments. \"\"\" for name , eq in self . _equations : hr = name + \" = \" + parser . ccode ( eq ) self . equations . append ( { 'type' : 'assignment' , 'name' : name , 'op' : \"=\" , 'rhs' : eq , 'human-readable' : hr , } )","title":"parse()"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.ODEBlock","text":"Block of ODEs.","title":"ODEBlock"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.ODEBlock.__init__","text":"Parameters: Name Type Description Default parser NeuronParser or SynapseParser parser. required method str numerical method. required Source code in ANNarchy_future/parser/EquationParser.py def __init__ ( self , parser , method ): \"\"\" Args: parser (NeuronParser or SynapseParser): parser. method (str): numerical method. \"\"\" self . method = method super ( ODEBlock , self ) . __init__ ( parser )","title":"__init__()"},{"location":"contributing/parser/#ANNarchy_future.parser.EquationParser.ODEBlock.parse","text":"Parses the block of ODEs by calling the numerical method. Source code in ANNarchy_future/parser/EquationParser.py def parse ( self ): \"\"\"Parses the block of ODEs by calling the numerical method. \"\"\" if self . method == 'euler' : self . equations = parser . NM . euler ( self . _equations ) elif self . method == 'exponential' : self . equations = parser . NM . exponential ( self . _equations ) elif self . method == 'midpoint' : self . equations = parser . NM . midpoint ( self . _equations ) elif self . method == 'rk4' : self . equations = parser . NM . rk4 ( self . _equations ) else : self . parser . logger . error ( self . method + \" is not implemented yet.\" ) sys . exit ( 1 )","title":"parse()"},{"location":"contributing/parser/#numerical-methods","text":"","title":"Numerical methods"},{"location":"contributing/parser/#ANNarchy_future.parser.NumericalMethods.euler","text":"Source code in ANNarchy_future/parser/NumericalMethods.py def euler ( equations ): gradients = [] updates = [] if len ( equations ) == 0 : pass elif len ( equations ) == 1 : name , eq = equations [ 0 ] # Update the variable update = sp . Symbol ( 'dt' ) * eq update_hr = name + \" += \" + parser . ccode ( update ) updates . append ( { 'type' : 'assignment' , 'name' : name , 'op' : \"+=\" , 'rhs' : update , 'human-readable' : update_hr , } ) else : # More than one equation for name , eq in equations : # Compute the gradient gradient_var = \"__k__\" + name gradient_hr = gradient_var + \" = \" + parser . ccode ( eq ) # Update the variable update = sp . Symbol ( 'dt' ) * sp . Symbol ( gradient_var ) update_hr = name + \" += \" + parser . ccode ( update ) gradients . append ( { 'type' : 'tmp' , 'name' : gradient_var , 'op' : \"=\" , 'rhs' : eq , 'human-readable' : gradient_hr , } ) updates . append ( { 'type' : 'assignment' , 'name' : name , 'op' : \"+=\" , 'rhs' : update , 'human-readable' : update_hr , } ) # Gather equations in the right order processed_equations = [] for gradient in gradients : processed_equations . append ( gradient ) for update in updates : processed_equations . append ( update ) return processed_equations","title":"euler()"},{"location":"contributing/parser/#ANNarchy_future.parser.NumericalMethods.exponential","text":"Source code in ANNarchy_future/parser/NumericalMethods.py def exponential ( equations ): gradients = [] updates = [] for name , eq in equations : # Gradient is of the form v' = (A - v)/tau # Expand the equation to better find the time constant: # v' = A/tau - v/tau expanded = eq . expand ( modulus = None , power_base = False , power_exp = False , mul = True , log = False , multinomial = False ) # Current variable v var = sp . Symbol ( name ) # Gradient name gradient_var = \"__k__\" + name # Factorize over the variable v: X*1 - v/tau collected_var = sp . collect ( expanded , var , evaluate = False , exact = False ) # Inverse the factor multiplying v to get tau tau = - 1 / collected_var [ var ] # Step size is (1 - exp(-dt/tau)) step_size = sp . simplify ( 1. - sp . exp ( - sp . Symbol ( 'dt' ) / tau )) # Multiply the gradient by tau to get (A - v) steady = sp . simplify ( tau * expanded ) # Compute the gradient v' = (1- exp(-dt/tau))*(A - v) gradient = step_size * steady gradient_hr = gradient_var + \" = \" + parser . ccode ( gradient ) # Update the variable r += v' update_hr = name + \" += \" + gradient_var gradients . append ( { 'type' : 'tmp' , 'name' : gradient_var , 'op' : \"=\" , 'rhs' : gradient , 'human-readable' : gradient_hr , } ) updates . append ( { 'type' : 'assignment' , 'name' : name , 'op' : \"+=\" , 'rhs' : sp . Symbol ( gradient_var ), 'human-readable' : update_hr , } ) # Gather equations in the right order processed_equations = [] for gradient in gradients : processed_equations . append ( gradient ) for update in updates : processed_equations . append ( update ) return processed_equations","title":"exponential()"},{"location":"contributing/parser/#ANNarchy_future.parser.NumericalMethods.midpoint","text":"Source code in ANNarchy_future/parser/NumericalMethods.py def midpoint ( equations ): midpoints = [] midpoint_vars = {} updates = [] for name , eq in equations : # Current symbol v var = sp . Symbol ( name ) # Midpoint name midpoint_var = \"__k1__\" + name midpoint_vars [ var ] = sp . Symbol ( midpoint_var ) # Compute v + dt/2*v' midpoint = var + sp . Symbol ( 'dt' ) * eq / 2.0 midpoint_hr = midpoint_var + \" = \" + parser . ccode ( midpoint ) midpoints . append ( { 'type' : 'tmp' , 'name' : midpoint_var , 'op' : \"=\" , 'rhs' : midpoint , 'human-readable' : midpoint_hr , } ) for name , eq in equations : # Evaluate gradient in v + dt/2*v' new_eq = sp . Symbol ( 'dt' ) * eq . subs ( midpoint_vars ) # Human readable update_hr = name + \" += \" + parser . ccode ( new_eq ) updates . append ( { 'type' : 'assignment' , 'name' : name , 'op' : \"+=\" , 'rhs' : new_eq , 'human-readable' : update_hr , } ) # Gather equations in the right order processed_equations = [] for midpoint in midpoints : processed_equations . append ( midpoint ) for update in updates : processed_equations . append ( update ) return processed_equations","title":"midpoint()"},{"location":"contributing/parser/#ANNarchy_future.parser.NumericalMethods.rk4","text":"Source code in ANNarchy_future/parser/NumericalMethods.py def rk4 ( equations ): k1s = [] k2s = [] k3s = [] k4s = [] p2s = [] p3s = [] p4s = [] k2_vars = {} k3_vars = {} k4_vars = {} updates = [] # k1 = f'(x, y) for name , eq in equations : # Current symbol v var = sp . Symbol ( name ) # k1 k1_var = \"__k1__\" + name p2_var = \"__p2__\" + name k2_vars [ var ] = sp . Symbol ( p2_var ) p2 = var + sp . Symbol ( 'dt' ) * sp . Symbol ( k1_var ) / 2.0 k1_hr = k1_var + \" = \" + parser . ccode ( eq ) p2_hr = p2_var + \" = \" + parser . ccode ( p2 ) k1s . append ( { 'type' : 'tmp' , 'name' : k1_var , 'op' : \"=\" , 'rhs' : eq , 'human-readable' : k1_hr , } ) p2s . append ( { 'type' : 'tmp' , 'name' : p2_var , 'op' : \"=\" , 'rhs' : p2 , 'human-readable' : p2_hr , } ) # k2 = f'(x + dt*k1/2, y + dt*k1/2) for name , eq in equations : # Current symbol v var = sp . Symbol ( name ) # Compute v + dt/2*v' k2 = sp . simplify ( eq . subs ( k2_vars )) # k1 k2_var = \"__k2__\" + name p3_var = \"__p3__\" + name k3_vars [ var ] = sp . Symbol ( p3_var ) p3 = var + sp . Symbol ( 'dt' ) * sp . Symbol ( k2_var ) / 2.0 k2_hr = k2_var + \" = \" + parser . ccode ( k2 ) p3_hr = p3_var + \" = \" + parser . ccode ( p3 ) k2s . append ( { 'type' : 'tmp' , 'name' : k2_var , 'op' : \"=\" , 'rhs' : k2 , 'human-readable' : k2_hr , } ) p3s . append ( { 'type' : 'tmp' , 'name' : p3_var , 'op' : \"=\" , 'rhs' : p3 , 'human-readable' : p3_hr , } ) # k3 = f'(x + dt*k2/2, y + dt*k2/2) for name , eq in equations : # Current symbol v var = sp . Symbol ( name ) # Substitute k3 = sp . simplify ( eq . subs ( k3_vars )) # k3 k3_var = \"__k3__\" + name p4_var = \"__p4__\" + name k4_vars [ var ] = sp . Symbol ( p4_var ) p4 = var + sp . Symbol ( 'dt' ) * sp . Symbol ( k3_var ) k3_hr = k3_var + \" = \" + parser . ccode ( k3 ) p4_hr = p4_var + \" = \" + parser . ccode ( p4 ) k3s . append ( { 'type' : 'tmp' , 'name' : k3_var , 'op' : \"=\" , 'rhs' : k3 , 'human-readable' : k3_hr , } ) p4s . append ( { 'type' : 'tmp' , 'name' : p4_var , 'op' : \"=\" , 'rhs' : p4 , 'human-readable' : p4_hr , } ) # k4 = f'(x + dt*k3, y + dt*k3) for name , eq in equations : # Current symbol v var = sp . Symbol ( name ) # Substitute k4 = sp . simplify ( eq . subs ( k4_vars )) # k4 k4_var = \"__k4__\" + name k4_hr = k4_var + \" = \" + parser . ccode ( k4 ) k4s . append ( { 'type' : 'tmp' , 'name' : k4_var , 'op' : \"=\" , 'rhs' : k4 , 'human-readable' : k4_hr , } ) for name , eq in equations : # tmp vars var = sp . Symbol ( name ) k1 = sp . Symbol ( \"__k1__\" + name ) k2 = sp . Symbol ( \"__k2__\" + name ) k3 = sp . Symbol ( \"__k3__\" + name ) k4 = sp . Symbol ( \"__k4__\" + name ) # Evaluate gradient in v + dt/2*v' new_eq = sp . Symbol ( 'dt' ) * ( k1 + 2 * k2 + 2 * k3 + k4 ) / sp . Symbol ( \"6.0\" ) # Human readable update_hr = name + \" += \" + parser . ccode ( new_eq ) updates . append ( { 'type' : 'assignment' , 'name' : name , 'op' : \"+=\" , 'rhs' : new_eq , 'human-readable' : update_hr , } ) # Gather equations in the right order processed_equations = [] for k1 in k1s : processed_equations . append ( k1 ) for p2 in p2s : processed_equations . append ( p2 ) for k2 in k2s : processed_equations . append ( k2 ) for p3 in p3s : processed_equations . append ( p3 ) for k3 in k3s : processed_equations . append ( k3 ) for p4 in p4s : processed_equations . append ( p4 ) for k4 in k4s : processed_equations . append ( k4 ) for update in updates : processed_equations . append ( update ) return processed_equations","title":"rk4()"},{"location":"contributing/parser/#code-generation","text":"","title":"Code generation"},{"location":"contributing/parser/#ANNarchy_future.parser.CodeGeneration.ccode","text":"Transforms a sympy expression into C99 code. Applies C99 optimizations ( sympy.codegen.rewriting.optims_c99 ). Expands pow(x; 2) into x*x and pow(x, 3) into x*x*x for performance. Parameters: Name Type Description Default eq sympy expression expression to convert. required Returns: Type Description str a string representing the C code. Source code in ANNarchy_future/parser/CodeGeneration.py def ccode ( eq ) -> str : \"\"\"Transforms a sympy expression into C99 code. Applies C99 optimizations (`sympy.codegen.rewriting.optims_c99`). Expands `pow(x; 2)` into `x*x` and `pow(x, 3)` into `x*x*x` for performance. Args: eq (sympy expression): expression to convert. Returns: a string representing the C code. \"\"\" # If the rhs is a int or float (v = 0.0), cast it to a symbol to avoid numerical errors. if isinstance ( eq , ( float )): eq = sp . Symbol ( str ( float ( eq ))) elif isinstance ( eq , ( int )): eq = sp . Symbol ( str ( int ( eq ))) # Optimize for C99 try : eq = optimize ( eq , optims_c99 ) except : logger = logging . getLogger ( __name__ ) logger . exception ( str ( eq )) sys . exit ( 1 ) # Explicitly expand the use of pow(x, 2) pow2 = ReplaceOptim ( lambda p : p . is_Pow and p . exp == 2 , lambda p : UnevaluatedExpr ( Mul ( p . base , p . base , evaluate = False )) ) eq = pow2 ( eq ) # Explicitly expand the use of pow(x, 3) pow3 = ReplaceOptim ( lambda p : p . is_Pow and p . exp == 3 , lambda p : UnevaluatedExpr ( Mul ( Mul ( p . base , p . base , evaluate = False ), p . base , evaluate = False )) ) eq = pow3 ( eq ) # Get the equivalent C code eq = sp . ccode ( eq ) # Remove the extralines of Piecewise return \" \" . join ( eq . replace ( ' \\n ' , ' ' ) . split ())","title":"ccode()"},{"location":"contributing/parser/#ANNarchy_future.parser.CodeGeneration.code_generation","text":"Gets a dictionary of correspondances and changes all symbols in the sympy expression. Calls eq.subs() and ccode . Parameters: Name Type Description Default eq sympy expression expression. required correspondance dict dictionary of correspondances. {} Returns: Type Description str a string representing the C code. Examples: >>> code_generation ( sp . Symbol ( tau ) * sp . Symbol ( r ), { 'tau' : 'this->tau' , 'r' : 'this->r[i]' }) this -> tau * this -> r [ i ] Source code in ANNarchy_future/parser/CodeGeneration.py def code_generation ( eq , correspondance : dict = {}) -> str : \"\"\"Gets a dictionary of correspondances and changes all symbols in the sympy expression. Calls `eq.subs()` and `ccode`. Args: eq (sympy expression): expression. correspondance (dict): dictionary of correspondances. Returns: a string representing the C code. Example: >>> code_generation( sp.Symbol(tau) * sp.Symbol(r), {'tau': 'this->tau', 'r': 'this->r[i]'}) this->tau*this->r[i] \"\"\" # If the rhs is a int or float (v = 0.0), cast it to a symbol to avoid numerical errors. if isinstance ( eq , ( float )): eq = sp . Symbol ( str ( float ( eq ))) elif isinstance ( eq , ( int )): eq = sp . Symbol ( str ( int ( eq ))) # Build a dictionary of sp.Symbols() replacements = {} for pre , post in correspondance . items (): replacements [ sp . Symbol ( pre )] = sp . Symbol ( post ) # Replace the symbols new_eq = eq . subs ( replacements ) return ccode ( new_eq )","title":"code_generation()"},{"location":"contributing/structure/","text":"Overview \u00b6 Contributing \u00b6 Some words on how to contribute on github. Style \u00b6 Attributes and methods must be typed according to PEP 484: def method ( a : int , b : float = 1.0 ) -> str : \"\"\"Dummy method. Args: a: first parameter. b: second parameter. Returns: a string. \"\"\" c : float = pow ( b , a ) return str ( c ) To facilitate documentation with mkdocstrings , all comments and docstrings must follow the Google style: https://google.github.io/styleguide/pyguide.html Example: https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html Pylint should never have to complain ;) Unit tests \u00b6 Find a strategy for consistent unit testing. Overview of ANNarchy's structure \u00b6 Overview of the architecture: api parser generator Publishing Cython extensions \u00b6 https://levelup.gitconnected.com/how-to-deploy-a-cython-package-to-pypi-8217a6581f09","title":"Overview"},{"location":"contributing/structure/#overview","text":"","title":"Overview"},{"location":"contributing/structure/#contributing","text":"Some words on how to contribute on github.","title":"Contributing"},{"location":"contributing/structure/#style","text":"Attributes and methods must be typed according to PEP 484: def method ( a : int , b : float = 1.0 ) -> str : \"\"\"Dummy method. Args: a: first parameter. b: second parameter. Returns: a string. \"\"\" c : float = pow ( b , a ) return str ( c ) To facilitate documentation with mkdocstrings , all comments and docstrings must follow the Google style: https://google.github.io/styleguide/pyguide.html Example: https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html Pylint should never have to complain ;)","title":"Style"},{"location":"contributing/structure/#unit-tests","text":"Find a strategy for consistent unit testing.","title":"Unit tests"},{"location":"contributing/structure/#overview-of-annarchys-structure","text":"Overview of the architecture: api parser generator","title":"Overview of ANNarchy's structure"},{"location":"contributing/structure/#publishing-cython-extensions","text":"https://levelup.gitconnected.com/how-to-deploy-a-cython-package-to-pypi-8217a6581f09","title":"Publishing Cython extensions"},{"location":"manual/neuron/","text":"Neuron \u00b6 class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Parameter ( params [ 'tau' ]) self . V_th = self . Parameter ( params [ 'V_th' ]) self . ge = self . Variable ( init = 0.0 ) self . v = self . Variable ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0","title":"Neuron"},{"location":"manual/neuron/#neuron","text":"class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Parameter ( params [ 'tau' ]) self . V_th = self . Parameter ( params [ 'V_th' ]) self . ge = self . Variable ( init = 0.0 ) self . v = self . Variable ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0","title":"Neuron"},{"location":"manual/structure/","text":"Structure \u00b6 Networks \u00b6 Everything is inside a Network object to avoid global variables and allow for parallel simulations easily. Populations are created with net.add() , projections with net.connect() . net = Network () pop = net . add ( 100 , Izhikevich ()) proj = net . connect ( pop , pop . ge ) proj . dense ( w = 1.0 ) net . compile () net . simulate ( 1000. ) net . save ( \"data.h5\" ) Networks can be inherited for a better parameterization and to allow finer control of the operations: class BG ( Network ): def __init__ ( self , N ): self . N = N super ( self , BG ) . __init__ ( dt = 1.0 ) def build ( self ): self . striatum = self . add ( N , MSN ()) self . gpi = self . add ( N / 10 , GPI ()) self . gpe = self . add ( N / 10 , GPE ()) self . thal = self . add ( N , Thal ()) self . str_gpi = self . connect ( striatum , gpi . gi , Covariance ) self . str_gpi . dense ( w = 1.0 ) def step ( self ): # Transmission for proj in self . projections (): proj . transmit () # Update neural equations for pop in self . populations (): pop . update () # Update synaptic equations for proj in self . projections () proj . update () Neurons \u00b6 Neurons have to be defined as classes. This allows to pass them default parameter values in the constructor and simplify instantiation of populations: pop1 = net . add ( 100 , Izhikevich ( a = 0.02 )) pop2 = net . add ( 100 , Izhikevich ( a = 0.2 )) Rate-coded neurons only need to define update() : class RateCoded ( ann . Neuron ): \"\"\" Simple rate-coded neuron. \"\"\" def __init__ ( self , tau ): self . tau = self . Parameter ( tau ) self . ge = self . Variable ( init = 0.0 ) self . v = self . Variable ( init = 0.0 ) self . r = self . Variable ( init = 0.0 ) def update ( self ): # n will contain all variables of the model as sympy symbols, # plus some operations (ite = if/then/else) with self . Equations ( method = 'euler' ) as n : # One can declare intermediary variables # that won't be allocated in memory! shunting = n . ite ( n . ge > 1 , n . ge , 0 ) # ODEs use the dX_dt trick n . dv_dt = ( n . ge + shunting + sp . exp ( n . v ** 2 ) - n . v ) / n . tau # Sympy functions can be used directly n . r = sp . tanh ( n . v ) Spiking neuron declares additionally spike() and reset() : class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Parameter ( params [ 'tau' ]) self . V_th = self . Parameter ( params [ 'V_th' ]) self . ge = self . Value ( init = 0.0 ) self . v = self . Value ( init = 0.0 ) def update ( self ): with self . Equations ( method = 'euler' ) as n : n . dv_dt = ( n . ge - n . v ) / n . tau with self . Equations ( method = 'exponential' ) as n : n . dge_dt = ( - n . ge ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0 The Equations() context provides sympy symbols for each parameter/variable of the neuron, plus some specific ones ( t , dt , spike for spike emission, etc). Derivatives are symbolically set as dX_dt . All sympy operations (math C99 ) can be used. Areas \u00b6 We introduce back the notion of Area / node / subnetwork, grouping several populations and their internal connections together: cortical columns reusable ensembles (BG, Hipp) hybrid networks (rate-coded -> spiking, with a specific projection interface) multi-scale networks, using DTI data for long-range connections between reservoirs class BG ( ANNarchy . Area ): def __init__ ( self ): \"Mostly creating the populations and projections.\" self . striatum = self . add ( 1000 , MSN ()) self . gpi = self . add ( 100 , GPI ()) self . gpe = self . add ( 100 , GPE ()) self . thal = self . add ( 100 , Thal ()) self . str_gpi = self . connect ( striatum , gpi . gi , Covariance ) self . str_gpi . dense ( w = 1.0 ) super ( self , BG ) . __init__ () net = Network () cortex = net . add ( 10000 , Cx ()) bg = net . add ( BG ()) cx_bg = net . connect ( cortex , bg . striatum . ge , Corticostriatal ) cx_bg . dense ( w = Normal ( 0.0 , 1.0 ))","title":"Structure"},{"location":"manual/structure/#structure","text":"","title":"Structure"},{"location":"manual/structure/#networks","text":"Everything is inside a Network object to avoid global variables and allow for parallel simulations easily. Populations are created with net.add() , projections with net.connect() . net = Network () pop = net . add ( 100 , Izhikevich ()) proj = net . connect ( pop , pop . ge ) proj . dense ( w = 1.0 ) net . compile () net . simulate ( 1000. ) net . save ( \"data.h5\" ) Networks can be inherited for a better parameterization and to allow finer control of the operations: class BG ( Network ): def __init__ ( self , N ): self . N = N super ( self , BG ) . __init__ ( dt = 1.0 ) def build ( self ): self . striatum = self . add ( N , MSN ()) self . gpi = self . add ( N / 10 , GPI ()) self . gpe = self . add ( N / 10 , GPE ()) self . thal = self . add ( N , Thal ()) self . str_gpi = self . connect ( striatum , gpi . gi , Covariance ) self . str_gpi . dense ( w = 1.0 ) def step ( self ): # Transmission for proj in self . projections (): proj . transmit () # Update neural equations for pop in self . populations (): pop . update () # Update synaptic equations for proj in self . projections () proj . update ()","title":"Networks"},{"location":"manual/structure/#neurons","text":"Neurons have to be defined as classes. This allows to pass them default parameter values in the constructor and simplify instantiation of populations: pop1 = net . add ( 100 , Izhikevich ( a = 0.02 )) pop2 = net . add ( 100 , Izhikevich ( a = 0.2 )) Rate-coded neurons only need to define update() : class RateCoded ( ann . Neuron ): \"\"\" Simple rate-coded neuron. \"\"\" def __init__ ( self , tau ): self . tau = self . Parameter ( tau ) self . ge = self . Variable ( init = 0.0 ) self . v = self . Variable ( init = 0.0 ) self . r = self . Variable ( init = 0.0 ) def update ( self ): # n will contain all variables of the model as sympy symbols, # plus some operations (ite = if/then/else) with self . Equations ( method = 'euler' ) as n : # One can declare intermediary variables # that won't be allocated in memory! shunting = n . ite ( n . ge > 1 , n . ge , 0 ) # ODEs use the dX_dt trick n . dv_dt = ( n . ge + shunting + sp . exp ( n . v ** 2 ) - n . v ) / n . tau # Sympy functions can be used directly n . r = sp . tanh ( n . v ) Spiking neuron declares additionally spike() and reset() : class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Parameter ( params [ 'tau' ]) self . V_th = self . Parameter ( params [ 'V_th' ]) self . ge = self . Value ( init = 0.0 ) self . v = self . Value ( init = 0.0 ) def update ( self ): with self . Equations ( method = 'euler' ) as n : n . dv_dt = ( n . ge - n . v ) / n . tau with self . Equations ( method = 'exponential' ) as n : n . dge_dt = ( - n . ge ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0 The Equations() context provides sympy symbols for each parameter/variable of the neuron, plus some specific ones ( t , dt , spike for spike emission, etc). Derivatives are symbolically set as dX_dt . All sympy operations (math C99 ) can be used.","title":"Neurons"},{"location":"manual/structure/#areas","text":"We introduce back the notion of Area / node / subnetwork, grouping several populations and their internal connections together: cortical columns reusable ensembles (BG, Hipp) hybrid networks (rate-coded -> spiking, with a specific projection interface) multi-scale networks, using DTI data for long-range connections between reservoirs class BG ( ANNarchy . Area ): def __init__ ( self ): \"Mostly creating the populations and projections.\" self . striatum = self . add ( 1000 , MSN ()) self . gpi = self . add ( 100 , GPI ()) self . gpe = self . add ( 100 , GPE ()) self . thal = self . add ( 100 , Thal ()) self . str_gpi = self . connect ( striatum , gpi . gi , Covariance ) self . str_gpi . dense ( w = 1.0 ) super ( self , BG ) . __init__ () net = Network () cortex = net . add ( 10000 , Cx ()) bg = net . add ( BG ()) cx_bg = net . connect ( cortex , bg . striatum . ge , Corticostriatal ) cx_bg . dense ( w = Normal ( 0.0 , 1.0 ))","title":"Areas"}]}