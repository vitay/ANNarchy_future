{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ANNarchy About ANNarchy ANNarchy (Artificial Neural Networks architect) is a neural simulator designed for distributed rate-coded or spiking neural networks. The core of the library is written in C++ and distributed using openMP, CUDA and MPI. It provides an interface in Python for the definition of the networks. It is released under the GNU GPL v2 or later . Source code: http://bitbucket.org/annarchy/annarchy Documentation: http://annarchy.readthedocs.io Forum: https://groups.google.com/forum/#!forum/annarchy Bug reports: https://bitbucket.org/annarchy/annarchy/issues Citation If you use ANNarchy for your research, we would appreciate if you cite the following paper: Vitay J, Dinkelbach H\u00dc and Hamker FH (2015). ANNarchy: a code generation approach to neural simulations on parallel hardware. Frontiers in Neuroinformatics 9:19. http://dx.doi.org/10.3389/fninf.2015.00019 Dependencies ANNarchy can be used on any GNU/Linux system, as well as MacOS X. Installation To install the latest stable release of ANNarchy, pip is recommended: pip install ANNarchy To install the latest developement release of ANNarchy, install it from source: git clone http://bitbucket.org/annarchy/annarchy.git cd annarchy/ python setup.py install","title":"ANNarchy"},{"location":"#annarchy","text":"","title":"ANNarchy"},{"location":"#about-annarchy","text":"ANNarchy (Artificial Neural Networks architect) is a neural simulator designed for distributed rate-coded or spiking neural networks. The core of the library is written in C++ and distributed using openMP, CUDA and MPI. It provides an interface in Python for the definition of the networks. It is released under the GNU GPL v2 or later . Source code: http://bitbucket.org/annarchy/annarchy Documentation: http://annarchy.readthedocs.io Forum: https://groups.google.com/forum/#!forum/annarchy Bug reports: https://bitbucket.org/annarchy/annarchy/issues Citation If you use ANNarchy for your research, we would appreciate if you cite the following paper: Vitay J, Dinkelbach H\u00dc and Hamker FH (2015). ANNarchy: a code generation approach to neural simulations on parallel hardware. Frontiers in Neuroinformatics 9:19. http://dx.doi.org/10.3389/fninf.2015.00019","title":"About ANNarchy"},{"location":"#dependencies","text":"ANNarchy can be used on any GNU/Linux system, as well as MacOS X.","title":"Dependencies"},{"location":"#installation","text":"To install the latest stable release of ANNarchy, pip is recommended: pip install ANNarchy To install the latest developement release of ANNarchy, install it from source: git clone http://bitbucket.org/annarchy/annarchy.git cd annarchy/ python setup.py install","title":"Installation"},{"location":"api/network/","text":"Network Network class containing the complete neural model. Attributes: Name Type Description dt simulation time step in ms. __init__ ( self , dt = 1.0 , verbose = 1 , logfile = None ) special Constructor of the Network class. The discretization time contant dt is determined at the network-level and should stay constant during the whole simulation. The verbose level specifies which logging messages will be shown: 0 : only errors and exceptions are printed. 1 : errors, exceptions and warnings are displayed (default). 2 : additional information is also displayed (parsing, etc). 3 : debug information is also displayed (which method is entered, variable values, etc...) When logfile is specified, the logging messages will be saved in that file instead of stdout. Parameters: Name Type Description Default dt float simulation step size in ms. 1.0 verbose int logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 1 logfile str file to save the logs. stdout if left empty. None Source code in ANNarchy_future/api/Network.py def __init__ ( self , dt : float = 1.0 , verbose : int = 1 , logfile : str = None ): \"\"\"Constructor of the `Network` class. The discretization time contant `dt` is determined at the network-level and should stay constant during the whole simulation. The `verbose` level specifies which logging messages will be shown: * 0 : only errors and exceptions are printed. * 1 : errors, exceptions and warnings are displayed (default). * 2 : additional information is also displayed (parsing, etc). * 3 : debug information is also displayed (which method is entered, variable values, etc...) When `logfile` is specified, the logging messages will be saved in that file instead of stdout. Args: dt: simulation step size in ms. verbose: logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 logfile: file to save the logs. stdout if left empty. \"\"\" self . dt = dt # Logging module: https://docs.python.org/3/howto/logging.html if logfile is not None : logging . basicConfig ( filename = logfile , level = verbosity_levels [ verbose ]) else : logging . basicConfig ( level = verbosity_levels [ verbose ]) self . logger = logging . getLogger ( __name__ ) self . logger . info ( \"Creating new network with dt=\" + str ( self . dt )) # List of populations self . _populations = [] add ( self , shape , neuron , name = None ) Adds a population to the network. Parameters: Name Type Description Default shape tuple shape of the population as a single integer or tuple. required neuron Neuron Neuron instance. required name str optional name. None Returns: Type Description Population A population instance. Source code in ANNarchy_future/api/Network.py def add ( self , shape : tuple , neuron : Neuron , name : str = None ) -> Population : \"\"\"Adds a population to the network. Args: shape: shape of the population as a single integer or tuple. neuron: Neuron instance. name: optional name. Returns: A population instance. \"\"\" if isinstance ( shape , int ): shape = ( shape ,) # Create the population self . logger . info ( \"Adding Population(\" + str ( shape ) + \", \" + type ( neuron ) . __name__ + \", \" + str ( name ) + \").\" ) pop = Population ( shape , neuron , name ) id_pop = len ( self . _populations ) pop . _register ( self , id_pop ) # Have the population analyse its attributes self . logger . debug ( \"Analysing the population.\" ) pop . _analyse () # Store the population self . _populations . append ( pop ) self . logger . info ( \"Population created.\" ) return pop compile ( self , backend = 'single' ) Compiles and instantiates the network. Args: backend: 'single', 'openmp', 'cuda' or 'mpi'. Source code in ANNarchy_future/api/Network.py def compile ( self , backend : str = 'single' ): \"\"\"Compiles and instantiates the network. Args: backend: 'single', 'openmp', 'cuda' or 'mpi'. \"\"\" self . _backend = backend # Gather all parsed information description = {} compiler = Compiler ( description , backend = backend ) # Sanity check ? compiler . sanity_check () # Code generation self . _simulation_core = compiler . compile () # Instantiate the network self . _instantiate () self . _obj_ids = self . _simulation_core . _instantiate ()","title":"Network"},{"location":"api/network/#network","text":"Network class containing the complete neural model. Attributes: Name Type Description dt simulation time step in ms.","title":"Network"},{"location":"api/network/#ANNarchy_future.api.Network.Network.__init__","text":"Constructor of the Network class. The discretization time contant dt is determined at the network-level and should stay constant during the whole simulation. The verbose level specifies which logging messages will be shown: 0 : only errors and exceptions are printed. 1 : errors, exceptions and warnings are displayed (default). 2 : additional information is also displayed (parsing, etc). 3 : debug information is also displayed (which method is entered, variable values, etc...) When logfile is specified, the logging messages will be saved in that file instead of stdout. Parameters: Name Type Description Default dt float simulation step size in ms. 1.0 verbose int logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 1 logfile str file to save the logs. stdout if left empty. None Source code in ANNarchy_future/api/Network.py def __init__ ( self , dt : float = 1.0 , verbose : int = 1 , logfile : str = None ): \"\"\"Constructor of the `Network` class. The discretization time contant `dt` is determined at the network-level and should stay constant during the whole simulation. The `verbose` level specifies which logging messages will be shown: * 0 : only errors and exceptions are printed. * 1 : errors, exceptions and warnings are displayed (default). * 2 : additional information is also displayed (parsing, etc). * 3 : debug information is also displayed (which method is entered, variable values, etc...) When `logfile` is specified, the logging messages will be saved in that file instead of stdout. Args: dt: simulation step size in ms. verbose: logging level. ERROR=0, WARNING=1, INFO=2, DEBUG=3 logfile: file to save the logs. stdout if left empty. \"\"\" self . dt = dt # Logging module: https://docs.python.org/3/howto/logging.html if logfile is not None : logging . basicConfig ( filename = logfile , level = verbosity_levels [ verbose ]) else : logging . basicConfig ( level = verbosity_levels [ verbose ]) self . logger = logging . getLogger ( __name__ ) self . logger . info ( \"Creating new network with dt=\" + str ( self . dt )) # List of populations self . _populations = []","title":"__init__()"},{"location":"api/network/#ANNarchy_future.api.Network.Network.add","text":"Adds a population to the network. Parameters: Name Type Description Default shape tuple shape of the population as a single integer or tuple. required neuron Neuron Neuron instance. required name str optional name. None Returns: Type Description Population A population instance. Source code in ANNarchy_future/api/Network.py def add ( self , shape : tuple , neuron : Neuron , name : str = None ) -> Population : \"\"\"Adds a population to the network. Args: shape: shape of the population as a single integer or tuple. neuron: Neuron instance. name: optional name. Returns: A population instance. \"\"\" if isinstance ( shape , int ): shape = ( shape ,) # Create the population self . logger . info ( \"Adding Population(\" + str ( shape ) + \", \" + type ( neuron ) . __name__ + \", \" + str ( name ) + \").\" ) pop = Population ( shape , neuron , name ) id_pop = len ( self . _populations ) pop . _register ( self , id_pop ) # Have the population analyse its attributes self . logger . debug ( \"Analysing the population.\" ) pop . _analyse () # Store the population self . _populations . append ( pop ) self . logger . info ( \"Population created.\" ) return pop","title":"add()"},{"location":"api/network/#ANNarchy_future.api.Network.Network.compile","text":"Compiles and instantiates the network. Args: backend: 'single', 'openmp', 'cuda' or 'mpi'. Source code in ANNarchy_future/api/Network.py def compile ( self , backend : str = 'single' ): \"\"\"Compiles and instantiates the network. Args: backend: 'single', 'openmp', 'cuda' or 'mpi'. \"\"\" self . _backend = backend # Gather all parsed information description = {} compiler = Compiler ( description , backend = backend ) # Sanity check ? compiler . sanity_check () # Code generation self . _simulation_core = compiler . compile () # Instantiate the network self . _instantiate () self . _obj_ids = self . _simulation_core . _instantiate ()","title":"compile()"},{"location":"api/neuron/","text":"Neuron Abstract class defining single neurons. TODO Array ( self , init = 0.0 , dtype =< class ' numpy . float32 '>) Creates and returns an array. Source code in ANNarchy_future/api/Neuron.py def Array ( self , init = 0.0 , dtype = np . float32 ): \"Creates and returns an array.\" if not hasattr ( self , \"_data\" ): self . _data = [] val = Array ( init , dtype ) self . _data . append ( val ) return val Equations ( self ) Returns an Equations context. Source code in ANNarchy_future/api/Neuron.py def Equations ( self ): \"Returns an Equations context.\" eq = Equations ( neuron = self ) self . _current_eq = eq return eq Value ( self , value , dtype =< class ' numpy . float32 '>) Defines a Value for the neuron. Values are defined only once for the whole population. If each neuron should have different values, use an Array instead. Parameters: Name Type Description Default value initial value. required dtype numpy type of the value (e.g. np.int, np.float) <class 'numpy.float32'> Returns: Type Description Value Value instance. Source code in ANNarchy_future/api/Neuron.py def Value ( self , value , dtype = np . float32 ) -> Value : \"\"\"Defines a Value for the neuron. Values are defined only once for the whole population. If each neuron should have different values, use an `Array` instead. Args: value: initial value. dtype: numpy type of the value (e.g. np.int, np.float) Returns: `Value` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = Value ( value , dtype ) self . _data . append ( val ) return val","title":"Neuron"},{"location":"api/neuron/#neuron","text":"Abstract class defining single neurons. TODO","title":"Neuron"},{"location":"api/neuron/#ANNarchy_future.api.Neuron.Neuron.Array","text":"Creates and returns an array. Source code in ANNarchy_future/api/Neuron.py def Array ( self , init = 0.0 , dtype = np . float32 ): \"Creates and returns an array.\" if not hasattr ( self , \"_data\" ): self . _data = [] val = Array ( init , dtype ) self . _data . append ( val ) return val","title":"Array()"},{"location":"api/neuron/#ANNarchy_future.api.Neuron.Neuron.Equations","text":"Returns an Equations context. Source code in ANNarchy_future/api/Neuron.py def Equations ( self ): \"Returns an Equations context.\" eq = Equations ( neuron = self ) self . _current_eq = eq return eq","title":"Equations()"},{"location":"api/neuron/#ANNarchy_future.api.Neuron.Neuron.Value","text":"Defines a Value for the neuron. Values are defined only once for the whole population. If each neuron should have different values, use an Array instead. Parameters: Name Type Description Default value initial value. required dtype numpy type of the value (e.g. np.int, np.float) <class 'numpy.float32'> Returns: Type Description Value Value instance. Source code in ANNarchy_future/api/Neuron.py def Value ( self , value , dtype = np . float32 ) -> Value : \"\"\"Defines a Value for the neuron. Values are defined only once for the whole population. If each neuron should have different values, use an `Array` instead. Args: value: initial value. dtype: numpy type of the value (e.g. np.int, np.float) Returns: `Value` instance. \"\"\" if not hasattr ( self , \"_data\" ): self . _data = [] val = Value ( value , dtype ) self . _data . append ( val ) return val","title":"Value()"},{"location":"api/population/","text":"Population Population Population of neurons. Populations should not be created explicitly, but returned by Network.add() : net = Network () pop = net . add ( 10 , LIF ()) Attributes: Name Type Description shape tuple shape of the population. size int number of neurons. name str unique name of the population. Additionaly, all values and arrays of the neuron type are accessible as attributes: class Leaky ( Neuron ): def __init__ ( self ): self . tau = self . Value ( 20. ) self . r = self . Array ( 0.0 ) net = Network () pop = net . add ( 10 , Leaky ()) print ( pop . tau ) # 20. print ( pop . r ) # [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]","title":"Population"},{"location":"api/population/#population","text":"","title":"Population"},{"location":"api/population/#ANNarchy_future.api.Population.Population","text":"Population of neurons. Populations should not be created explicitly, but returned by Network.add() : net = Network () pop = net . add ( 10 , LIF ()) Attributes: Name Type Description shape tuple shape of the population. size int number of neurons. name str unique name of the population. Additionaly, all values and arrays of the neuron type are accessible as attributes: class Leaky ( Neuron ): def __init__ ( self ): self . tau = self . Value ( 20. ) self . r = self . Array ( 0.0 ) net = Network () pop = net . add ( 10 , Leaky ()) print ( pop . tau ) # 20. print ( pop . r ) # [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]","title":"Population"},{"location":"manual/neuron/","text":"Neuron class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Value ( params [ 'tau' ]) self . V_th = self . Value ( params [ 'V_th' ]) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0","title":"Neuron"},{"location":"manual/neuron/#neuron","text":"class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Value ( params [ 'tau' ]) self . V_th = self . Value ( params [ 'V_th' ]) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0","title":"Neuron"},{"location":"manual/structure/","text":"Structure Networks Everything is inside a Network object to avoid global variables and allow for parallel simulations easily. net = Network () pop = net . add ( 100 , Izhikevich ()) proj = net . connect ( pop , pop . ge ) proj . dense ( w = 1.0 ) net . compile () net . simulate ( 1000. ) net . save ( \"data.h5\" ) Neurons Neurons have to be defined as classes. Rate-coded neurons: class RateCoded ( ann . Neuron ): \"\"\" Simple rate-coded neuron. \"\"\" def __init__ ( self , tau ): self . tau = self . Value ( tau ) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) self . r = self . Array ( init = 0.0 ) def update ( self ): # n will contain all variables of the model as sympy symbols, # plus some operations (ite = if/then/else) with self . Equations () as n : # One can declare intermediary variables # that won't be allocated in memory! shunting = n . ite ( n . ge > 1 , n . ge , 0 ) # ODEs use the dX_dt trick n . dv_dt = ( n . ge + shunting + sp . exp ( n . v ** 2 ) - n . v ) / n . tau # Sympy functions can be used directly n . r = sp . tanh ( n . v ) Spiking neuron declares additionally spike() and reset() : class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Value ( params [ 'tau' ]) self . V_th = self . Value ( params [ 'V_th' ]) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0 Areas We introduce back the notion of Area / node / subnetwork, grouping several populations and their internal connections together: cortical columns reusable ensembles (BG, Hipp) hybrid networks (rate-coded -> spiking, with a specific projection interface) multi-scale networks, using DTI data for long-range connections between reservoirs class BG ( ANNarchy . Area ): def __init__ ( self ): \"Mostly creating the populations and projections.\" self . striatum = self . add ( MSN ( 1000 )) self . gpi = self . add ( GPI ( 100 )) self . gpe = self . add ( GPE ( 100 ) self . thal = self . add ( Thal ( 100 )) self . str_gpi = self . connect ( striatum , gpi . gi , Covariance ) self . str_gpi . dense ( w = 1.0 ) super ( self , BG ) . __init__ () net = Network () cortex = net . add ( Cx ( 10000 )) bg = net . add ( BG ()) cx_bg = net . connect ( cortex , bg . striatum . ge , Corticostriatal ) cx_bg . dense ( w = Normal ( 0.0 , 1.0 ))","title":"Structure"},{"location":"manual/structure/#structure","text":"","title":"Structure"},{"location":"manual/structure/#networks","text":"Everything is inside a Network object to avoid global variables and allow for parallel simulations easily. net = Network () pop = net . add ( 100 , Izhikevich ()) proj = net . connect ( pop , pop . ge ) proj . dense ( w = 1.0 ) net . compile () net . simulate ( 1000. ) net . save ( \"data.h5\" )","title":"Networks"},{"location":"manual/structure/#neurons","text":"Neurons have to be defined as classes. Rate-coded neurons: class RateCoded ( ann . Neuron ): \"\"\" Simple rate-coded neuron. \"\"\" def __init__ ( self , tau ): self . tau = self . Value ( tau ) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) self . r = self . Array ( init = 0.0 ) def update ( self ): # n will contain all variables of the model as sympy symbols, # plus some operations (ite = if/then/else) with self . Equations () as n : # One can declare intermediary variables # that won't be allocated in memory! shunting = n . ite ( n . ge > 1 , n . ge , 0 ) # ODEs use the dX_dt trick n . dv_dt = ( n . ge + shunting + sp . exp ( n . v ** 2 ) - n . v ) / n . tau # Sympy functions can be used directly n . r = sp . tanh ( n . v ) Spiking neuron declares additionally spike() and reset() : class LIF ( ann . Neuron ): def __init__ ( self , params ): self . tau = self . Value ( params [ 'tau' ]) self . V_th = self . Value ( params [ 'V_th' ]) self . ge = self . Array ( init = 0.0 ) self . v = self . Array ( init = 0.0 ) def update ( self ): with self . Equations () as n : n . dv_dt = ( n . ge - n . v ) / n . tau def spike ( self ): with self . Equations () as n : n . spike = n . v >= n . V_th def reset ( self ): with self . Equations () as n : n . v = 0","title":"Neurons"},{"location":"manual/structure/#areas","text":"We introduce back the notion of Area / node / subnetwork, grouping several populations and their internal connections together: cortical columns reusable ensembles (BG, Hipp) hybrid networks (rate-coded -> spiking, with a specific projection interface) multi-scale networks, using DTI data for long-range connections between reservoirs class BG ( ANNarchy . Area ): def __init__ ( self ): \"Mostly creating the populations and projections.\" self . striatum = self . add ( MSN ( 1000 )) self . gpi = self . add ( GPI ( 100 )) self . gpe = self . add ( GPE ( 100 ) self . thal = self . add ( Thal ( 100 )) self . str_gpi = self . connect ( striatum , gpi . gi , Covariance ) self . str_gpi . dense ( w = 1.0 ) super ( self , BG ) . __init__ () net = Network () cortex = net . add ( Cx ( 10000 )) bg = net . add ( BG ()) cx_bg = net . connect ( cortex , bg . striatum . ge , Corticostriatal ) cx_bg . dense ( w = Normal ( 0.0 , 1.0 ))","title":"Areas"}]}